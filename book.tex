\documentclass[oneside,11pt,dvipsnames]{book}
\setcounter{secnumdepth}{3}

\usepackage{xcolor}
\definecolor{myred}{RGB}{255,100,100}
\definecolor{yellowfill}{RGB}{255,245,200}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.97,0.97,0.97}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[margin=1.5in]{geometry}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{complexity}
\usepackage{etoolbox}
\usepackage{hyperref}
\hypersetup{
  colorlinks,
  citecolor=black,
  filecolor=black,
  linkcolor=blue,
  urlcolor=blue,
}

\usepackage{soul}
\usepackage[most]{tcolorbox}

\numberwithin{equation}{section}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollary}{Corollary}[section]

% Definitions and remarks usually use a different style:
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]
\newtheorem{problem}{Problem}[section]
\newtheorem{solutione}{Solution}[section]
\theoremstyle{remark}
\newtheorem{remark}{Remark}


\newbool{showsol}
\setbool{showsol}{false}

\newenvironment{solution}{%
  \ifbool{showsol}{%
    \begin{solutione}%
  }{%
    \comment % start ignoring
  }%
}{%
  \ifbool{showsol}{%
    \end{solutione}%
  }{%
    \endcomment % stop ignoring
  }%
}

% \setsecnumdepth{subsection}
% \setcounter{tocdepth}{3}
\usepackage{multirow,multicol}
\usepackage{enumitem}
\usepackage{epigraph}
\usepackage{cite}
\usepackage{caption}
\usepackage{adjustbox}
\usepackage{makecell}
\usepackage{longtable}
\captionsetup{font=small}
\usepackage{graphicx}
\usepackage{pdfpages}
\usepackage{wrapfig}
\usepackage{subcaption}
\setlength\intextsep{0pt} % remove extra space above and below in-line float
%\usepackage{cleveref}
\usepackage{booktabs}
\usepackage{tikz}
\usetikzlibrary{calc,positioning,intersections}
\tikzstyle{input}=[circle,draw=green,fill=green!20,thick]
\tikzstyle{hidden}=[circle,draw=yellow,fill=yellowfill,thick]
\tikzstyle{output}=[circle,draw=red,fill=red!20,thick]

\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

\usepackage{anyfontsize}
\usepackage{sectsty}

\usepackage[makeroom]{cancel}

\usepackage{listings}
\lstset{basicstyle=\ttfamily\scriptsize,
  language=Python,
  morekeywords={assert},
  keywordstyle=\color{blue},
  commentstyle=\color{magenta},
  numbers=none,
  mathescape,
  stepnumber=1,
  numbersep=8pt,
  tabsize=4,
  showspaces=false,
  showstringspaces=false,
  emph={},
  emphstyle=\color{red}\bfseries
}
\definecolor{keywords}{RGB}{0,35,197}
\definecolor{comments}{RGB}{19,121,0}
\definecolor{highlight}{RGB}{255,255,102}


\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\SetKwFor{Parfor}{parfor}{do}{endparfor}

\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}

\SetKw{Break}{break}
\SetKw{Continue}{continue}
\SetKw{In}{in}
\SetKwData{certified}{certified}
\SetKwData{prooftree}{proof}
\SetKwData{uncertified}{uncertified}
\SetKwData{model}{model}
\SetKwData{leaf}{node}
\SetKwData{mynull}{null}
\SetKwData{layer}{layer}
\SetKwData{layer}{layer}
\SetKwData{layerbounds}{layer\_bounds}
\DontPrintSemicolon

\SetAlgoCaptionSeparator{.}
\SetAlCapFnt{\footnotesize\rm}
\SetAlCapNameFnt{\footnotesize\rm}

\newcommand{\mycode}[1]{\textrm{\texttt{#1}}}



\newtoggle{usecomment}
\settoggle{usecomment}{true}

\newcommand{\tcomment}[1]{\iftoggle{usecomment}{#1}{}}
\newcommand{\tvn}[1]{\iftoggle{usecomment}{{\color{red}{[TVN]: #1}}}{}}

\newcommand{\mbd}[1]{\iftoggle{usecomment}{{\color{magenta}{[MBD]: #1}}}{}}
\newcommand{\hd}[1]{\iftoggle{usecomment}{{\color{blue}{[HD]: #1}}}{}}
\newcommand{\hai}[1]{\iftoggle{usecomment}{{\color{blue}{[HD]: #1}}}{}}

\newcommand{\mynew}[1]{\iftoggle{usecomment}{{\color{red}{[NEW]: #1}}}{}}
\newcommand{\alert}[1]{{\color{red}{#1}}}
%\newcommand{\ignore}[1]{}

\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\red}[1]{\textcolor{blue}{#1}}

\newtcolorbox{mybox}{
  enhanced,
  boxrule=0pt,frame hidden,
  borderline west={2pt}{0pt}{green!75!black},
  colback=green!10!white,
  sharp corners
}

\newenvironment{commentbox}[1][]{
  \small
  \begin{mybox}
    {\small \textbf{#1}}
  }{
  \end{mybox}
}

\newtcolorbox{mydomesticbox}{
  enhanced,
  boxrule=0pt,frame hidden,
  borderline west={2pt}{0pt}{red!75!black},
  colback=blue!10!white,
  sharp corners
}

\newenvironment{domesticbox}[1][]{
  \small
  \begin{mydomesticbox}
    {\small \textbf{#1}}
  }{
  \end{mydomesticbox}
}

\newcommand{\ignore}[1]{}


\makeatletter
% for cross references
% \renewcommand{\algorithmcflinename}{L.}and use it in
\renewcommand{\algorithmautorefname}{Alg.}
\renewcommand{\figureautorefname}{Fig.}
\renewcommand{\tableautorefname}{Tab.}
\renewcommand{\equationautorefname}{Eq.}
\providecommand{\definitionautorefname}{Def.}
\renewcommand{\chapterautorefname}{\textsection\@gobble}
\renewcommand{\sectionautorefname}{\textsection\@gobble}
\renewcommand{\subsectionautorefname}{\textsection\@gobble}
\renewcommand{\subsubsectionautorefname}{\textsection\@gobble}
\renewcommand{\appendixautorefname}{\textsection\@gobble}

\newcommand{\exampleautorefname}{Ex.}
\newcommand{\problemautorefname}{Prob.}

\makeatother
\newcommand{\proofgen}{\texttt{BaB$_{\text{ProofGen}}$}}
\newcommand{\prooflang}{\texttt{BaB$_{\text{ProofLang}}$}}
\newcommand{\proofcheck}{\texttt{BaB$_{\text{ProofCheck}}$}}

\newcommand{\veristable}{\texttt{VeriStable}}
\newcommand{\crown}{\texttt{$\alpha\beta$-CROWN}}
\newcommand{\nnenum}{\texttt{nnenum}}
\newcommand{\marabou}{\texttt{Marabou}}
\newcommand{\eran}{\texttt{ERAN}}
\newcommand{\reluplex}{\texttt{Reluplex}}
\newcommand{\reluval}{\texttt{Reluval}}
\newcommand{\neurify}{\texttt{Neurify}}
\newcommand{\nnv}{\texttt{NNV}}
\newcommand{\ovalnnv}{\texttt{OVAL}}
\newcommand{\dnnv}{\texttt{DNNV}}
\newcommand{\verinet}{\texttt{VeriNet}}
\newcommand{\mnbab}{\texttt{MN-BaB}}
% \newcommand{\vnncomp}{VNN-COMP'23}
\newcommand{\planet}{\texttt{Planet}}
\newcommand{\bab}{\texttt{BaB$_{\text{NNV}}$}}
\newcommand{\neuralsat}{\texttt{NeuralSAT}}
\newcommand{\tool}{\texttt{NeuralSAT}}
\newcommand{\mipverify}{\texttt{MIPVerify}}
\newcommand{\crowndefault}{\texttt{$\alpha\beta$-CROWN} (default)}

\newcommand{\myrelu}{\mathrm{ReLU}}
\newcommand{\relu}[1]{\mathrm{ReLU}\left(#1\right)}
\newcommand{\sigmoid}[1]{\mathrm{sigmoid}\left(#1\right)}
\newcommand{\mytanh}[1]{\mathrm{tanh}\left(#1\right)}
\newcommand{\softmax}[1]{\mathrm{softmax}\left(#1\right)}

\newcommand{\sat}{\texttt{sat}}
\newcommand{\unsat}{\texttt{unsat}}

\newcommand{\code}[1]{\texttt{#1}}

\lstdefinelanguage{SMTLIB}{
    morekeywords={assert, declare-const, declare-pwl, or, and, },
    alsoletter={-},
    morecomment=[l];,
    morestring=[b]",
    morekeywords=[2]{Real, Int, ReLU},
    keywordstyle=[2]\color{codepurple},
}

\lstdefinestyle{SMTLIB-style}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{blue},
    numberstyle=\tiny\color{black},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false, 
    breaklines=true, 
    captionpos=b, 
    keepspaces=true, 
    numbers=left, 
    numbersep=5pt, 
    showspaces=false, 
    showstringspaces=false,
    showtabs=false, 
    tabsize=2,
}

% \lstset{
%     language=SMTLIB,
%     style=SMTLIB-style
% }


\begin{document}

\pagestyle{empty}


\begin{tikzpicture}[overlay,remember picture]

    % Background color
    \fill[
    black!2]
    (current page.south west) rectangle (current page.north east);
    
    % Rectangles
    \shade[
    left color=Dandelion, 
    right color=Dandelion!40,
    transform canvas ={rotate around ={45:($(current page.north west)+(0,-6)$)}}] 
    ($(current page.north west)+(0,-6)$) rectangle ++(9,1.5);
    
    \shade[
    left color=lightgray,
    right color=lightgray!50,
    rounded corners=0.75cm,
    transform canvas ={rotate around ={45:($(current page.north west)+(.5,-10)$)}}]
    ($(current page.north west)+(0.5,-10)$) rectangle ++(15,1.5);
    
    \shade[
    left color=lightgray,
    rounded corners=0.3cm,
    transform canvas ={rotate around ={45:($(current page.north west)+(.5,-10)$)}}] ($(current page.north west)+(1.5,-9.55)$) rectangle ++(7,.6);
    
    \shade[
    left color=orange!80,
    right color=orange!60,
    rounded corners=0.4cm,
    transform canvas ={rotate around ={45:($(current page.north)+(-1.5,-3)$)}}]
    ($(current page.north)+(-1.5,-3)$) rectangle ++(9,0.8);
    
    \shade[
    left color=red!80,
    right color=red!80,
    rounded corners=0.9cm,
    transform canvas ={rotate around ={45:($(current page.north)+(-3,-8)$)}}] ($(current page.north)+(-3,-8)$) rectangle ++(15,1.8);
    
    \shade[
    left color=orange,
    right color=Dandelion,
    rounded corners=0.9cm,
    transform canvas ={rotate around ={45:($(current page.north west)+(4,-15.5)$)}}]
    ($(current page.north west)+(4,-15.5)$) rectangle ++(30,1.8);
    
    \shade[
    left color=RoyalBlue,
    right color=Emerald,
    rounded corners=0.75cm,
    transform canvas ={rotate around ={45:($(current page.north west)+(13,-10)$)}}]
    ($(current page.north west)+(13,-10)$) rectangle ++(15,1.5);
    
    \shade[
    left color=ForestGreen,
    rounded corners=0.3cm,
    transform canvas ={rotate around ={45:($(current page.north west)+(18,-8)$)}}]
    ($(current page.north west)+(18,-8)$) rectangle ++(15,0.6);
    
    \shade[
    left color=ForestGreen,
    rounded corners=0.4cm,
    transform canvas ={rotate around ={45:($(current page.north west)+(19,-5.65)$)}}]
    ($(current page.north west)+(19,-5.65)$) rectangle ++(15,0.8);
    
    \shade[
    left color=OrangeRed,
    right color=red!80,
    rounded corners=0.6cm,
    transform canvas ={rotate around ={45:($(current page.north west)+(20,-9)$)}}] 
    ($(current page.north west)+(20,-9)$) rectangle ++(14,1.2);
    
 
    
    % Title
    \node[align=center] at ($(current page.center)+(0,-5)$) 
    {
        {\fontsize{24}{24} \selectfont {{Introduction to}}} \\[0.15in]
        {\fontsize{24}{24} \selectfont {{Deep Neural Network Verification}}} \\[1in]
        %{\fontsize{18}{18} \selectfont {{A Handbook for International Students}}} \\[1.in]

        {\fontsize{14}{19.2} \selectfont \textcolor{ForestGreen}{ \bf ThanhVu Nguyen}}\\[0.1in]
        {\fontsize{14}{19.2} \selectfont \textcolor{ForestGreen}{ \bf Hai Duong}}\\[0.1in]
    \today{} (latest version available on  \href{https://github.com/nguyenthanhvuh/book_nnv}{Github})
    };
    \end{tikzpicture}

    
\chapter*{Preface}

% \begin{mybox}
% This document will be updated regularly to reflect the latest information and updates in the admission process. Its latest version is available at

% \begin{center}
%   \href{https://nguyenthanhvuh.github.io/phd-cs-us/demystify.pdf}{nguyenthanhvuh.github.io/phd-cs-us/demystify.pdf},
% \end{center}

% \noindent and its \LaTeX{} source is also on \href{https://github.com/nguyenthanhvuh/phd-cs-us}{GitHub}. If you have questions or comments, feel free to create new \href{https://github.com/nguyenthanhvuh/phd-cs-us/issues}{GitHub issues} or \href{https://github.com/nguyenthanhvuh/phd-cs-us/discussions}{discussions}.

%\end{mybox}

\newpage
\tableofcontents




\newcommand{\proofnet}[1]{
\begin{tikzpicture}[scale=#1,every node/.style={scale=#1},->,semithick]
  % Styles


  % Nodes
  \node[input]  (x1) at (0,1) {$x_1$};
  \node[input]  (x2) at (0,-1) {$x_2$};

  \node[hidden] (v1) at (2.5,1) {$v_1$};
  \node[hidden] (v2) at (2.5,-1)   {$v_2$};
  \node[hidden] (v3) at (5,1) {$v_3$};
  \node[hidden] (v4) at (5,-1) {$v_4$};

  \node[output] (y1) at (7.5,1) {$y_1$};
  \node[output] (y2) at (7.5,-1) {$y_2$};

  % Edges with weights
  % x1 to hidden
  \draw (x1) -- (v1) node[midway,above] {$-0.5$};


  \draw (x1) -- (v2) node[near end,below] {$0.3$};

  % x2 to hidden
  \draw (x2) -- (v2) node[midway,below] {$0.2$};
  \draw (x2) -- (v1) node[near end,above] {$0.2$};
  

  % hidden layer connections
  \draw (v1) -- (v3) node[midway,above] {$-0.9$};

  \draw (v1) -- (v4) node[near end,below] {$0.6$};
  
  
  \draw (v2) -- (v4) node[midway,below] {$0.9$};
  \draw (v2) -- (v3) node[near end,above] {$0.6$};

  % hidden to outputs
  \draw (v3) -- (y1) node[midway,above] {$-0.1$};
  \draw (v3) -- (y2) node[near end,below] {$-0.3$};
  \draw (v4) -- (y1) node[near end,above] {$0.2$};
  \draw (v4) -- (y2) node[midway,below] {$0.5$};

  % biases
  \node[above] at (v1.north) {$-0.5$};  
  \node[above] at (v3.north) {$0.2$};  
  \node[above] at (y1.north) {$-0.4$};

  \node[below] at (v2.south) {$0.3$};
  \node[below] at (v4.south) {$-0.1$};
  \node[below] at (y2.south) {$-0.5$};

\end{tikzpicture}
}

\part{Basics of Neural Networks and Verification}
\chapter{Neural Networks}\label{chap:nn-basics}

\section{Basics of Neural Networks}
A \emph{neural network} (\textbf{NN})~\cite{Goodfellow-et-al-2016} consists of an input layer, multiple hidden layers, and an output layer. Each layer has a number of neurons, each connected to neurons in the next layer through a predefined set of weights (derived by training the network with data). A \emph{Deep Neural Network} (\textbf{DNN}) is an NN with \emph{two} or more hidden layers. 

%A deep neural network consists of three types of layers: an input layer, multiple hidden layers, and an output layer. Each layer consists of a number of neurons, each connected to neurons from another layers through a predefined set of weights (derived by training the network with data). A network is called a \emph{fully connected feed-forward} neural network (FNN) if it connects every neuron in a layer (i.e., all weights are non-zero) to a neuron in the next layer.

The output of an NN is obtained by iteratively computing  the  values  of  neurons  in  each  layer.
The value of a neuron in the input layer is the input data. 
The value of a neuron in the hidden layers is computed by applying an \emph{affine transformation} (\autoref{sec:affine}) to values of neurons in the previous layers, then followed by an \emph{activation function} (\autoref{sec:activation}) such as ReLU and Sigmoid. 
The value of a neuron in the output layer is computed similarly but may skip the activation function.

\paragraph{NN as a Function} We can view an NN as a function that maps input vectors to output vectors: 
\begin{equation}
f: \mathbb{R}^{n} \to \mathbb{R}^{m}
\end{equation}
where \(n\) is the number of input neurons and \(m\) is the number of output neurons. The neurons in the input layer are the inputs to the function, and the neurons in the output layer are the outputs of the function. The neurons in the hidden layers are also functions that transform the inputs from the previous layer to produce outputs for the next layer.

%\autoref{fig:dnn}b shows the same network but with each hidden neuron $x$ split into two neurons $x'$ and $x''$ representing the result of affine transformation on $x$ and ReLU activation on $x'$, respectively, e.g.,  $x_3'=-x_1-0.5x_2-1.0$ and  $x_3'' = ReLU(x_3')$. This ReLU-slitting representation is adopted by \tool{} and other DNN analyses (e.g., ~\cite{katz2017reluplex,wang2018efficient,henriksen2020efficient}) 
% including Reluplex~\cite{katz2017reluplex}, Neurify~\cite{wang2018efficient}, and VeriNet~\cite{henriksen2020efficient},
%because it does not change the semantics or complexity of the problem and is easier to reason about as we will show in \S\ref{sec:overview}.

% \section{The Basics}\label{sec:nn-basics}




% \paragraph{Graph Structure} A neural network (NN) can be viewed as a special kind of \emph{directed acyclic graph (DAG)} where each node represents a computation unit that receives inputs from its parent nodes and produces outputs for its child nodes. %Typically, neural networks are organized into layers, although more complex architectures may deviate from strict layer-wise organization (e.g., residual networks, attention models). 
% Overall, the NN defines a composite function \( f \) mapping vectors of real numbers to vectors of real numbers:
% \begin{align}
% f: \mathbb{R}^{n} \to \mathbb{R}^{m}
% \end{align}
% where $n, m$ are the dimensions of the input and output vectors, respectively.


% \begin{figure}[htp]
%     \centering
%     \begin{tikzpicture}[
%         every node/.style={draw, circle, minimum size=8mm, thick, font=\large, inner sep=0pt},
%         xnode/.style={draw=red!60!black, fill=red!15},
%         vnode/.style={draw=cyan!60!black, fill=cyan!40},
%         ynode/.style={draw=green!60!black, fill=green!15}
%       ]
%       % Nodes
%       \node[xnode]   (x) at (0,0)    {$x$};
%       \node[vnode]   (v) at (2.5,0)  {$v$};
%       \node[ynode]   (y) at (5,0)    {$y$};
%       % Arrows
%       \draw[->, thick] (x) -- (v);
%       \draw[->, thick] (v) -- (y);
%     \end{tikzpicture}
%     \caption{A simple neural network with 3 nodes.}
%     \label{fig:snn}
% \end{figure}

% \begin{example}\label{ex:nn3}
% \Cref{fig:snn} illustrates a simple neural network with three nodes:

% \begin{enumerate}
%     \item The \textbf{input node} \(x\) (red) simply receives the external input value \(r \in \mathbb{R}\) and passes it forward without any modification.

%     \item The \textbf{hidden node} \(v\) (cyan) applies a linear transformation:
%     \[
%     v = 2r + 1.
%     \]

%     \item The \textbf{output node} \(y\) (green) applies a non-linear activation function, in this case, the ReLU function:
%     \[
%     y = \relu{v} = \max(0, v).
%     \]
% \end{enumerate}

% Thus, the network defines the function \(f: \mathbb{R} \to \mathbb{R}\) given by:
% \begin{align}
% f(r) = \relu{2r + 1}.
% \end{align}
% \end{example}

\newcommand{\mydnn}[1]{
\begin{tikzpicture}[scale=#1, transform shape, semithick, ->]
    % Input nodes
    \node[input] (x1) at (0,1)  {$x_1$};
    \node[input] (x2) at (0,-1) {$x_2$};

    % Hidden layer
    \node[hidden] (x3) at (2.8,1) {$x_3$};
    \node[hidden] (x4) at (2.8,-1) {$x_4$};

    % Output layer node (centered horizontally)
    \node[output] (x5) at (5,0) {$x_5$};

    % Connections with weights
    \draw (x1) -- (x3) node[midway, above] {$-0.5$} ;
    \draw (x1) -- (x4) node[near end, below] {$0.5$} ;
    \draw (x2) -- (x3) node[near end, above] {$0.5$} ;
    \draw (x2) -- (x4) node[midway, below] {$-0.5$} ;
    \draw (x3) -- (x5) node[midway, below] {$-1.0$};
    \draw (x4) -- (x5) node[midway, below] {$1.0$};

    % Output weights under x3, x4, x5 (biases)
    \node[above] at (x3.north) {$+1.0$};
    \node[below] at (x4.south) {$-1.0$};
    \node[above] at (x5.north) {$-1.0$};
\end{tikzpicture}
}


\newcommand{\mydnntwo}[1]{
\begin{tikzpicture}[scale=#1, transform shape, semithick, ->]
    % Input nodes
    \node[input] (x1) at (0,1)  {$x_1$};
    \node[input] (x2) at (0,-1) {$x_2$};

    % Hidden layer
    \node[hidden] (x3) at (2.8,1) {$x_3$};
    \node[hidden] (x4) at (2.8,-1) {$x_4$};

    % Output layer node (centered horizontally)
    \node[output] (x5) at (5,1) {$x_5$};
    \node[output] (x6) at (5,-1) {$x_6$};

    % Connections with weights
    \draw (x1) -- (x3) node[midway, above] {$-0.7$} ;
    \draw (x1) -- (x4) node[near end, below] {$1.2$} ;
    \draw (x2) -- (x3) node[near end, above] {$0.3$} ;
    \draw (x2) -- (x4) node[midway, below] {$-0.5$} ;
    \draw (x3) -- (x5) node[midway, above] {$-2.0$};
    \draw (x4) -- (x5) node[near end, above] {$3.0$};
    \draw (x3) -- (x6) node[near end, below] {$-1.8$};
    \draw (x4) -- (x6) node[midway, below] {$0.7$};

    % Biases
    \node[above] at (x3.north) {$.8$};
    \node[below] at (x4.south) {$-2.0$};
    \node[above] at (x5.north) {$-1.2$};
    \node[below] at (x6.south) {$-.3$};
\end{tikzpicture}
}

\begin{figure}
    \centering
    \mydnn{1}
    \caption{\label{fig:dnn}A simple DNN with two inputs $x_1,x_2$, two hidden neurons $x_3,x_4$, and one output neuron $x_5$.}
\end{figure}

\begin{example}\label{ex:dnn}
\autoref{fig:dnn} shows an NN with two inputs $x_1, x_2 \in \mathbb{R}$, two hidden neurons \(x_3, x_4\) in one hidden layer, and one output neuron \(x_5\). The connections between the neurons are weighted edges, and the biases are shown below each neuron.


\begin{itemize}
    \item The hidden neurons compute:
    \[
    x_3 = \relu{-0.5 x_1 + 0.5 x_2 + 1.0},\quad x_4 = \relu{0.5 x_1 + -0.5 x_2 + -1.0},
    \]
    where $\relu{x} = \max(x, 0)$ is the ReLU activation function.
    \item The output neuron computes:
    \[
    x_5 = -1.0 \cdot x_3 + 1.0 \cdot x_4 - 1.0.
    \]
\end{itemize}

Thus, this NN computes a function \(f: \mathbb{R}^2 \to \mathbb{R}\) where:
\[
f(x_1, x_2) = -\relu{-0.5 x_1 + 0.5 x_2 + 1.0} + \relu{0.5x_1 -0.5 x_2 - 1.0} - 1.0.
\]
\end{example}


\section{Affine Transformation}\label{sec:affine}

The affine transformation (AF) of a neuron consists of a \emph{linear combination}---a weighted sum\footnote{A weighted sum is a sum of the form \( \sum_{i=1}^{n} w_i v_i \), where \(w_i\) are weights and \(v_i\) are variables or terms.}---of its inputs, followed by the addition of a bias term. More specifically, for a neuron with weights \(w_1, \dots, w_n\), bias \(b\), and inputs \(v_1, \dots, v_n\) from the previous layer, the AF computes:

\begin{equation}\label{eq:affine}   
    f(v_1, v_2, \dots,v_n) = \sum_{i=1}^{n} w_i v_i + b.
\end{equation}


\begin{example}
In~\autoref{fig:dnn}, neuron \(x_3\) receives inputs \(x_1\) and \(x_2\) with weights \(-0.5\), \(0.5\), and bias \(1.0\), so its AF is $x_3 = -0.5 x_1 + 0.5 x_2 + 1.0$.
\end{example}


% \paragraph{Matrix Form} AF can also be represented in matrix form.
% \begin{equation}
% f(v_1, v_2, \dots,v_n) = \begin{pmatrix}
% w_1 & w_2 & \cdots & w_n
% \end{pmatrix}
% \begin{pmatrix}
% v_1 \\
% v_2 \\
% \vdots \\
% v_n
% \end{pmatrix}
% +
% b,
% \end{equation}


% or equivalently,
% \begin{equation}
% f(\vec{v}) = W \vec{v} + b,
% \end{equation}
% where $W$ is the weight matrix, $\vec{x}$ is the input vector, and $b$ is the bias vector.


% The affine transformation can be expressed in matrix form as follows:

% \[
% \begin{pmatrix}
% x_3 \\
% x_4
% \end{pmatrix}
% =
% \begin{pmatrix}
% -0.5 & 0.5 \\
% 1.0 & 1.0
% \end{pmatrix}
% \begin{pmatrix}
% x_1 \\
% x_2
% \end{pmatrix}
% +
% \begin{pmatrix}
% 1.0 \\
% \end{pmatrix}
% =
% \begin{pmatrix}
% -0.5 & 0.5 \\
% 1.0 & 1.0
% \end{pmatrix}
% \begin{pmatrix}
% x_1 \\
% x_2
% \end{pmatrix}
% +
% \begin{pmatrix}
% 1.0 \\
% -1.0
% \end{pmatrix}
% \]

\section{Activation Functions}\label{sec:activation}
Popular activation functions used in NNs include ReLU, Sigmoid, Tanh, and Softmax. All of these are non-linear\footnote{Non-linear means that the output of the function is not a linear combination of its inputs.} functions that introduce non-linearity to the network, allowing it to learn complex patterns in the data.

\autoref{tab:activation} summarizes the most common activation functions used in NNs, their equations, output ranges, and key uses.

\begin{table}
  \centering
  \caption{Summary of Common Neural Network Activation Functions}\label{tab:activation}
  \small
  \begin{tabular}{llll}
    \toprule
    \textbf{Name} & \textbf{Equation} & \textbf{Output Range} & \textbf{Key Use} \\
    \midrule
    ReLU      & $ \max(0, x) $                   & $[0, \infty)$   & Hidden layers, fast train \\    
    Sigmoid   & $ \frac{1}{1 + e^{-x}} $         & $(0, 1)$        & Binary classification \\
    Tanh      & $ \tanh(x) $                     & $(-1, 1)$       & Hidden layers, zero-centered \\
    Softmax   & $ \frac{e^{x_i}}{\sum_j e^{x_j}} $& $(0, 1), \sum_i=1 $ & Multi-class output \\    
    % Leaky ReLU& $ \begin{cases} x & x>0 \\ \alpha x & x\leq 0 \end{cases} $ & $(-\infty, \infty)$ & Prevent dead neurons \\
    % Swish     & $ x \cdot \sigmoid{x} $  & $(-\infty, \infty)$ & Deep networks \\
    % ELU       & $ \begin{cases} x & x>0 \\ \alpha(e^{x}-1) & x\leq 0 \end{cases} $ & $(-\alpha, \infty)$ & Advanced networks \\
    \bottomrule
  \end{tabular}
\end{table}


\subsection{ReLU (Rectified Linear Unit)}\label{sec:relu}

ReLU is a widely used activation function in NNs. It is defined as:

\[
\relu{x} = \max(0, x) = 
\begin{cases}
0 & \text{if } x \leq 0 \\
x & \text{if } x > 0
\end{cases}
\]

ReLU is \textbf{piecewise linear} because it consists of two linear segments as shown as in~\autoref{fig:relu}: (i) a constant function ($0$) when $x \leq 0$, (ii) and (ii) a linear function ($x$) when $x > 0$.
A ReLU activated neuron is said to be \emph{active} if its input is greater than zero and \emph{inactive} otherwise.


\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=1.7in, height=1.7in,
            axis x line=middle, axis y line=middle,
            xlabel={}, ylabel={},
            axis equal,
            xtick={-4, -2, 0, 2, 4},
            ytick={0, 2, 4},
            xmin=-4.5, xmax=4.5, ymin=-0.5, ymax=4.5,
            enlargelimits=false,
            samples=2,
            domain=-4.5:4.5,
            axis line style={-latex},
            tick label style={font=\small},
            % yticklabel style={font=\small},
            % xticklabel style={font=\small},
            tick align=outside,
            minor tick num=0,
        ]
        % ReLU curve: flat at zero, then linear
        \addplot[line width=1.5pt, red!80!black, samples=2, domain=-4.5:0] {0};
        \addplot[line width=1.5pt, red!80!black, domain=0:4.5] {x};
      \end{axis}
    \end{tikzpicture}
    \caption{ReLU (Rectified Linear Unit) function.}\label{fig:relu}
\end{figure}

\begin{example}
$\relu{-1.2} = 0$ (inactive), $\relu{0} = 0$ (inactive), and $\relu{2.8} = 2.8$ (active).
\end{example}


\paragraph{Logical encoding} ReLU can be encoded using the following logical formula:
\[y = \relu{x} \iff (x \leq 0 \land y = 0) \lor (x > 0 \land y = x).\] 
In other words, if \(x \le 0\), \(y\) must be zero; otherwise; otherwise, \(y\) must equal \(x\).

\begin{example}
In Z3, we can declare ReLU using \texttt{If()}
\begin{lstlisting}[language=python]
    import z3
    def relu(x): return z3.If(x <= 0, 0, x)

    relu(-1.2)  # returns 0
    relu(0)     # returns 0
    relu(2.8)   # returns 2.8
\end{lstlisting}
\end{example}
\paragraph{Nonlinear Property} Despite being piecewise linear, ReLU is \textbf{nonlinear} because it does not satisfy the two core properties of a linear function

    \begin{itemize}
        \item \textit{Additivity:} $\text{ReLU}(x + y) \ne \text{ReLU}(x) + \text{ReLU}(y)$ in general,
        \item \textit{Homogeneity:} $\text{ReLU}(\alpha x) \ne \alpha \cdot \text{ReLU}(x)$ when $\alpha < 0$.
    \end{itemize}

In simpler terms, ReLU is nonlinear because it does not form a straight line.  It has a \textbf{kink} (a sharp bend) at $x = 0$, where the slope changes abruptly from $0$ to $1$. This discontinuity in the derivative prevents the function from being globally linear.


This non-linearity makes DNN verification difficult. In fact, verifying DNNs with ReLU has the $\mathsf{NP}$-complete complexity as shown in~\autoref{sec:complexity}. We will use ReLU throughout this book as the default activation function for hidden neurons in an NN.

\subsection{Sigmoid}\label{sec:sigmoid}



\begin{figure}[ht]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=1.7in, height=1.7in,
            axis x line=middle, axis y line=middle,
            xlabel={}, ylabel={},
            xtick={-4, -2, 0, 2, 4},
            ytick={0, 0.5, 1},
            xmin=-4.5, xmax=4.5, ymin=0, ymax=1.1,
            enlargelimits=false,
            samples=300,
            domain=-4.5:4.5,
            axis line style={-latex},
            tick label style={font=\small},
            % yticklabel style={font=\small},
            % xticklabel style={font=\small},
            tick align=outside,
            minor tick num=0,
        ]
        \addplot[line width=1.5pt, red!80!black, samples=300, domain=-4.5:4.5] {1/(1 + exp(-x))};
      \end{axis}
    \end{tikzpicture}
    \caption{Sigmoid function.}\label{fig:sigmoid}
\end{figure}

Sigmoid, shown in~\autoref{fig:sigmoid}, is a smooth---i.e., continuous and differentiable---non-linear activation function that maps any real value to the range (0,1).
It is continuous, meaning that small changes in the input will result in small changes in the output, and differentiable, meaning that it has a well-defined derivative at every point. Sigmoid is often used in the output layer of a binary classification problem.

    \begin{align}
        \sigmoid{x} = \frac{1}{1+e^{-x}}
    \end{align}

\begin{example}
$\sigmoid{-1.2} \approx 0.23$, $\sigmoid{0} = 0.5$, and $\sigmoid{2.8} \approx 0.94$. This means that the sigmoid function maps -1.2 to a value close to 0, 0 to 0.5, and 2.8 to a value close to 1.
\end{example}

\subsection{Hyperbolic Tangent (Tanh)}\label{sec:tanh}

Tanh, shown in~\autoref{fig:tanh}, is similar to sigmoid (\autoref{sec:sigmoid})  but maps any real value to the range (-1,1). It is often used in the output layer of a multi-class classification problem.

\begin{figure}[htp]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=1.7in, height=1.7in,
            axis x line=middle, axis y line=middle,
            xlabel={}, ylabel={},
            xtick={-4, -2, 0, 2, 4},
            ytick={-1, 0, 1},
            xmin=-4.5, xmax=4.5, ymin=-1.2, ymax=1.2,
            enlargelimits=false,
            samples=300,
            domain=-4.5:4.5,
            axis line style={-latex},
            tick label style={font=\small},
            tick align=outside,
            minor tick num=0,
        ]
        % tanh curve
        \addplot[line width=1.5pt, red!80!black, samples=300, domain=-4.5:4.5] {tanh(x)};
        % 0.0 label at origin, slightly offset
      \end{axis}
    \end{tikzpicture}
    \caption{tanh (hyperbolic tangent) activation function.}\label{fig:tanh}
\end{figure}

\begin{align}
\tanh(x) = \frac{e^x-e^{-x}}{e^x+e^{-x}}
\end{align}

\begin{example}
$\tanh(-1.2) \approx -0.83$, $\tanh(0) = 0$, and $\tanh(2.8) \approx 0.99$. This means that the tanh function maps -1.2 to a value close to -1, 0 to 0, and 2.8 to a value close to 1.
\end{example}

\subsection{Softmax}\label{sec:softmax}


\begin{figure}[htp]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=1.7in, height=1.7in,
            axis x line=middle, axis y line=middle,
            % axis equal,
            xlabel={}, ylabel={},
            xtick={-4, -2, 0, 2, 4},
            ytick={0, 0.5, 1},
            xmin=-4.5, xmax=4.5, ymin=-0.1, ymax=1.1,
            enlargelimits=false,
            samples=200,
            domain=-4.5:4.5,
            axis line style={-latex},
            tick label style={font=\small},
            tick align=outside,
            minor tick num=0,
            legend style={at={(0.5,1.03)},anchor=south,legend columns=2,draw=none, font=\footnotesize},
        ]
        % softmax_1 curve
        \addplot[line width=1.5pt, red!80!black, domain=-4.5:4.5] {exp(x)/(exp(x)+1)};
        % softmax_2 curve
        \addplot[line width=1.5pt, blue!80!black, domain=-4.5:4.5, dashed] {1/(exp(x)+1)};
        % Add legends
        \addlegendentry{$\mathrm{softmax}_1(x)$}
        \addlegendentry{$\mathrm{softmax}_2(x)$}
      \end{axis}
    \end{tikzpicture}
    \caption{Softmax function for 2 classes.}\label{fig:softmax}
\end{figure}


Softmax, shown in~\autoref{fig:softmax}, is a generalization of sigmoid (\autoref{sec:sigmoid}) that maps any real value to the range (0,1) and ensures that the sum of the output values is 1. It is often used in the output layer of a multi-class classification problem.
\begin{align}
\softmax{x}_i = \frac{e^{x_i}}{\sum_{j=1}^{n}e^{x_j}}
\end{align}

\begin{example}
For a vector $x = [2, 1, 0]$, softmax computes: 

{\small
\begin{align*}
\softmax{x} &= \left[\frac{e^2}{e^2+e^1+e^0}, \frac{e^1}{e^2+e^1+e^0}, \frac{e^0}{e^2+e^1+e^0}\right] \\
&= \left[\frac{7.389}{7.389+2.718+1}, \frac{2.718}{7.389+2.718+1}, \frac{1}{7.389+2.718+1}\right] \\
&\approx [0.71, 0.24, 0.05]
\end{align*}
}

This means that softmax maps the input vector $x$ to a probability distribution over the three classes, where the first class has a probability of 0.71, the second class has a probability of 0.24, and the third class has a probability of 0.05.
\end{example}

\begin{example}\label{ex:z3-dnn}
Use Z3 to encode the DNN in~\autoref{fig:dnn} and compute its output $x5$ for the input $(x_1, x_2) = (2.0, 0.5)$.

\begin{lstlisting}[language=python]
    import z3

    #setup the network
    x1 = z3.Real(`x1')
    x2 = z3.Real(`x2')
    x3 = -0.5*x1 + 0.5*x2 + 1.0    
    x3_ = z3.If(x3 <= 0, 0, x3)  # ReLU
    x4 = 0.5*x1 + -0.5*x2 + -1.0
    x4_ = z3.If(x4 <= 0, 0, x4)  # ReLU
    x5 = -1.0*x3_ + 1.0*x4_ - 1.0
    
    #check output on given input
    s = z3.Solver()
    s.add(x1 == 2.0, x2 == 0.5)
    if s.check() == z3.sat:
        m = s.model()
        print("Output x5 is ", m.evaluate(x5))
\end{lstlisting} 
\end{example}

\section{Neural Network Architectures and Layers}

NNs vary in architecture depending on how information flows through them and how computations are structured. Most common models are variations of the \emph{feedforward network}, with additional structures or constraints layered on top. ~\autoref{tab:nn-types} summarizes several common NN architectures and their typical application domains.


\begin{table}[ht]
\caption{Popular NN Architectures and Applications}\label{tab:nn-types}
\centering
\small
\begin{tabular}{llp{8cm}@{}}
\toprule
\textbf{Name} & \textbf{Acronym} & \textbf{Typical Applications} \\
\midrule
Feedforward NN & FNN / MLP & General function approximation, tabular data \\
Convolutional NN & CNN & Image processing, video analysis \\
Residual NN & ResNet & Deep image recognition, medical imaging \\
Recurrent NN & RNN & Sequence modeling, NLP, time series \\
Transformer & -- & NLP, summarization, code generation, vision \\
Graph NN & GNN & Graph-structured data, molecule modeling, recommendation \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Feedforward Neural Networks (FNNs)}\label{sec:ffn}

In an FNN, information flows in one direction: from the input layer, through one or more hidden layers, and finally to the output layer. There are no loops or cycles in the computation graph. 

Widely used feedforward architectures include fully connected, convolutional, and residual networks. Each architecture has its own strengths and is suited for different types of tasks.

\paragraph{Fully Connected NNs (FCNs)}

In FCNs, each neuron in a layer is connected to every neuron in the next layer. Thus, every neuron in the input layer is connected to every neuron in the first hidden layer, every neuron in the first hidden layer is connected to every neuron in the second hidden layer, and so on, until the output layer. Fully connected NNs, sometimes called \emph{dense networks}, are the most basic type of FNNs and are commonly used for tasks like classification. 

\begin{example}
\autoref{fig:dnn} earlier is an FCN with two inputs and one hidden layer with two neurons, and one output neuron.~\autoref{fig:ffn} below shows an FCN with four inputs, two hidden layers with five neurons each, and three output neurons (weights and biases not shown for simplicity).

\begin{figure}[htp]
    \centering
    \begin{tikzpicture}[scale=0.8, transform shape]
        % Input Layer
        \node at (0,4) {\textbf{Input Layer}};
        \foreach \x in {1,2,3,4} {
            \node[circle, draw=black, fill=white, minimum size=0.6cm] (I\x) at (0,4-\x) {};
        }

        % Hidden Layer 1
        \node at (3,4) {\textbf{Hidden Layer 1}};
        \foreach \x in {1,2,3,4,5} {
            \node[circle, draw=black, fill=white, minimum size=0.6cm] (H1\x) at (3,4.5-\x) {};
        }

        % Hidden Layer 2
        \node at (6,4) {\textbf{Hidden Layer 2}};
        \foreach \x in {1,2,3,4,5} {
            \node[circle, draw=black, fill=white, minimum size=0.6cm] (H2\x) at (6,4.5-\x) {};
        }

        % Output Layer
        \node at (9,4) {\textbf{Output Layer}};
        \foreach \x in {1,2,3} {
            \node[circle, draw=black, fill=white, minimum size=0.6cm] (O\x) at (9,3.5-\x) {};
        }

        % Connections
        \foreach \i in {1,2,3,4}
            \foreach \j in {1,2,3,4,5}
                \draw[->] (I\i) -- (H1\j);

        \foreach \i in {1,2,3,4,5}
            \foreach \j in {1,2,3,4,5}
                \draw[->] (H1\i) -- (H2\j);

        \foreach \i in {1,2,3,4,5}
            \foreach \j in {1,2,3}
                \draw[->] (H2\i) -- (O\j);
    \end{tikzpicture}
    \caption{A fully connected NN with two hidden layers.}
    \label{fig:ffn}
\end{figure}
\end{example}


\begin{example}[Classifier]
A common use case for FCNs is classification. They take an input, e.g., pixels of an image, and predict what the image is (e.g., cat, dog, car). The output layer represents the probabilities of each class (e.g., $y_1$ is the probability of cat, $y_2$ is the probability of dog). Moreover, the outputs are often passed through a softmax activation function (\autoref{sec:softmax}) to convert them into probabilities that sum to 1, and the class with the highest probability is chosen as the predicted label.

\end{example}

\paragraph{Convolutional NNs (CNNs)} CNNs replace fully connected layers with \emph{convolutional layers}, which apply local filters across the input space. In CNNs, each neuron receives several inputs, takes a weighted sum over them, passes it through an activation function, and responds with an output.  CNNs are commonly used in computer vision and image processing. Despite their local structure, CNNs remain feedforward: data flows forward without cycles.



\begin{figure}[htp]
    \centering
    \begin{tikzpicture}[scale=0.8, transform shape]
    % Parameters
    \def\inpN{4}
    \def\hidN{3}
    \def\outN{3}
    \def\dy{1.5}
    \def\xInput{0}
    \def\xHidden{3.2}
    \def\xOutput{6.4}

    % Input nodes
    \foreach \i [evaluate=\i as \lbl using int(\i)] in {1,...,4} {
        \node[circle, draw, fill=white, minimum size=0.4in, label=center:{$x_{\lbl}$}] 
            (I\i) at (\xInput, {(4-1)*0.5*\dy - (\i-1)*\dy}) {};
    }

    % Hidden nodes
    \node[circle, draw, fill=white, minimum size=0.4in, label=center:{$h_1$}] at (\xHidden, {1.5}) (H1) {};
    \node[above=0.1cm of H1] (B1) {$0.5$};
    \node[circle, draw, fill=white, minimum size=0.4in, label=center:{$h_2$}] at (\xHidden, {0}) (H2) {};
    % \node[above=0.2cm of H2] (B2) {$b=0.5$};
    \node[circle, draw, fill=white, minimum size=0.4in, label=center:{$h_3$}] at (\xHidden, {-1.5}) (H3) {};
    % \node[above=0.2cm of H3] (B3) {$b=0.5$};

    % Output nodes
    \node[circle, draw, fill=white, minimum size=0.4in, label=center:{$y_1$}] at (\xOutput, {1.5}) (O1) {};
    \node[above=0.1cm of O1] (B1) {$-1$};
    \node[circle, draw, fill=white, minimum size=0.4in, label=center:{$y_2$}] at (\xOutput, {0}) (O2) {};
    \node[circle, draw, fill=white, minimum size=0.4in, label=center:{$y_3$}] at (\xOutput, {-1.5}) (O3) {};

    % Connections: Input to Hidden (with weight labels spaced to avoid overlap)
    \draw[->, thick] (I1) -- node[above=2pt, midway, xshift=-2pt, yshift=1pt] {$2$} (H1);
    \draw[->, thick] (I2) -- node[below=1pt, midway, xshift=2pt] {$-1$} (H1);
    \draw[->, thick] (I2) -- (H2);
    \draw[->, thick] (I3) -- (H2);
    \draw[->, thick] (I3) -- (H3);
    \draw[->, thick] (I4) -- (H3);

    % Hidden to Output, one to one
    \draw[->, thick] (H1) -- node[above=2pt, midway] {$1$} (O1);
    \draw[->, thick] (H2) -- (O2);
    \draw[->, thick] (H3) -- (O3);

    \end{tikzpicture}
    \caption{1-dimensional CNN}\label{fig:cnn}
\end{figure}

\begin{example}
   ~\autoref{fig:cnn} shows a simple CNN with four inputs, three hidden neurons, and three outputs. %The first hidden neuron computes a weighted sum of its inputs, applies the ReLU activation function, and produces an output. The second and third hidden neurons compute their outputs similarly. The outputs are computed by taking the outputs of the hidden neurons and applying a linear transformation (without activation) to produce the final output values.
Given an input vector $\mathbf{x} = [x_1, x_2, x_3, x_4]$, the computation of the first output proceeds as follows. 
The first hidden unit forms a linear combination of its inputs as $h_1 = 2x_1 - x_2 + 0.5$. 
This value is then passed through the ReLU activation function, resulting in $\hat{h}_1 = \mathrm{ReLU}(h_1) = \max(0, 2x_1 - x_2 + 0.5)$. 
Finally, the first output is simply $y_1 = \hat{h}_1 - 1$.


\end{example}

\paragraph{Residual Networks (ResNets)} Resnets extend FNNs by adding \emph{skip connections}â€”direct links that bypass one or more layers. Resnets are often used in image recognition and classification. 

\begin{example}
\begin{figure}[htp]
    \centering
    \begin{tikzpicture}[scale=0.8, transform shape]
    % Horizontal node positions with labels
    \node[circle, draw=black, thick, minimum size=0.4in, fill=white, label=center:{$x$}] (H1) at (0,0) {};
    \node[circle, draw=black, thick, minimum size=0.4in, fill=white, label=center:{$h_1$}] (H2) at (2.5,0) {};
    \node[circle, draw=black, thick, minimum size=0.4in, fill=white, label=center:{$h_2$}] (H3) at (5,0) {};
    \node[circle, draw=black, thick, minimum size=0.4in, fill=white, label=center:{$h_3$}] (H4) at (7.5,0) {};
    \node[circle, draw=black, thick, minimum size=0.4in, fill=white, label=center:{$y$}] (H5) at (10,0) {};

    % Layer labels
    \node at (0,2.0) {\textbf{Input}};
    \node at (5.0,2.0) {\textbf{Hidden Layers}};
    \node at (10.0,2.0) {\textbf{Output}};

    % Biases above all except input node
    \node[above=0.18cm of H2] {$1$};    % bias for h1
    \node[above=0.18cm of H3] {$-1$}; % bias for h2
    \node[above=0.18cm of H4] {$0.5$};  % bias for h3
    \node[above=0.18cm of H5] {$2$};    % bias for y

    % Main arrows with weights
    \draw[->, thick] (H1) -- node[above, midway] {$1$} (H2);
    \draw[->, thick] (H2) -- node[above, midway] {$2$} (H3);
    \draw[->, thick] (H3) -- node[above, midway] {$-1$} (H4);
    \draw[->, thick] (H4) -- node[above, midway] {$0.5$} (H5);

    % Residual (skip) connections with weights
    \draw[->, thick] (H1) to[out=60,in=120] node[above, pos=0.4] {$1$} (H3);
    \draw[->, thick] (H3) to[out=60,in=120] node[above, pos=0.4] {$1$} (H5);

    \end{tikzpicture}
    \caption{ResNet block with weights on all connections and biases above nodes. Each node is labeled and typical ReLU is applied after each hidden sum.}\label{fig:resnet}
\end{figure}


\autoref{fig:resnet}  shows an example of a Resnet.
Assume the input $x$ and each node applies the ReLU activation. With the weights and biases shown in the diagram, the outputs are computed as follows:

\[
\begin{aligned}
    h_1 = \relu{x + 1} &\quad h_2 = \relu{2h_1 + x - 1} \\
    h_3 = \relu{-h_2 + 0.5} &\quad y  = 0.5h_3 + h_2 + 2
\end{aligned}
\]

\end{example}

% \subsubsection*{Common Layer Types}

% Feedforward networks, including CNNs and ResNets, are built from layers such as:

% \begin{itemize}
%     \item \textbf{Fully Connected (Dense) Layers}: Every neuron is connected to every neuron in the next layer.
%     \item \textbf{Convolutional Layers}: Local filters scan over inputs to extract spatial features.
%     \item \textbf{Residual (Skip) Connections}: Enable shortcut paths from earlier to later layers.
% \end{itemize}

\subsection{Other NN Architectures}

Not all NNs are feedforward. 
Some architectures introduce cycles, dynamic connections, or non-Euclidean\footnote{Euclidean data refers to data that can be represented in a flat, two-dimensional space, such as images.} data structures (e.g., graphs).

\subsubsection{Recurrent Neural Networks (RNNs)} RNNs, often used in natural language processing (NLP) and speech recognition, are designed to recognize patterns in sequences of data. RNNs have \emph{loops} in them, allowing information to be sent forward and backward.


\begin{figure}[h]
    \begin{center}
\begin{tikzpicture}[scale=0.5, transform shape]
% --- Rolled RNN (left diagram) ---
\begin{scope}
% Layer labels
\node at (0,1.5) {\textbf{Input}};
\node at (2.4,1.5) {\textbf{Hidden}};
\node at (4.8,1.5) {\textbf{Output}};
% Nodes
\node[circle, draw=black, fill=white, thick, minimum size=0.4in, label=center:{$x_t$}] (RI) at (0,0) {};
\node[circle, draw=black, fill=white, thick, minimum size=0.4in, label=center:{$h_t$}] (RH) at (2.4,0) {};
\node[circle, draw=black, fill=white, thick, minimum size=0.4in, label=center:{$y_t$}] (RO) at (4.8,0) {};
% Bias above nodes
\node[above=0.16cm of RH] {$0.5$};
\node[above=0.16cm of RO] {$-0.5$};
% Main arrows with weights
\draw[->, thick] (RI) -- node[above, pos=0.5] {$2$} (RH);
\draw[->, thick] (RH) -- node[above, pos=0.5] {$1$} (RO);
% Recurrent/self-loop at hidden node with recurrent weight
\draw [->, thick] (RH) edge [out=-120,in=-60,looseness=8] node[below, yshift=-2pt, xshift=10pt] {$-1$} (RH);
% Caption
\node[align=center] at (2.4,-2.7) {RNN cell};
\end{scope}



% --- Unrolled RNN (right diagram) ---
\begin{scope}[xshift=8cm]
% Parameters for vertical node spacing
\def\inpN{4}
\def\hidN{4}
\def\outN{4}
\def\dy{2.0}
\def\xInput{0}
\def\xHidden{3.2}
\def\xOutput{6.4}
% Layer labels
\node at (\xInput,{\inpN/2*\dy+0.8}) {\textbf{Input}};
\node at (\xHidden,{\inpN/2*\dy+0.8}) {\textbf{Hidden}};
\node at (\xOutput,{\inpN/2*\dy+0.8}) {\textbf{Output}};
% Input nodes (left column)
\foreach \i in {1,...,\inpN} {
    \node[circle, draw=black, fill=white, minimum size=0.4in, label=center:{$x_{\i}$}] (I\i) at (\xInput, {(\inpN-1)*0.5*\dy - (\i-1)*\dy}) {};
}
% Hidden nodes (centered) (as many as input)
\foreach \i in {1,...,\hidN} {
    \node[circle, draw=black, fill=white, minimum size=0.4in, label=center:{$h_{\i}$}] (H\i) at (\xHidden, {(\hidN-1)*0.5*\dy - (\i-1)*\dy}) {};
    \node[above right=0 of H\i] {$0.5$}; % Bias above each hidden
}
% Output nodes (centered) (as many as input)
\foreach \i in {1,...,\outN} {
    \node[circle, draw=black, fill=white, minimum size=0.4in, label=center:{$y_{\i}$}] (O\i) at (\xOutput, {(\outN-1)*0.5*\dy - (\i-1)*\dy}) {};
    \node[above=0.16cm of O\i] {$-0.5$}; % Bias above each output
}
% RNN input-to-hidden (1-to-1, with weight)
\foreach \i in {1,...,4} {
    \draw[->, thick] (I\i) -- node[above, pos=0.5, yshift=2pt] {$2$} (H\i);
}
% Hidden-to-hidden (recurrent arrows, with weight)
\foreach \i [evaluate={\j=int(\i+1);}] in {1,2,3} {
    \draw[->, thick] ([xshift=4pt]H\i) -- node[above left, pos=0.5, yshift=2pt] {$-1$} ([xshift=-4pt]H\j);
}
% Hidden-to-output (1-to-1, with weight)
\foreach \i in {1,...,4} {
    \draw[->, thick] (H\i) -- node[above, pos=0.5, yshift=2pt] {$1$} (O\i);
}
% Caption
\node[align=center] at (3.2,-4.0) {Unrolled RNN};
\end{scope}
\end{tikzpicture}
\end{center}
\caption{RNN cell (left) and unrolled RNN sequence structure (right). 
Weights on connections; biases above hidden and output nodes.}
\label{fig:rnn}
\end{figure}

\begin{example}
\autoref{fig:rnn} shows a simple RNN cell. Assume the input sequence is $\mathbf{x} = [x_1, x_2, x_3, x_4]$, and the initial hidden state is $h_0$. 
For the first time step, the hidden state is computed as $h_1 = \relu{2x_1 - h_0 + 0.5}$, and the output is $y_1 = h_1 - 0.5$. 
For the second time step, the hidden state is $h_2 = \relu{2x_2 - h_1 + 0.5}$, and the output is $y_2 = h_2 - 0.5$.
% For the third time step, the hidden state is $h_3 = ReLU(2x_3 - h_2 + 0.5)$, and the output is $y_3 = h_3 - 0.5$.
% For the fourth time step, the hidden state is $h_4 = ReLU(2x_4 - h_3 + 0.5)$, and the output is $y_4 = h_4 - 0.5$.

\end{example}

\subsubsection{Transformers} Transformers are designed for long-range dependencies using \emph{self-attention} rather than recurrence. They dominate applications in natural language processing and are increasingly used in vision and reinforcement learning.

\subsubsection{Graph Neural Networks (GNNs)} operate on graphs, allowing each node to aggregate information from its neighbors. GNNs are used in applications involving structured data like molecules or social networks.



\section{ONNX: Modelling Neural Networks}\label{sec:onnx}

\textbf{ONNX} (Open Neural Network Exchange)~\cite{onnx} is an open source and widely adopted standard for representing neural networks. It provides a common format for representing the structure and parameters of neural networks, enabling interoperability between different ML frameworks and tools.

%\paragraph{Supported ONNX Operators} VNN-LIB supports a subset of ONNX operators that cover most sequential feedforward networks used in NN verification. These operators include:


ONNX operators that cover most sequential feedforward networks include: 
\begin{itemize}
    \item \texttt{Add, Sub, Gemm, MatMul}: basic arithmetic and matrix operations.
    \item \texttt{ReLU, Sigmoid, SoftMax}: activation functions.
    \item \texttt{AveragePool, MaxPool, Flatten, Reshape}: tensor manipulation.
    \item \texttt{Conv, BatchNormalization, LRN}: CNN layers and normalizations.
    \item \texttt{Concat, Dropout, Unsqueeze}: tensor operations.
\end{itemize}

%\textbf{Note:} Preprocessing (e.g., normalization) should not be included in the model itself to keep property alignment clear.

\begin{example} For the network in~\autoref{fig:dnn}, the ONNX representation would include:
\begin{itemize}
    \item Input: $x_1, x_2$.
    \item Hidden layer: $x_3 = \relu{-0.5x_1 + 0.5x_2 + 1.0}$, $x_4 = \relu{0.5x_1 - 0.5x_2 + 1.0}$.
    \item Output: $x_5 = -x_3 + x_4 - 1$.
\end{itemize} 
The ONNX representation would look like:

%\tvn{check for accuracy, I make it very small just to illustrate what ONNX looks like}
\begin{lstlisting}
ir_version: 9
opset_import { version: 13 }
graph example_nn {
  input: "x"
  output: "x5"

  node { op_type: "Gemm" input: "x" input: "W1" input: "b1" output: "h1" }   # -0.5*x1+0.5*x2+1
  node { op_type: "Relu" input: "h1" output: "x3" }

  node { op_type: "Gemm" input: "x" input: "W2" input: "b2" output: "h2" }   # 0.5*x1-0.5*x2+1
  node { op_type: "Relu" input: "h2" output: "x4" }

  node { op_type: "Neg" input: "x3" output: "nx3" }
  node { op_type: "Add" input: "nx3" input: "x4" output: "s1" }
  node { op_type: "Add" input: "s1" input: "c_minus_1" output: "x5" }

  initializer { name: "W1" values: [-0.5, 0.5] }
  initializer { name: "b1" values: [1.0] }
  initializer { name: "W2" values: [0.5, -0.5] }
  initializer { name: "b2" values: [1.0] }
  initializer { name: "c_minus_1" values: [-1.0] }
}
\end{lstlisting}
\end{example}



\chapter{Properties}\label{chap:properties}

Similar to software programs, neural networks (NNs) have desirable properties to ensure the network behaves as expected. These could be specific to the applications modeled by the network, e.g., safety properties for a network modelling a collision avoidance system, or general properties that are desired by all networks, e.g., robustness to small perturbations in the input data.

Below we will discuss properties that are relevant to the verification of NNs. Specifically, these properties can be 
expressed in a formal language supported by a DNN verifier. Additional properties can be found in the literature~\cite{seshia2018formal}.

\section{Definition}\label{sec:properties-def}

As described in~\autoref{chap:nn-basics} NNs define functions of the form $f: \mathbb{R}^{n} \to \mathbb{R}^{m}$, 
where $n$ is the dimension of the input and $m$ is the dimension of the output. Thus, the properties or specifications of an NN---similarly to properties of software program---are defined in terms of its input and output:

\begin{quote}
\textit{For any input $x \in \mathbb{R}^{n}$ satisfying a precondition $P$, the neural network should produce an output $f(x) \in \mathbb{R}^{m}$ that satisfies a postcondition $Q$.}
\end{quote}

This says that if the input $x$ satisfies the precondition $P$, then the output $f(x)$ should satisfy the postcondition $Q$.



\section{Common Properties in Neural Networks}

We now define some commonly studied properties in NNs verification.

\subsection{Robustness}\label{sec:properties-robustness}

\textbf{Robustness} ensures that small changes in the input do not drastically change the output. This is a desirable property for all neural networks, especially classifiers, where we want to ensure that similar inputs yield similar outputs. For example, a slightly blurred image of a red light should still be classified as a red light.

There are two types of robustness properties: \emph{local} (robustness around a chosen point) and  \emph{global} (robustness everywhere).




\paragraph{Local Robustness}
A neural network $f$ is $\epsilon$-locally-robust at point $x$ with respect to norm $\| \cdot \|$ if 
\begin{equation}
    \forall x', \qquad \|x-x'\| \leq \epsilon \implies f(x) = f(x').
\end{equation}
where $\|x - x'\| \leq \epsilon$ indicates that the difference between the two points is within a certain (small) threshold $\epsilon$.


Thus local robustness says that a network is robust if all nearby inputs $x'$ (within radius $\epsilon$) are classified the same as $x$. In other words, no small perturbation around this specific point $x$ will fool the classifier."

Local robustness is what most adversarial robustness papers mean, e.g., checking whether an image of a cat is still classified as a cat under small pixel noise.

\begin{example}[Local Robustness: Image Classification]
Consider a neural network $f$ that classifies images into different categories (e.g., dog, cat, etc.). A robustness property requires that if an input image $c$ is classified as a dog, then any perturbed image $x$ that is visually similar to $c$ should also be classified as a dog. This can be expressed as:

\[
\forall x, \qquad \|c - x\| \leq \epsilon \implies f(x) = f(c)
\]

\end{example}



\paragraph{Global Robustness}

A neural network $f$ is $\epsilon$-globally-robust with respect to norm $\| \cdot \|$ if 
\begin{equation}
    \forall x_1, x_2, \qquad \|x_1 - x_2\| \leq \epsilon \implies f(x_1) = f(x_2).
\end{equation}

 This says the property must hold for all pairs of inputs in the domain: whenever two points are within $\epsilon$ of each other, they must share the same label.
 
Global robustness is a very strong definition, and in practice, almost impossible unless the network is trivial (e.g., outputs the same label everywhere).



\begin{problem}
Suppose that an network classifies an input image $x$ as digit 7. 
We want to ensure that if the image is slightly perturbed (e.g., brightness changed by a small amount $\epsilon$), 
the network still outputs 7.

\begin{solution}
\[
\forall x', \quad \|x - x'\| \leq \epsilon \implies f(x') = f(x) = 7
\]
\end{solution}
\end{problem}






\subsection{Safety}\label{sec:properties-safety}


\textbf{Safety} properties ensure that the network conforms to certain safety constraints. This is particularly important in safety-critical applications, such as autonomous vehicles or medical diagnosis systems, where incorrect outputs can lead to catastrophic consequences. %For example, in a self-driving car, we want to ensure that the car maintains a safe distance from other vehicles and pedestrians under all scenarios.

\begin{problem}[Collision Avoidance System]\label{ex:collision-safety}
    A safety property in a collision avoidance system such as an autonomous vehicle might be that if the intruder is distant and significantly slower than us, then we stay below a certain velocity threshold. Formally, this can be expressed as:
\[
d_{intruder} > d_{threshold} \land v_{intruder} < v_{threshold} \implies v_{us} < v_{threshold},
\]
where $d_{intruder}$ is the distance to the intruder, $d_{threshold}$ is a predefined safe distance, $v_{intruder}$ is the speed of the intruder, and $v_{us}$ is our speed.
\end{problem}


Unlike robustness properties, which are often desirable in all networks, safety properties are often \emph{specific} to the application domain. For example, a safety property for an autonomous vehicle may not be relevant for a surgical robot.



\begin{problem}[Safety: Self-Driving Car]\label{problem:safety}
A network controlling a self-driving car on a highway might require that:  
If the car in front is at least 160 meters away  and moving slower than us, 
then we should not accelerate.

\begin{solution}
\[
d \geq 160 \land v_{\text{front}} < v_{\text{us}} \implies a_{\text{us}} \leq 0
\]
\end{solution}
\end{problem}

\section{Other properties}\label{sec:other-properties}

\subsection{Consistency}

\textbf{Consistency} requires that a NN behaves consistently when given semantically equivalent or related inputs.

\begin{example}[Logical Consistency in LLMs] Consider queries $q_1$, $q_2$, and $q_3$ about a person's age:
\[
q_1: \texttt{``How old is person X?''}
\]
\[
q_2: \texttt{``What year was X born if they are currently Y years old?''}
\]
\[
q_3: \texttt{``Will X be Z years old in 2025?''}
\]
Thus, if the LLM outputs age $Y$ for $q_1$, then $q_2$ should output $\texttt{current\_year} - Y$, and the answer to $q_3$ should be logically consistent with the stated age. This prevents scenarios where an LLM claims someone is 30 years old but was born in 1985 when the current year is 2024.
\end{example}


% \paragraph{Example: Object Position Consistency.}
% Consider a neural network tracking the position of objects in a video frame. It should not report that an object is on the left in one frame and then immediately claim it is on the right in the next frame.

% \paragraph{Formal Specification:}
% \[
% \{ \text{frame } t, \text{ frame } t+1 \}
% \quad r_1 \gets f(x_t), \quad r_2 \gets f(x_{t+1})
% \quad \{ \text{consistent}(r_1, r_2) \}
% \]

\subsection{Monotonicity}

\textbf{Monotonicity} ensures that the NN maintains a consistent ordering relationship between inputs and outputs: an increase in certain input features always leads to a non-decreasing output value. This property is important in applications where domain knowledge dictates logical ordering constraints, such as fairness-aware systems, medical diagnosis, and scientific applications where physical laws impose natural ordering relationships.

\begin{example}[Fairness]
    A network modelling the probability of admission to a university should be monotonically non-decreasing with respect to GPA and test scores, regardless of gender. Formally, for applicants with profiles $(p, s, g)$ and $(p', s', g')$ where $p, p'$ are GPAs, $s, s'$ are test scores, and $g, g'$ are gender indicators:
\[
p \leq p' \land s = s' \land g \neq g' \implies f(p, s, g) \leq f(p', s', g'),
\]
\[
s \leq s' \land p = p' \land g \neq g' \implies f(p, s, g) \leq f(p, s', g'),
\]
where $f$ is the neural network computing admission probability. Additionally, for fairness:
\[
f(p, s, \text{male}) = f(p, s, \text{female}) \text{ for all } p, s,
\]
ensuring that applicants with identical academic qualifications receive the same treatment regardless of gender.
\end{example}



\section{Counterexamples}\label{sec:properties-counterexamples}

A \emph{counterexample} (\textbf{cex}) is a witness that falsifies the correctness property. Given the property defined in~\autoref{sec:properties-def}, a counterexample is an input $x$ that satisfies the precondition $P$ but produces an output $f(x)$ that violates the postcondition $Q$.


\begin{example}[Counterexample to Robustness Property]
For local robustness property (\autoref{sec:properties-robustness}):
\[
f(x) \neq f(x') \land \|x - x'\| \leq \epsilon \implies x' \text{ is a counterexample.}
\]
\end{example}

The goal of DNN verification (\autoref{sec:nnv-problem}) is to either prove that a property holds---no cex exist---or find a cex that violates the property.




\begin{example}[Counterexample: Monotonicity in Admission]
A network predicts admission probability to a university. Inputs: GPA $p$ and test score $s$.  

We want: a higher GPA with same score should not decrease admission probability.  

But we observe a case violating this:
\begin{itemize}
 \item A: GPA = 3.0, score = 1500, prediction = 0.8  
 \item B: GPA = 3.5, score = 1500, prediction = 0.6  
\end{itemize}

Using the numbers in this violating case, write the monotonicity requirement and show how this is a counterexample.


Monotonicity requirement:
\[
p \leq p' \land s = s' \implies f(p,s) \leq f(p',s')
\]

Counterexample:
\[
3.0 \leq 3.5 \land 1500 = 1500 \quad \text{but} \quad f(3.0,1500)=0.8 > f(3.5,1500)=0.6
\]

\end{example}


\section{The VNN-LIB  Specification Language}\label{sec:vnnlib}


The VNN-LIB standard~\cite{demarchi2023supporting,vnnlib} defines a format to describe neural networks and properties. Such a standard format enables the sharing of benchmarks across different tools and platforms, facilitating evaluations and comparisons of their performance. VNN-COMP~\cite{brix2024fifth} uses VNN-LIB to evaluate different neural network verification tools.


Specifically, VNN-LIB defines a common format for the following components:
\begin{itemize}
    \item \textbf{Neural Network (or model) representation} in the ONNX format~\cite{onnx}.
    \item \textbf{Property specification} in SMT-LIB format~\cite{barrett2010smt}.
\end{itemize}



\subsection{VNN-LIB: Property Specification Language}

Verification tasks involve proving that the output of a network remains within some desired post-condition $\Sigma$, given inputs within a bounded set $\Pi$.

\paragraph{Formal Specification}
Let $\nu: D^{n_1 \times \dots \times n_h} \to D^{m_1 \times \dots \times m_k}$ be a neural network, and $x$ and $y$ its input and output tensors. A property is expressed as:
\[
\forall x \in \Pi \rightarrow \nu(x) \in \Sigma
\]
This includes:
\begin{itemize}
    \item \textbf{Precondition} $\Pi$: constraints on inputs.
    \item \textbf{Postcondition} $\Sigma$: required properties of outputs.
\end{itemize}

Properties are encoded in \textbf{SMT-LIB2}, referencing input/output variable names consistent with ONNX.


\begin{example}
A typical ACAS XU network (\autoref{sec:acasxu}) maps 5D input to 5D output via 6 layers of 50 ReLU neurons. A property is of the network is
\[
-\varepsilon_i \leq x_i \leq \varepsilon_i \quad (0 \leq i < 5)
\]
\[
y_0 \leq y_1, \quad y_0 \leq y_2, \quad y_0 \leq y_3, \quad y_0 \leq y_4,
\]
where $x_i$ are the input variables, $y_i$ are the output variables, and $\varepsilon_i$ are small perturbation bounds for each input dimension. This property states that if the inputs are perturbed within the bounds $\varepsilon_i$, then the first output neuron $y_0$ is less than or equal to all other output neurons $y_1, y_2, y_3, y_4$.

%\tvn{Hai, is this local?}\hd{yes, it is local. But it doesn't tailor to a specific input (center point), so people might call it a safety property.}

The VNN-LIB code for this property is as follows:

\begin{lstlisting}[style=SMTLIB-style, language=SMTLIB,basicstyle=\ttfamily\scriptsize, multicols=2]
; declaring the input variables
(declare-const X_0 Real)
(declare-const X_1 Real)
(declare-const X_2 Real)
(declare-const X_3 Real)
(declare-const X_4 Real)
(declare-const X_5 Real)
; declaring neuron outputs
(declare-const Y_0 Real)
(declare-const Y_1 Real)
(declare-const Y_2 Real)
(declare-const Y_3 Real)
(declare-const Y_4 Real)
; asserting the input relations
(assert (<= X_0 eps0))
(assert (>= X_0 -eps0))
(assert (<= X_1 eps1))
(assert (>= X_1 -eps1))
(assert (<= X_2 eps2))
(assert (>= X_2 -eps2))
(assert (<= X_3 eps3))
(assert (>= X_3 -eps3))
(assert (<= X_4 eps4))
(assert (>= X_4 -eps4))
; asserting the output relations
(assert (<= Y_0 Y_1))
(assert (<= Y_0 Y_2))
(assert (<= Y_0 Y_3))
(assert (<= Y_0 Y_4))
\end{lstlisting}
\end{example}


% \begin{example}[MNIST Network]

% A CNN model for MNIST uses:
% \begin{itemize}
%     \item 2 convolutional layers (5x5 kernel, padding 2), followed by ReLU and MaxPool (2x2).
%     \item A flatten layer, then a fully connected layer with 10 outputs.
%     \item Input: $1 \times 28 \times 28$; Output: 10-class classification.
% \end{itemize}

% A robustness property around a sample $\hat{x}$ classified as class 9:
% \[
% \forall i \in [0, 783] : \hat{x}_i - \varepsilon \leq x_i \leq \hat{x}_i + \varepsilon
% \]
% \[
% \forall j \in [0,8] : y_j - y_9 \leq 0
% \]


% \subsubsection*{Variable Naming Convention}\tvn{what's the purpose of this section?}\hd{seems unnecessary}
% \begin{itemize}
%     \item 1D tensor: \texttt{X\_0, X\_1, ..., X\_n}
%     \item 2D tensor: \texttt{X\_0-0, X\_0-1, ..., X\_n-m}
%     \item 3D tensor: \texttt{X\_0-0-0, ..., X\_i-j-k}
% \end{itemize}

% \paragraph{Example: Tensor Flattening Algorithm}
% \begin{lstlisting}
% procedure flatten(x)
%     idx = 0
%     for a = 0 to N1
%       for b = 0 to N2
%         ...
%           for k = 0 to Nk
%             X_idx = x[a][b]...[k]
%             idx += 1
% \end{lstlisting}

% \noindent In SMT-LIB:
% \begin{lstlisting}
% (declare-fun X0 () Real) ; or (declare-fun X_0-0-0 () Real)
% ...
% (assert (<= X0 (+ Xhat0 eps)))
% (assert (>= X0 (- Xhat0 eps)))
% ...
% (assert (<= (- FC0_0 FC0_9) 0.0))
% \end{lstlisting}



\section{Problems}

\begin{problem}[Robustness + Safety: Drone Controller]\label{problem:drone}
An autonomous drone computes its thrust level using  a network controller $f(w,d)$, where $w$ is winds speed and $d$ the distance to nearest obstacle. We want two properties:  
\begin{enumerate}
\item Robustness: If the wind speed reading changes by at most 1 unit ($|w-w'|\leq 1$) and distance remains the same, 
   the thrust decision should remain the same.  
\item Safety: If the obstacle distance is less than 5 meters, then thrust must not be greater than 2.
\end{enumerate}

\begin{solution}
Robustness:
\[
\forall w, w', d, \quad |w-w'|\leq 1 \implies f(w,d) = f(w',d)
\]

Safety:
\[
\forall w, d, \quad d < 5 \implies f(w,d) \leq 2
\]
\end{solution}
\end{problem}

\begin{problem}[Global Consistency: Celsius and Fahrenheit]
An NN answers two related questions:
Q1: ``What is the temperature in Celsius?'' (input $t_C$)  
Q2: ``What is the temperature in Fahrenheit?'' (input $t_F$)  

We want consistency: If Q1 outputs $y$, then Q2 must output $1.8y+32$.

\begin{solution}
\[
\forall t_C, \quad f(Q2, t_C \times 1.8 + 32) = 1.8 \cdot f(Q1,t_C) + 32
\]
\end{solution}
\end{problem}

% \begin{problem}[Monotonicity in Multiple Inputs: Flight Risk]
% A neural network predicts flight risk score $r$ for passengers. Inputs are number of missed flights $m$ 
% and number of valid documents provided $d$. We want:  
% - Increasing $m$ should never decrease $r$.  
% - Increasing $d$ should never increase $r$.

% \begin{solution}
% Missed flights:
% \[
% m \leq m' \land d = d' \implies f(m,d) \leq f(m',d')
% \]

% Documents:
% \[
% d \leq d' \land m = m' \implies f(m,d) \geq f(m,d')
% \]
% \end{solution}
% \end{problem}

% \begin{problem}[Temporal Safety: Medical Monitoring]
% A medical monitoring network takes as input heart rate readings over time and outputs an alarm signal 
% (0 = safe, 1 = alarm). Property:  
% If heart rate exceeds 180 bpm for 3 consecutive time steps, then the alarm must be raised at the next time step.

% \begin{solution}
% \[
% \forall t, \quad (HR_t > 180 \land HR_{t+1} > 180 \land HR_{t+2} > 180) \implies f(HR_{t+3}) = 1
% \]
% \end{solution}
% \end{problem}


% \begin{problem}[Robustness in Speech Recognition]
% A speech recognition NN maps audio clips $x$ to text. Robustness property: if background noise changes by at most 
% $\epsilon$ in volume, the transcription should remain the same.

% \begin{solution}
% \[
% \forall x', \quad \|x - x'\| \leq \epsilon \implies f(x') = f(x)
% \]
% \end{solution}
% \end{problem}

% \begin{problem}[Safety in Medical Diagnosis]
% A NN diagnoses diseases from patient data (age $a$, blood pressure $bp$, heart rate $hr$).  
% Safety property: If age $a > 80$ and $bp > 200$, then the network must never output ``safe''.

% \begin{solution}
% \[
% a > 80 \land bp > 200 \implies f(a,bp,hr) \neq \text{``safe''}
% \]
% \end{solution}
% \end{problem}

% \begin{problem}[Consistency in Translation]
% A multilingual NN translates between English, French, and German.  
% If English $\to$ French translation of ``cat'' is ``chat'', then French $\to$ German translation of ``chat'' must be ``Katze''.

% \begin{solution}
% \[
% f(\text{EN}\to\text{FR}, \text{``cat''}) = \text{``chat''} \implies 
% f(\text{FR}\to\text{DE}, \text{``chat''}) = \text{``Katze''}
% \]
% \end{solution}
% \end{problem}

% \begin{problem}[Monotonicity in Fairness]
% A network computes credit approval probability $f(p,s,g)$ with GPA $p$, score $s$, and gender $g$.  
% We require: increasing GPA or score cannot decrease approval, and gender should not matter.

% \begin{solution}
% \[
% p \leq p' \land s = s' \land g \neq g' \implies f(p,s,g) \leq f(p',s',g')
% \]
% \[
% s \leq s' \land p = p' \land g \neq g' \implies f(p,s,g) \leq f(p,s',g')
% \]
% \[
% f(p,s,\text{male}) = f(p,s,\text{female}) \quad \forall p,s
% \]
% \end{solution}
% \end{problem}

\begin{problem}[Counterexample: Safety in Vehicles]
A NN computes car acceleration $a$. We want a safety property: if distance to obstacle $d<10$, then $a\leq 0$. But we observe a scenario where $d=5$ but $a=+2$.

Write the safety requirement and show how this is a counterexample.

\begin{solution}
Safety requirement:
\[
d < 10 \implies a \leq 0
\]

Counterexample:
\[
d=5, \quad f(d)=a=+2 \quad \text{violates property.}
\]
\end{solution}
\end{problem}



\begin{problem}\label{problem:z3-properties}

\begin{figure}
\centering
\proofnet{1}
\caption{\label{fig:proofnet}A simple NN with 2 inputs, 4 hidden ReLU neurons, and 2 outputs.}
\end{figure}



Consider the NN in~\autoref{fig:proofnet}. Note that in this network the hidden neurons ($v_1 \ldots v_4$) use ReLU activation, but the output neurons ($y_1,y_2$) just use affine transformation.






\begin{itemize}
    \item Encode this network using Z3.
    \begin{itemize}
        \item Try to use Z3 to evaluate the network on various inputs.
    \end{itemize}
\item Come up with \textbf{three} properties that this network \emph{does not} have.  Recall that a property often has the form in~\autoref{sec:properties-def}. 
\begin{itemize}
    \item Argue why each property does not hold by providing a counterexample (\autoref{sec:properties-counterexamples}).
    \item (Optional, Easy) Try to use Z3 to show that the properties you came up with do not hold by asking Z3 to find counterexamples (one for each property).
\end{itemize}
\item Come up with \textbf{three} properties that that this network has (i.e., as long as the precondition holds, the postcondition holds).   
\begin{itemize}
    \item Argue why each property always holds (e.g., for any input satisfying the range X, the first layer outputs values in range Y, etc).
    \item (Optional, A bit harder) Try to use Z3 to show that the properties you came up will always hold by asking Z3 to prove that no counterexample exists (i.e., \texttt{unsat}).  
\end{itemize}
\end{itemize}

\end{problem}

\chapter{Verification of Neural Networks}\label{sec:verification}

This chapter discusses the problem of verifying neural networks, i.e., checking if a given property holds for a neural network. 
We define the NN verification (NNV) problem in~\autoref{sec:nnv-problem} and its satisfiability formulation, which is commonly used by DNN verifiers.


\section{The Neural Network Verification (NNV) Problem}\label{sec:nnv-problem}

\begin{definition}[NNV]\label{def:nnv}
Given a DNN \(N\) and a property $\phi$, the \emph{NN verification} (NNV) problem asks if $\phi$ is a valid property\footnote{\autoref{chap:properties} provides various examples of properties.} of $N$.

Typically, $\phi$ is a formula of the form 

\[
\phi_{in} \Rightarrow \phi_{out},
\]
where $\phi_{in}$ is the \emph{precondition}, i.e., a condition over the inputs of $N$, and $\phi_{out}$ is the \emph{postcondition}, i.e., a condition over the outputs of $N$.

A DNN verifier attempts to find a \emph{counterexample} input to $N$ that satisfies $\phi_{in}$ but violates $\phi_{out}$.  If no such counterexample exists, $\phi$ is a valid property of $N$. Otherwise, $\phi$ is not valid and the counterexample can be used to retrain or debug the DNN~\cite{huang2017safety}.
\end{definition}



\begin{example}[Safety Property for Collision Avoidance System]
    In~\autoref{ex:collision-safety}, we defined a safety property (\autoref{sec:properties-safety}) for a collision avoidance system: 
\[
d_{intruder} > d_{threshold} \land v_{intruder} < v_{threshold} \implies v_{us} < v_{threshold},
\]
where $d_{intruder}$ is the distance to the intruder, $d_{threshold}$ is a predefined safe distance, $v_{intruder}$ is the speed of the intruder, and $v_{us}$ is our speed.  

Here, the precondition is 
\[
\phi_{in} = d_{intruder} > d_{threshold} \land v_{intruder} < v_{threshold},
\]
and the postcondition is 
\[
\phi_{out} = v_{us} < v_{threshold}.
\]
\end{example}




\begin{example}\label{ex:dnn-b}

\begin{figure}
\centering
\mydnn{1}
\caption{\label{fig:dnn-b}A simple DNN (similar to~\autoref{fig:dnn}).}
\end{figure}

For the DNN in~\autoref{fig:dnn-b} a \emph{valid} property is that the output is $x_5 \le 0$ for any inputs $x_1 \in [-1,1], x_2\in[-2,2]$.

An \emph{invalid} property is that $x_5 > 0$ for those similar inputs.
A counterexample showing this property violation is $\{x_1=-1, x_2=2\}$, from which the network evaluates to $x_5=-3.5$. 
\end{example}


\section{Satisfiability Formulation and Checking}\label{sec:satisfiability-and-activation-pattern-search}

As with traditional software verification, DNN verification is often represented as a satisfiability problem, which can be solved using an SMT solver (e.g., Z3~\cite{de2008z3}) or a MILP solver (e.g., Gurobi~\cite{gurobi}).

\paragraph{Formulation} To formulate the problem, we first define a formula $\alpha$ to represent the network.
Typically $\alpha$ is a conjunction ($\bigwedge$) of constraints representing the affine transformation (\autoref{sec:affine}) and activation function (\autoref{sec:activation}) of each neuron in the network.
For example, for a fully-connected neural network (\autoref{sec:ffn}) with $L$ layers, $N$ ReLU neurons per layer, this formula is:

\begin{equation}
\alpha = \bigwedge_{\begin{smallmatrix}i \in [1,L]\\ j \in [1,N]\end{smallmatrix}}~~v_{i,j} \equiv \relu{\sum_{k \in [1,N]} (w_{i-1,j,k} \cdot v_{i-1,j}) + b_{i,j}}
\end{equation}
where $v_{i,j}$ is the output of the $j$-th neuron in layer $i$, $w_{i-1,j,k}$ is the weight connecting the $k$-th neuron in layer $i-1$ to the $j$-th neuron in layer $i$, and $b_{i,j}$ is the bias of the $j$-th neuron in layer $i$.  The input layer is layer 0, i.e., $v_{0,j}$ are the input variables.



With this the NNV problem (\autoref{def:nnv}) can be formulated as checking the validity of the following formula:
\begin{equation}\label{eq:nnv}
    \alpha \implies (\phi_{in} \implies \phi_{out}).
\end{equation}
Formula~\autoref{eq:nnv} checks if network $N$ satisfies (implies) the property $\phi_{in} \implies \phi_{out}$. This validity checking can be reduced to checking the satisfiability of the formula:

\begin{equation}\label{eq:nnv2}
  \alpha \land \phi_{in} \land \neg \phi_{out}
\end{equation}
If~\autoref{eq:nnv2} is unsatisfiable, then $\phi$ is a valid property of $N$. Otherwise, $\phi$ is not valid.  Moreover, we can extract a counterexample for the original problem from the satisfying assignment of~\autoref{eq:nnv2}.

\begin{problem}\label{ex:prop-neg1}
  Let $\alpha$ represent our network and the robustness property $| x - x | \le \epsilon \implies  f(x) = f(y)$. Form the satisfiability formula (\autoref{eq:nnv2}) that we need to check. Check them using Z3. 
\end{problem}


\begin{problem}\label{ex:prop-neg2}
  Let $\alpha$ represent our network and the property $y>0$ for any input $x_1 \in [r_1,r_2], x_2 \in [r_3,r_4]$. Form the satisfiability formula (\autoref{eq:nnv2}) that we need to check. Check them using Z3.
\end{problem}


\begin{problem}[Validity Formulation]\label{ex:negation-trick}
Show that $\alpha \implies (\phi_{in} \implies \phi_{out})$ (\autoref{eq:nnv}) is valid if and only if $\alpha \land \phi_{in} \land \neg \phi_{out}$ (\autoref{eq:nnv2}) is unsatisfiable.
First, do this by hand by explicitly writing out the logical equivalences step by step. Then, verify your result using Z3, i.e., show that the negation of the first formula is equivalent to the second formula.
\end{problem}

\begin{example}\label{ex:dnn-sat}
We represent the network in~\autoref{fig:dnn-b} as a formula $\alpha$:
\begin{align*}
& x_3 = \relu{-0.5x_1 + 0.5x_2 + 1.0}  ~\land \\
& x_4 = \relu{0.5x_1 - 0.5x_2 - 1.0}  ~\land \\
& x_5 = -x_3 + x_4 - 1.0,
\end{align*}
\noindent and the property $x_5 > 0$ for any inputs $x_1 \in [-1,1], x_2\in[-2,2]$ as:
\begin{equation*}
\phi_{in} = (-1 \le x_1 \le 1) \land (-2 \le x_2 \le 2); \qquad
\phi_{out} = (x_5 > 0)
\end{equation*}

\paragraph{Satisfiability Solving} We can check the satisfiability of $\alpha \land \phi_{in} \land \neg \phi_{out}$ using constraint solving.~\autoref{sec:se-smt} shows how to perform symbolic execution and an SMT solver (e.g., Z3) to automatically generate this formula from a given DNN and property, and check its satisfiability.~\autoref{sec:using-milp} shows how to encode the problem as a MILP constraints, solvable using a MILP solver (e.g., Gurobi).

In this case, the formula is satisfiable, i.e., the property is invalid, and the solver returns \sat{}.  Any satisfying assignment, e.g., $x_1=-1$ and $x_2=2$, is a counterexample (\autoref{sec:properties-counterexamples}) to the property, as it satisfies the precondition $\phi_{in}$ but violates the postcondition $\phi_{out}$, i.e., $x_5 = -3.5$, which is  $< 0$.
\end{example}

\begin{problem}\label{problem:z3-dnn}
Use Z3 to do~\autoref{ex:dnn-sat}. You might find~\autoref{ex:z3-dnn} useful.  Make sure that you also ask Z3 to  find a counterexample violating the property (does not have to be the same as above).
\end{problem}

\begin{problem}\label{problem:mydnntwo}
\begin{figure}
    \centering
\mydnntwo{1.2}
    \caption{A simple DNN with 2 inputs, 2 hidden ReLU neurons, and 2 outputs.}
    \label{fig:mydnntwo}
\end{figure}
Consider the DNN in~\autoref{fig:mydnntwo}.  Do the following:
\begin{itemize}
    \item Write the formula $\alpha$ representing the network. 
    \item Create the property $\phi$ that the output $x_5 \ge x_6$ for any inputs $x_1 \in [-1,1], x_2\in[-1,1]$.  
    \item Generate the satisfiability formula (\autoref{eq:nnv2}).  DO NOT use Z3 to check it.
\end{itemize}    
\end{problem}


\section{Complexity}\label{sec:complexity}

ReLU-based NNV is \NP{}-complete as shown in~\cite{katz2017reluplex,salzer2023reachability} by reducing the 3-SAT problem to it. This means that the problem of checking whether a given ReLu-based DNN satisfies a property is computationally hard, and no polynomial-time algorithm is known to solve it in the general case.

% \section{Challenges} %TODO

% \subsection{Scalability} Neural networks can be very large, with millions of parameters. This makes it difficult to verify their correctness, as the number of possible inputs grows exponentially with the size of the network.

% %TODO: put somewhere else  
% For DNN verification, AF is straightforward to reason about because it is a linear function. However, AFs are often followed by non-linear activation functions, described next in~\autoref{sec:activation}, which make the verification problem more challenging.

% %TODO: put somewhere else
% For DNN verification, these non-linear activation functions make verification difficult because it introduces multiple possible outcomes for any input, making it hard to reason about the output of the network. For example, ReLU has two possible outputs for any input: 0 if the input is less than zero, and the input itself otherwise, and Sigmoid has a smooth curve with infinite possible outputs for any input.


% \subsection{Formalization}


% \subsection{Expressiveness}



% \section{Challenges in Specifying Properties}\tvn{TODO}

% Specifying desirable properties for neural networks is not straightforward. Some challenges include:
% \begin{itemize}
%     \item \textbf{Incomplete Specifications:} We may not be able to specify all desirable properties.
%     \item \textbf{Expressiveness} For tasks such as sentiment analysis or image recognition, functional correctness is hard to define precisely.
% \end{itemize}



\part{Constraint Solving and Abstraction}

\chapter{Constraint Solving}\label{chap:constraint-solving}

\section{Symbolic Execution and SMT Solving}\label{sec:se-smt}

As described in~\autoref{sec:satisfiability-and-activation-pattern-search} the Neural Network Verification (NNV) problem can be formulated as a satisfiability problem. Specifically, we encode the network as a logical formula, and use a constraint solver to check that formula satisfies the property of interest.

A straightforward and automated way to do this encoding is using \emph{symbolic execution} (SE)~\cite{baldoni2018survey,king1976symbolic}, a well-known software testing technique for finding bugs.  SE executes a program on symbolic inputs, i.e., inputs represented as symbols rather than concrete values, and tracks the reachability of program state as symbolic expressions, i.e., logical formulae over symbolic inputs. The satisfiability of these formulae is then checked using an SMT solver, and satisfying assignments represent inputs leading to the undesirable (buggy) program state.

\subsection{Symbolic Execution}\label{sec:se}
We can adapt traditional SE to our problem by treating the DNN as a program and neurons as variables and executing the DNN on symbolic inputs. Affine transformations can easily be represented as logical formulae because they are linear functions. Activation functions such as ReLUs are translated to disjunctions of linear functions or if-then-else statements, i.e., $\relu{x} ~=~ \max(x,0) ~=~ x \ge 0 \land x \lor 0 \land \neg x$.


\begin{example}\label{ex:se-dnn}
\begin{figure}
\centering
\mydnn{1}
\caption{\label{fig:dnn-a}A simple DNN (similar to~\autoref{fig:dnn}).}
\end{figure}    

To create a logical formula representing the DNN in~\autoref{fig:dnn-a}, we can symbolically execute the DNN on symbolic inputs $x_1,x_2$ and track the values of the neurons $x_3, x_4, x_5$ as a set (conjunction) of logical formulae.  SE starts with the inputs $x_1$ and $x_2$ and computes the values of the neurons in the hidden layer, $x_3$ and $x_4$, using the affine transformations, followed by ReLUs. Finally, SE computes the output neuron $x_5$ as a linear combination of the hidden layer neurons.

\begin{equation}\label{eq:se-dnn}
    \begin{split}
x_5 &= -x_3 + x_4 - 1.0 ~\land \\
x_3 &= \max(-0.5x_1 + 0.5x_2 + 1.0, 0) ~\land \\
x_4 &= \max(0.5x_1 - 0.5x_2 - 1.0, 0)
    \end{split}
\end{equation}

\end{example}

\subsection{SMT Solving}\label{sec:smt}
After obtaining the symbolic representation of the DNN, we can use an SMT solver~\cite{barrett2010smt} to check the satisfiability of the formula $\alpha \land \phi_{in} \land \neg \phi_{out} $, where $\alpha$ is the symbolic representation of the DNN, $\phi_{in}$ is the precondition on the inputs, and $\phi_{out}$ is the postcondition on the outputs. The solver checks if there exists an assignment to the symbolic inputs that satisfies the formula. If such an assignment exists, it means that the property is violated, and we can extract a counterexample from the satisfying assignment. Otherwise, if no such assignment exists, the property is valid



\begin{example}\label{ex:smt-dnn}
    To check that the DNN in~\autoref{fig:dnn-a} satisfies the property $x_5 > 0$ for any inputs $x_1 \in [-1,1], x_2\in[-2,2]$ (\autoref{ex:dnn-sat}), represented as:
\begin{align*}
\phi_{in} = (x_1 \ge -1) \land (x_1 \le 1) \land (x_2 \ge -2) \land (x_2 \le 2); \quad \phi_{out} = (x_5 > 0)
\end{align*}
We check the satisfiability of $\alpha \land \phi_{in} \land \neg \phi_{out}$:
\begin{align*}
\begin{split}
x_5 &= -x_3 + x_4 - 1.0 ~\land \\
x_3 &= \max(-0.5x_1 + 0.5x_2 + 1.0, 0) ~\land \\
x_4 &= \max(0.5x_1 - 0.5x_2 - 1.0, 0) ~\land \\
    &(x_1 \ge -1) \land (x_1 \le 1) \land (x_2 \ge -2) \land (x_2 \le 2) \quad \land
    (x_5 \le 0) \\
    \end{split}    
\end{align*}    

In this case, the SMT solver returns \sat{} and a satisfying assignment, e.g., $x_1=-1$ and $x_2=2$, which is a counterexample to the property. This means that for these inputs, the output $x_5 = -3.5$ violates the property $x_5 > 0$.
\end{example}

\subsection{Limitations}\label{sec:smt-limitations} 

While using symbolic execution and SMT solving is a straightforward way to verify DNNs, it has several practical limitations:
\begin{itemize}
    \item \textbf{Path Explosion and Scalability}: the number of paths that the solver has to analyze can grow exponentially with the number of ReLU-based neurons and layers as each ReLU, represented as a disjunction of linear functions, has two possible outputs for any input (i.e., the input value itself or 0).  This leads to the notorious \emph{path explosion} problem and becoming intractable for large DNNs. Programming assignment 1 (\autoref{sec:pa1}) demonstrates this issue.
    
    \item \textbf{Non-linearity:} Other non-linear activation functions (\autoref{sec:activation}), such as Sigmoid or Tanh, might not be easily representable as disjunctions of linear functions as ReLU. This can lead to complex formulae that are hard to reason about and/or result in a large search space for the SMT solver.
    
    \item \textbf{Precision Issues:} SMT solvers may struggle with precision issues when dealing with floating-point arithmetic, which is common in DNNs. This can lead to incorrect results or false positives/negatives in the verification process.
\end{itemize}

For these reasons, SMT solving is mostly used on toy examples, e.g., in a classroom setting.  Modern-based DNN verification tools do not use SMT solving, and instead, rely on more efficient techniques such as abstraction (\autoref{chap:abstractions}).

%\tvn{Hai, include some references or results, e.g., from Nguyen's, showing that SMT solvers are not scalable for DNN verification.}\hai{where can I find the results?}\tvn{Not sure, I thought Nguyen record the results/graphs in some TeX document. Could you ask him?}

\section{MILP}\label{sec:using-milp}

Instead of using SMT solving, we can encode the NNV problem as a Mixed Integer Linear Programming (MILP) constraints (\autoref{sec:lp}), and then invoke an MILP solver such as Gurobi~\cite{gurobi} to check their \emph{feasibility} or satisfiability (\autoref{sec:lp-feasibility}).


% The fundamental difference between SMT and MILP solving is that SMT solvers aims to find satisfying assignments that make a given logical formula true. In contrast, MILP solvers aim to find the best solution (according to some objective function) that satisfy a given set of \emph{linear} constraints.
% Thus, we need to encode the DNN as a set of linear constraints, and use binary indicator variables (\autoref{sec:milp-binary}) to represent the non-linear activation functions such as ReLU.  This creates an MILP problem solvable using a MILP solver.

% Due to scalability issues with SMT solvers (\autoref{sec:smt-limitations}), modern DNN verification techniques ~\cite{wang2018efficient,tjeng2019evaluating,duong2024harnessing} often rely on Mixed Integer Linear Programming (MILP) solving, which is specialized for linear constraints and more efficient for DNN reasoning. %Many state-of-the-art DNN verification tools use the industrial-strength MILP solver Gurobi~\cite{gurobi}.

% The fundamental distinction between SMT and MILP solving lies in their problem formulation and solution approach. 
% SMT solvers address satisfiability problems: determining whether there exist variable assignments that make a given logical formula true. 
% SMT solvers can handle diverse mathematical theories including non-linear arithmetic.
% MILP solvers address optimization problems: finding the best solution (according to some objective function) that satisfy a given set of \emph{linear} constraints. 


% MILP solvers cannot directly solve general SMT problems because they are restricted to linear constraints and cannot handle the non-linear theories and complex logical structures that SMT problems often contain. 
% While SMT solvers could theoretically encode MILP problems as satisfiability queries, they are not designed for optimization and would be highly inefficient. 
% Despite both approaches having exponential worst-case complexity, MILP solvers often demonstrate superior practical performance due to their restriction to linear constraints, which enables several key optimizations such as linear relaxations, preprocessing techniques, and specialized algorithms. 


%\paragraph{MILP} Mixed Integer Linear Programming (MILP) is an optimization technique that solves problems involving both continuous variables (real numbers) and integer variables (including binary 0/1 variables), subject to linear constraints. Unlike SMT solvers that handle complex logical formulae with disjunctions, MILP solvers are specifically designed for linear constraints and can leverage decades of optimization research to solve large-scale problems efficiently.


\subsection{ReLU Encoding}\label{sec:relu-encoding}

We first encode non-linear activation functions like ReLU using \emph {binary indicator} variables and linear constraints. For each neuron, we introduce a binary variable (\autoref{sec:milp-binary}) that indicates whether the neuron is ``active'' (output equals input) or ``inactive'' (output is zero). This transforms the non-linear $\max(z,0)$ operation into a set of linear inequalities controlled by the binary variable. 
We define 

\begin{itemize}
    \item $z$: the pre-activation value, i.e., the value that goes into ReLU
    \item $\hat{z}$: the post-activation value, i.e., the output of ReLU
    \item $a \in \{0,1\}$: a binary indicator variable encoding whether the neuron is active ($z \ge 0$) or inactive ($z < 0$)
    \item $l, u$: lower and upper bounds on $z$ ($l \leq z \leq u$). 
\end{itemize}

The MILP encoding of $\hat{z} = \max(z, 0)$ is then (\autoref{ex:relu_milp} shows a simpler example that does not involve bounds):
\begin{align*}
    &\hat{z} \geq z \\
    &\hat{z} \geq 0 \\
    &\hat{z} \leq a \cdot u \\
    &\hat{z} \leq z - l(1-a) \\
    &a \in \{0,1\}
\end{align*}

These constraints enforce $\hat{z} = z$ when $a = 1$ (active) and $\hat{z} = 0$ when $a = 0$ (inactive), which captures the two possible ReLU outputs ($0$ or $z$).
Note that constraints are linear and involve both continuous variable $\hat{z}$ and binary variable $a$.  



\subsection{Computing Concrete Bounds}\label{sec:pre-relu-bounds} 

The mentioned lower and upper bounds (\autoref{sec:relu-encoding})---\emph{concrete} values $l$ and $u$ such that $l \leq z \leq u$ over the input $z$ to ReLU--- are critical for ensuring that the binary indicator $a$ can only take on values that are \emph{valid} given the possible range of $z$. For example, if $u < 0$, then $z$ is always negative, so the active phase ($a=1$) is infeasible, and thus can be eliminated.  Similarly, if $l \geq 0$, then $z$ is always active.


Either of these cases indicates the neuron is \emph{stable}---always active or always inactive---and thus significantly simplifies the MILP problem because ReLU can be replaced with a linear function (identity or constant 0). Of course, if $l < 0 < u$, then both active and inactive phases are possible, and the MILP solver has to consider both cases. \autoref{chap:abstractions} discusses abstraction techniques to approximate ReLU outputs.


%In general, the tightness of the bounds $l$ and $u$ is crucial for the efficiency of the MILP solver and a major focus of DNN reasoning is developing techniques to capture these bounds more precisely (\autoref{chap:abstractions}).

\paragraph{Computing Bounds $l \le e \le u$}  Given a linear expression $e$
\[
 e = a_1 x_1 + a_2 x_2 + \ldots + b,
\]
where each variable $x_i$ ranges over $[l_i, u_i]$, a simple way to compute the bounds $l \le e \le u$ is using \emph{interval} arithmetic (\autoref{sec:interval-abstraction}):

\begin{itemize}
    \item \textbf{For the lower bound} ($l_3$):
    For each $x_i$, use its upper bound $u_i$ if $a_i < 0$, and use its lower bound $l_i$ if $a_i \geq 0$.
    \item \textbf{For the upper bound} ($u_3$):
    For each $x_i$, use $l_i$ if $a_i < 0$, and use $u_i$ if $a_i \geq 0$.
\end{itemize}

This guarantees that the extreme values of $e$ are achieved at some corner of the input box.




\begin{example}\label{ex:relu_milp1}

\begin{figure}
\centering
\mydnn{1}
\caption{\label{fig:dnn-c}A simple DNN (similar to~\autoref{fig:dnn}).}
\end{figure}   

    Consider neuron $x_3$ in the DNN in~\autoref{fig:dnn-c}. 
    We have $x_3 = -0.5x_1 + 0.5x_2 + 1.0$ as the pre-activation value of $x_3$. The upper $u_3$ and lower $l_3$ bounds on $x_3$ over the input region $x_1 \in [-1,1]$ and $x_2\in[-2,2]$ are:
\begin{align*}
    & z_3 = -0.5x_1 + 0.5x_2 + 1.0 \\
    & l_3 = -0.5(1) + 0.5(-2) + 1.0 = -0.5 \\
    & u_3 = -0.5(-1) + 0.5(2) + 1.0 = 2.5 \\
\end{align*}

Notice that we use different pairs of values to compute the lower (1,-2) and upper (-1,2) bounds.


With the computed bounds, we encode the ReLU output of $x_3$:
\begin{align*}
    &\hat{x}_3 \geq x_3 \\
    &\hat{x}_3 \geq 0 \\
    &\hat{x}_3 \leq a_3 \cdot u_3 \\
\implies  &\hat{x}_3 \leq a_3 \cdot 2.5 \\
    &\hat{x}_3 \leq x_3 - l_3(1-a_3) \\
\implies  &\hat{x}_3 \leq x_3 - (-0.5)(1-a_3) \\
\implies  &\hat{x}_3 \leq x_3 + 0.5(1-a_3) \\
    &a_3 \in \{0,1\}
\end{align*}

Note that because $l_3 = -0.5$ and $u_3 = 2.5$, $a_3$ can be either 0 or 1, depending on the value of $x_3$. If we had different bounds, e.g., $l_3 = 0.1$, then $a_3$ would be forced to be 1, as $x_3$ can never be less than 0.1 (i.e., $x_3$ is a stable neuron because it is always active). Stable neurons replaces ReLU with either 0 or identity function, which significantly simplifies the problem.
\end{example}


\subsection{DNN encoding} More generally, we can encode the DNN as a set of MILP linear constraints as follows:

\begin{equation}\label{eq:mip}
    \begin{aligned}
        &\text{(a)}\quad z^{(i)} = W^{(i)} \hat{z}^{(i-i)} + b^{(i)}; \\
        &\text{(b)}\quad y = z^{(L)};  x = \hat{z}^{(0)}; \\
        &\text{(c)}\quad \hat{z}_j^{(i)} \ge {z}_j^{(i)}; \hat{z}_j^{(i)} \ge 0; \\
        &\text{(d)}\quad a_j^{(i)} \in \{ 0, 1\} ;\\
        &\text{(e)}\quad \hat{z}_j^{(i)} \le {a}_j^{(i)} {u}_j^{(i)}; \hat{z}_j^{(i)} \le {z}_j^{(i)} - {l}_j^{(i)}(1 - {a}_j^{(i)}); \\
    \end{aligned}
\end{equation}
where $x$ is input, $y$ is output, and $z^{(i)}$, $\hat{z}^{(i)}$, $W^{(i)}$, and $b^{(i)}$ are the pre-activation, post-activation, weight, and bias vectors for layer $i$. 
\begin{enumerate}[label=(\alph*)]
    \item defines the affine transformation computing the pre-activation value for a neuron in terms of outputs in the preceding layer;
    \item defines the inputs and outputs in terms of the adjacent hidden layers;
    \item asserts that post-activation values are non-negative and no less than pre-activation values;
    \item defines that the neuron activation status indicator variables that are either 0 or 1; and
    \item defines constraints on the upper, $u_j^{(i)}$, and lower, $l_j^{(i)}$, bounds of the pre-activation value of the $j$th neuron in the $i$th layer.
\end{enumerate}
Deactivating a neuron, $a_j^{(i)} = 0$, simplifies the first of the (e) constraints to $\hat{z}_j^{(i)} \le 0$, and activating a neuron simplifies the second to $\hat{z}_j^{(i)} \le z_j^{(i)}$, which is consistent with the semantics of $\hat{z}_j^{(i)} = max(z_j^{(i)},0)$.

 

\begin{example}[Full example]\label{ex:milp-dnn}

    We use MILP to formulate and check if the DNN in~\autoref{fig:dnn-c} satisfies the property $x_5 > 0$ for any inputs $x_1 \in [-1,1], x_2\in[-2,2]$. We do this by checking the feasibility of the MILP constraints encoding $\alpha \land \phi_{in} \land \neg \phi_{out}$, where $\alpha$ is the MILP encoding of the DNN, $\phi_{in}$ is the precondition on the inputs, and $\phi_{out}$ is the postcondition on the outputs.  We do this in several steps:


\begin{enumerate}    
\item Encoding precondition $\phi_{in}$ representing input bounds and the postcondition $\neg \phi_{out}$ representing the negation of the postcondition:
\begin{align*}
\phi_{in} &: -1 \le x_1 \le 1;\quad -2 \le x_2 \le 2 \\
\neg \phi_{out} &: x_5 \le 0
\end{align*}

\item Encoding the DNN
Hidden layer (pre- and post-activation): 
\begin{align*}
z_3 &= -0.5x_1 + 0.5x_2 + 1.0 \\
z_4 &= 0.5x_1 - 0.5x_2 - 1.0 \\
\hat{z}_3 &\ge z_3, \quad \hat{z}_3 \ge 0 \\
\hat{z}_4 &\ge z_4, \quad \hat{z}_4 \ge 0 \\
a_3, a_4 &\in \{0, 1\} \\
\hat{z}_3 &\le a_3 \cdot u_3, \quad \hat{z}_3 \le z_3 - l_3(1 - a_3) \\
\hat{z}_4 &\le a_4 \cdot u_4, \quad \hat{z}_4 \le z_4 - l_4(1 - a_4)
\end{align*}

Output layer:
\begin{align*}
x_5 &= -\hat{z}_3 + \hat{z}_4 - 1.0
\end{align*}


\item Computing upper and lower bounds over given input ranges. Here, with $x_1 \in [-1,1]$ and $x_2 \in [-2,2]$, we have: 
\begin{align*}
z_3 &\in [-0.5 \cdot 1 + 0.5 \cdot (-2) + 1, -0.5 \cdot (-1) + 0.5 \cdot 2 + 1] = [-0.5, 2.5] \\
z_4 &\in [0.5 \cdot (-1) - 0.5 \cdot 2 - 1, 0.5 \cdot 1 - 0.5 \cdot (-2) - 1] = [-2.5, 0.5]
\end{align*}

So we set $l_3 = -0.5, u_3 = 2.5$, and $l_4 = -2.5, u_4 = 0.5$. 

\item \textbf{Substituting bounds into the constraints:}
\begin{align*}
\hat{z}_3 &\le a_3 \cdot 2.5, \quad \hat{z}_3 \le z_3 - (-0.5)(1 - a_3) = z_3 + 0.5(1 - a_3) \\
\hat{z}_4 &\le a_4 \cdot 0.5, \quad \hat{z}_4 \le z_4 - (-2.5)(1 - a_4) = z_4 + 2.5(1 - a_4)
\end{align*}

\item \textbf{The final MILP encoding:}
\begin{align*}
& -1 \le x_1 \le 1; \quad -2 \le x_2 \le 2; \\
& z_3 = -0.5x_1 + 0.5x_2 + 1.0; \\
& z_4 = 0.5x_1 - 0.5x_2 - 1.0; \\
& \hat{z}_3 \ge z_3, \quad \hat{z}_3 \ge 0; \\
& \hat{z}_4 \ge z_4, \quad \hat{z}_4 \ge 0; \\
& a_3, a_4 \in \{0, 1\}; \\
& \hat{z}_3 \le a_3 \cdot 2.5, \quad \hat{z}_3 \le z_3 + 0.5(1 - a_3); \\
& \hat{z}_4 \le a_4 \cdot 0.5, \quad \hat{z}_4 \le z_4 + 2.5(1 - a_4); \\
& x_5 = -\hat{z}_3 + \hat{z}_4 - 1.0; \\
& x_5 \le 0; \\
& \text{where } z_3 \in [-0.5, 2.5], z_4 \in [-2.5, 0.5], \hat{z}_3 \in [0, 2.5], \hat{z}_4 \in [0, 0.5].
\end{align*}

%\tvn{Do we need to specify the ranges (e.g., $z_3 \in [-0.5, 2.5]$) at the end or they are redundant?}

\item \textbf{Solving} From the MILP formulation, the MILP solver attempts to find a feasible (\autoref{sec:lp-feasibility}) or satisfying assignment representing a counterexample violating the property.  In this example, it might find $x_1 = -1, x_2 = 2$, which leads to:
\begin{align*}
z_3 &= -0.5(-1) + 0.5(2) + 1.0 = 2.5 \\
z_4 &= 0.5(-1) - 0.5(2) - 1.0 = -2.5 \\
a_3 &= 1, \hat{z}_3 = 2.5 \quad \text{(neuron active)} \\
a_4 &= 0, \hat{z}_4 = 0 \quad \text{(neuron inactive)} \\
x_5 &= -2.5 + 0 - 1.0 = -3.5
\end{align*}
Since $x_5 = -3.5 \le 0$, this assignment satisfies our search for $x_5 \le 0$ and  thus is a counterexample. 
\end{enumerate}
\end{example}


\begin{problem}\label{prob:milp-dnn}
\begin{figure}
\centering
\mydnntwo{1.2}
\caption{\label{fig:dnn-d}A simple DNN (similar to~\autoref{fig:mydnntwo}).}
\end{figure} 

Use MILP encoding and solving to check if the network in~\autoref{fig:dnn-d} satisfies the property $\phi$ that the output $x_5 \ge x_6$ for any inputs $x_1 \in [-1,1], x_2\in[-1,1]$. Specificaly, do the following steps:
\begin{enumerate}
    \item Write down the precondition $\phi_{in}$ and postcondition $\phi_{out}$ representing the property $\phi$.
    \item Write down the MILP encoding of the DNN.
    \item Compute the upper and lower bounds of the pre-activation values of the neurons in the hidden layer.
    \item Substitute the bounds into the MILP encoding.
    \item Write down the final MILP encoding of $\alpha \land \phi_{in} \land \neg{\phi_{out}}$.
    \item Check the feasibility of the MILP encoding (e.g., using Z3) and report the result.
\end{enumerate}
\end{problem}

\begin{problem}\label{prob:stable-neuron}
As shown in~\autoref{ex:relu_milp1}, the upper and lower bounds of neuron $x_3$ of the DNN in~\autoref{fig:dnn-c} are $u_3 = 2.5$ and $l_3 = -0.5$. 
\begin{itemize}
\item Compute the upper and lower bounds of $x_4$ in the same example.
\item Change the weights and/or biases of the network in~\autoref{fig:dnn-c}, but keep the input ranges $-1 \le x_1 \le 1$ and $-2 \le x_2 \le 2$, such that $x_3$ becomes a stable neuron (always active or always inactive).  Show the new weights and/or biases, and compute the new upper and lower bounds of $x_3$.
\end{itemize}
\end{problem}

% \tvn{So far we talk about bounds for pre-ReLU values, right? is that the same as post-ReLU?  In other words, when we talk about abstraction for ReLU, are we talking about these pre-ReLU bounds, which currently use intervals?  or the abstraction for ReLU refer to something else and not these pre-ReLU bounds?}
% \hd{no, we are referring to post-ReLU bounds. For example, a pre-ReLU interval is  $z_3 \in [-0.5, 2.5]$ --- indicating an unstable neuron, and we will abstraction to compute bounds for the post-ReLU e.g., $\hat{z}_3$.}\tvn{I am still confused, see example~\autoref{ex:relu_milp} .. I am computing the upper and lower bounds of $x_3$, not $\hat{x}_3$. The bounds of $\hat{x}_3$ is always $[0, u_3]$.}

\subsection{Limitations}\label{sec:milp-limitations}


\begin{itemize}
    \item \textbf{Scalability:} While MILP is efficient in dealing with linear constraints, it still cannot be applied directly to real-world DNNs due to the large search space. Each ReLU application to an unstable neuron introduces a binary variable (\autoref{sec:relu-encoding}), leading to exponential number of possible branches, and real-world DNNs can have millions of such ReLUs, making the search space intractable.

    \item \textbf{Limited exploitation of network structure and modern hardware} Off-the-shelf MILP solvers are designed for arbitrary MILP problems and do not exploit DNN-specific structures and concepts such as activation patterns (\autoref{sec:activation-patterns}) to prune the search space.
    Moreover, MILP solvers, even industrial-strength ones such as Gurobi~\cite{gurobi}, are primarily CPU-based and does not leverage the massive parallelism provided by modern GPUs to speed up computation.

    %\item \textbf{Generic branch-and-bound algorithms:} While MILP solvers employ branch-and-bound (BaB) algorithms, these are generic and not tailored to DNNs. In contrast, specialized DNN verification algorithms leverage DNN-specific BaB strategies, such as layer-wise branching, abstract domain propagation, and neuron-specific heuristics, enabling greater efficiency.

    \item \textbf{Advanced Abstraction and Heuristics} Interval analysis is efficient and commonly used for computing neuron bounds, but cannot capture dependencies between neurons, leading to precision loss in deeper networks. SOTA DNN verification tools use more advanced abstract domains such as zonotopes  and polytopes to improve precision (\autoref{chap:abstractions}).

    Modern DNN verification tools also employ heuristics to decide which neurons to branch on and to determine stable neurons to avoid unnecessary branching. These heuristics are not available in general MILP solvers.
\end{itemize}


%\tvn{Hai, above you mention MILP also employs BaB algorithm, could you write a paragraph or so about how MILP solvers use BaB and briefly show how that would apply to example 4.2.2 (just briefly, no need a full step by step demonstration). Is this BaB algorithm used by MILP very similar to the one used by DNN verification tools (minus the DNN specific optimizations and heuristics)? like the BaB algorithm described in~\autoref{alg:bab} }
% ---

% Let me know if you want this condensed further or expanded into sub-items for even more clarity!



% Despite its precision, MILP encoding faces severe scalability limitations that prevent its direct application to real-world DNNs. 
% The primary issue is the exponential explosion in the search space: each ReLU neuron introduces a binary variable $a$, and for a network with $n$ ReLU neurons, the MILP solver must potentially explore $2^n$ different activation patterns. 
% While industrial MILP solvers like Gurobi are highly optimized, they are designed for general optimization problems and cannot exploit the specific structure of neural networks. 
% Additionally, MILP solvers are primarily CPU-based and cannot leverage the massive parallelism of GPUs that modern DNNs rely upon, further limiting their computational efficiency. 

% While MILP solvers already employ BaB algorithms, they use general-purpose BaB designed for arbitrary linear programming problems, which cannot exploit the specific structure of neural networks. 
% % This motivates the development of specialized DNN verification algorithms like \reluplex{}~\cite{katz2017reluplex} and custom branch-and-bound techniques that integrate DNN-specific abstractions and propagation methods. 
% Unlike MILP's generic branching on arbitrary variables, DNN-specific BaB algorithms can exploit layer-wise structure, propagate bounds through activation functions using specialized abstract domains (intervals, zonotopes, polyhedra), and employ neuron-specific heuristics to select which neurons to branch. 
% For instance, \reluplex{} extends the Simplex algorithm with custom pivot rules for ReLU constraints, while \neuralsat{} integrates conflict-driven learning tailored to activation patterns and neuron stabilization techniques that can infer neurons proven to be always active or inactive---optimizations that are not available in general MILP frameworks.

% While interval abstraction provides a foundation for computing bounds, it suffers from significant precision loss that compounds through network layers, necessitating more sophisticated and precise abstractions. 
% The fundamental limitation is that intervals cannot capture correlations between variables---each neuron's bounds are computed independently, ignoring relationships with other neurons which leads to over-approximation that becomes increasingly loose in deeper networks. 
% More advanced abstractions like zonotopes can capture linear relationships between variables, while polytopes can represent arbitrary linear constraints. 


\chapter{Abstractions}\label{chap:abstractions}


As mentioned in~\autoref{sec:relu-encoding} the computation of upper and lower bounds of the neuron values help determine neuron stability and therefore can significantly reduce the complexity of verification. Modern DNN verifiers explore different \emph{abstraction} techniques to compute these bounds more precisely while balancing computational efficiency.
 
This chapter discusses the interval, zonotope, and polytope abstract domains commonly used in verification. Each domain provides a different way to represent and compute the bounds of neurons, with its own trade-offs in terms of precision and computational complexity.

\section{Overview and Background} 

%We will focus on ReLU (\autoref{sec:relu}) activation functions, which are the most common in DNNs. The goal is to compute the bounds of a post-ReLU neuron $\hat{z}$ given the bounds of its pre-ReLU value $z$ over the input region. For example, for a ReLU neuron $y = \max(0, x)$, we want to compute the bounds $[l_y(x), u_y(x)]$ of $y$ given the bounds $[l_x, u_x]$ on $x$.\tvn{is the pre-Relu bounds always computed like what was described in~\autoref{sec:pre-relu-bounds}? Is that computation considered interval too? Can that bound computation be obtained using other abstractions?}
%\hd{yes, concrete bounds will always be computed like what was described in~\autoref{sec:pre-relu-bounds} IF the bounds of a neurons are presented as linear equations. In other words, abstractions differ in the way they construct the linear equations, concretization step will be the same.}

%\hd{Zonotope uses a different approach to represent the abstraction, using center and generators, so concretization step will be different. But if we construct the lower and upper equations for a zonotope, the concretization step will be the same.}

%\hd{Note that, the equations of a neuron are not $e = f(x_1, ..., x_n)$, but 
%\[f_L(x_1, ..., x_n) \le e \le f_U(x_1, ..., x_n)\] 
%So to compute the concrete bounds, $e_L = min(f_L(x_1, ..., x_n))$ and $e_U = max(f_U(x_1, ..., x_n))$, where $min(f_L(x_1, ..., x_n))$ and $max(f_U(x_1, ..., x_n))$ are the concretization steps.}

%We want to compute the bounds to be as tight as possible, i.e., they should be the largest lower and lowest upper values that $\hat{z}$ can take given the bounds on $z$. This computation is called \emph{abstraction} and is crucial for DNN verification, as it allows us to reason about the behavior of the network without having to enumerate all possible values of the neurons. There are several abstraction techniques that can be used to compute these bounds, each with its own trade-offs in terms of precision and computational complexity.

\newcommand{\intervalabstraction}[1]{
    \begin{tikzpicture}[scale=#1]
        % Colors
        \def\lx{-1.0}
        \def\ux{1.0}
        \def\ly{0}
        \def\uy{1.0}
        % Fill region
        \fill[yellowfill] (\lx,\ly) rectangle (\ux,\uy);
        % Axes
        \draw[thick,->] ({\lx-0.2},0) -- ({\ux+0.3},0) node[right] {$x$};
        \draw[thick,->] (0,{\ly-0.3}) -- (0,{\uy+0.3}) node[above] {$y$};
        % Dashed bounds
        \draw[dashed] (\lx,{\ly-0.1}) -- (\lx,{\uy+0.2});
        \draw[dashed] (\ux,{\ly-0.1}) -- (\ux,{\uy+0.2});
        \draw[dashed] (\lx,\uy) -- (\ux,\uy);
        % ReLU line
        \draw[ultra thick,myred] (\lx,\ly) -- (0,\ly) -- (\ux,\uy);
        % Labels
        \node[below] at (\lx,0) {$l_x$};
        \node[below] at (\ux,-0.05) {$u_x$};
        \node[left] at (-0.1,\ly-0.2) {$l_y(x)$};
        \node[above] at (\ux-0.5,\uy) {$u_y(x)$};
        \node[below right] at (0,0) {$0$};
    \end{tikzpicture}
}
\newcommand{\zonotopeabstraction}[1]{
    \begin{tikzpicture}[scale=#1]
        \def\lx{-1.0} \def\ux{1.0} \def\d{0.5}
        \coordinate (A) at (\lx, \d*\lx+0.1);
        \coordinate (B) at (\lx, 0.2);
        \coordinate (E) at (\ux, \ux+0.01);
        \coordinate (F) at (\ux, \ux-\d*\ux-0.1);
        \fill[yellowfill] (A) -- (B) -- (E) -- (F) -- cycle;
        \draw[thick,->] ({\lx-0.2},0) -- ({\ux+0.3},0) node[right] {$x$};
        \draw[thick,->] (0,-0.6) -- (0,{\ux+0.2}) node[above] {$y$};
        \draw[dashed] (\lx,-0.6) -- (\lx,{\ux+0.1});
        \draw[dashed] (\ux,-0.6) -- (\ux,{\ux+0.1});
        \draw[dashed] (\lx, 0.2) -- (\ux, \ux+0.01);
        \draw[dashed] (\lx, \d*\lx+0.1) -- (\ux, \ux-\d*\ux-0.1);
        \draw[ultra thick,myred] (\lx,0) -- (0,0) -- (\ux,\ux);
        \node[below] at (\lx-0.1,0) {$l_x$};
        \node[below] at (\ux+0.12,-0.05) {$u_x$};
        \node[below] at ({\lx/2},-0.3) {$l_{y}(x)$};
        \node[above] at (\ux/2,\ux/2+0.3) {$u_{y}(x)$};
        \node[below right] at (0,0) {$0$};
    \end{tikzpicture}    
}

\newcommand{\polytopeabstraction}[1]{
    \begin{tikzpicture}[scale=#1]
        \def\lx{-1.0} \def\ux{1.0} \def\d{0.5}
        \coordinate (A) at (\lx, 0);
        \coordinate (B) at (\lx, 0.01);
        \coordinate (E) at (\ux, \ux+0.01);
        \coordinate (F) at (\ux, 0);
        \fill[yellowfill] (A) -- (B) -- (E) -- (F) -- cycle;
        \draw[thick,->] ({\lx-0.2},0) -- ({\ux+0.3},0) node[right] {$x$};
        \draw[thick,->] (0,-0.4) -- (0,{\ux+0.2}) node[above] {$y$};
        \draw[dashed] (\lx,-0.3) -- (\lx,{\ux+0.1});
        \draw[dashed] (\ux,-0.3) -- (\ux,{\ux+0.1});
        \draw[dashed] (\lx, 0) -- (\ux, \ux+0.01);
        \draw[dashed] (\lx, 0) -- (\ux, 0);
        \draw[ultra thick,myred] (\lx,0) -- (0,0) -- (\ux,\ux);
        \node[below] at (\lx-0.1,0) {$l_x$};
        \node[below] at (\ux+0.12,-0.05) {$u_x$};
        \node[below] at ({\lx/2},-0.01) {$l_{y}(x)$};
        \node[above] at (\ux/2,\ux/2+0.3) {$u_{y}(x)$};
        \node[below right] at (0,0) {$0$};
    \end{tikzpicture}
}

\begin{figure}[h]
    \centering
    % First row
    \begin{subfigure}{0.3\linewidth}
        \centering
        \intervalabstraction{1.5}
        \caption{Interval}
        \label{fig:relu-interval-abstraction}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.3\linewidth}
        \centering
        \zonotopeabstraction{1.5}
        \caption{Zonotope}
        \label{fig:relu-zonotope-abstraction}
    \end{subfigure}
    \hfill
    % Second row
    \begin{subfigure}{0.3\linewidth}
        \centering
        \polytopeabstraction{1.5}
        \caption{Polytope (lower flat)}
        \label{fig:relu-polytope-abstraction}
    \end{subfigure}
    \caption{Abstractions of $\myrelu(x) = \max(0,x)$ over $x \in [l_x, u_x]$ using (a) interval, (b) zonotope, (c) polytope abstractions.}
    \label{fig:relu-all-abstractions}
\end{figure}

\paragraph{Common Abstractions for ReLU}
We use ReLU to illustrate different abstractions.
Our goal is to approximate the bounds of the post-ReLU value of a neuron given the bounds of its pre-ReLU value. For example, for a ReLU neuron $y = \max(0, x)$, we want to compute the bounds $[l_y(x), u_y(x)]$ of $y$ given the bounds $[l_x, u_x]$ on $x$.

\autoref{fig:relu-all-abstractions} illustrates common abstractions (or \emph{over-approximations}) for the ReLU function $y = \max(0, x)$, where $x \in [l_x, u_x]$ and $y \in [l_y(x), u_y(x)]$. The values of ReLU are shown as points on the \colorbox{myred}{red line}, which is non-convex and consists of two linear segments: one for $x < 0$ (where $y = 0$) and another for $x \geq 0$ (where $y = x$).
To compute the bounds $l_y(x)$ and $u_y(x)$, we can use different abstractions: 

\begin{itemize}
    \item \textbf{Interval Abstraction:} Interval represents the post-ReLU value as an interval $[l_y(x), u_y(x)]$ where $l_y(x) = 0$ and $u_y(x) = u_x$. Interval is a simple and efficient abstraction, but it can be \emph{imprecise}, e.g., it does not capture the relationship between the input and output of ReLU. %, and simply assumes that the output can take any value between 0 and the upper bound of the input. 

    In~\autoref{fig:relu-interval-abstraction}, the \colorbox{yellowfill}{yellow rectangle} (box) represents the interval abstraction in the 2D space of $(x, y)$. As can be seen, this box is too large of an over-approximation (too coarse or loose), as it includes many points that are not achievable by ReLU, e.g., the point $(0.5, 0.0)$ is not on the red line.
    
    \item \textbf{Zonotope Abstraction:} Zonotopes, commonly represented using center and generators, can capture linear relationships between variables more effectively. %We can represent ReLU as a zonotope that includes the linear segments.  The lower bound $l_y(x)$ is $y = \lambda x$ and the upper bound $u_y(x)$ is $y = \lambda x + u_x(1 - \lambda)$ for some slope $\lambda \in [0, \frac{u_x}{u_x - l_x}]$. If we set $\lambda = 0$, the zonotope is a rectangle, which is the same as the interval abstraction. If we set $\lambda = \frac{u_x}{u_x - l_x}$, the zonotope's is upper bound is the same as polytope's upper bound in~\autoref{fig:relu-polytope-abstraction}.
    In~\autoref{fig:relu-zonotope-abstraction}, the \colorbox{yellowfill}{a parallelogram}---a zonotope in 2D---is arguably tighter than the interval in~\autoref{fig:relu-interval-abstraction}.  It captures the linear relationship between $x$ and $y$ and excludes points that are not achievable by ReLU, e.g., the point $(0.5, 0.0)$ that was included in the interval abstraction is not included in the zonotope. However, it still includes non-ReLU points and is also not strictly better than interval, e.g., the point $(0.5, -0.5)$ is included in the zonotope but not in the interval abstraction (or ReLU). 
    
    %too technical here
    

%    The \colorbox{yellowfill}{zonotope} shown in~\autoref{fig:relu-zonotope-abstraction} 

    \item \textbf{Polytope Abstraction:} Polytopes can represent arbitrary linear constraints and provide very precise bounds. We can construct a polytope that tightly encloses the non-convex shape of the ReLU function.

    In~\autoref{fig:relu-polytope-abstraction}, the polytope is shown as a \colorbox{yellowfill}{trapezoid} that captures the linear segments of ReLU. The lower bound is $l_y(x) = 0$ and the upper bound is $u_y(x) = u_x$. %\tvn{this is similar to the interval abstraction, as both have the same bounds, right?}\hd{you mean the same lower bound equation? Yes. Upper bound equation is different. However given a single neuron abstraction like in those figures, the concrete bounds (not the equations) are the same.}

\end{itemize}

% \begin{figure}[h]
%     \centering
    
%     \begin{tikzpicture}[scale=2]
%         % Colors
%         \definecolor{myred}{RGB}{255,100,100}
%         \definecolor{yellowfill}{RGB}{255,245,200}
%         % Parameters
%         \def\lx{-1.0}
%         \def\ux{1.0}
%         \def\ly{0}
%         \def\uy{1.0}
%         % Fill region
%         \fill[yellowfill] (\lx,\ly) rectangle (\ux,\uy);
%         % Axes
%         \draw[thick,->] ({\lx-0.2},0) -- ({\ux+0.3},0) node[right] {$x$};
%         \draw[thick,->] (0,{\ly-0.3}) -- (0,{\uy+0.3}) node[above] {$y$};
%         % Dashed bounds
%         \draw[dashed] (\lx,{\ly-0.1}) -- (\lx,{\uy+0.2});
%         \draw[dashed] (\ux,{\ly-0.1}) -- (\ux,{\uy+0.2});
%         \draw[dashed] (\lx,\uy) -- (\ux,\uy);
%         % ReLU line
%         \draw[ultra thick,myred] (\lx,\ly) -- (0,\ly) -- (\ux,\uy);
%         % Labels
%         \node[below] at (\lx,0) {$l_x$};
%         \node[below] at (\ux,-0.05) {$u_x$};
%         \node[left] at (-0.1,\ly-0.2) {$l_y(x)$};
%         \node[above] at (\ux-0.5,\uy) {$u_y(x)$};
%         % Origin
%         \node[below right] at (0,0) {$0$};
%     \end{tikzpicture}
%     \caption{Interval abstraction for ReLU: $y = \max(0, x)$, with $x \in [l_x, u_x]$ and $y \in [l_y(x), u_y(x)]$.}
%     \label{fig:relu-interval-abstraction}
% \end{figure}

% \begin{figure}[h]
%     \centering
%     \begin{subfigure}{0.49\linewidth}
%     \begin{tikzpicture}[scale=2]
%         % Colors
%         \definecolor{myred}{RGB}{255,100,100}
%         \definecolor{yellowfill}{RGB}{255,245,200}
%         % Parameters
%         \def\lx{-1.0}
%         \def\ux{1.0}
%         \def\ly{0}
%         \def\uy{1.0}
%         % Fill region
%         \fill[yellowfill] (\lx,\ly) rectangle (\ux,\uy);
%         % Axes
%         \draw[thick,->] ({\lx-0.2},0) -- ({\ux+0.3},0) node[right] {$x$};
%         \draw[thick,->] (0,{\ly-0.3}) -- (0,{\uy+0.3}) node[above] {$y$};
%         % Dashed bounds
%         \draw[dashed] (\lx,{\ly-0.1}) -- (\lx,{\uy+0.2});
%         \draw[dashed] (\ux,{\ly-0.1}) -- (\ux,{\uy+0.2});
%         \draw[dashed] (\lx,\uy) -- (\ux,\uy);
%         % ReLU line
%         \draw[ultra thick,myred] (\lx,\ly) -- (0,\ly) -- (\ux,\uy);
%         % Labels
%         \node[below] at (\lx,0) {$l_x$};
%         \node[below] at (\ux,-0.05) {$u_x$};
%         \node[left] at (-0.1,\ly-0.2) {$l_y(x)$};
%         \node[above] at (\ux-0.5,\uy) {$u_y(x)$};
%         % Origin
%         \node[below right] at (0,0) {$0$};
%     \end{tikzpicture}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}{0.49\linewidth}
%         \begin{tikzpicture}[scale=2]
%             % Colors
%             \definecolor{myred}{RGB}{255,100,100}
%             \definecolor{yellowfill}{RGB}{255,245,200}
%             % Parameters
%             \def\lx{-1.0}
%             \def\ux{1.0}
%             % Zonotope (band width)
%             \def\d{0.5}
%             % Zonotope corners
%             \coordinate (A) at (\lx, 0+\d*\lx+0.1);    % bottom left
%             \coordinate (B) at (\lx, 0.2);    % top left
%             \coordinate (C) at (0, \d*0);          % top middle
%             \coordinate (D) at (0, -\d*0);         % bottom middle
%             \coordinate (E) at (\ux, \ux+0.01);  % top right
%             \coordinate (F) at (\ux, \ux-\d*\ux-0.1);  % bottom right
%             % Fill zonotope
%             \fill[yellowfill] (A) -- (B) -- (E) -- (F) -- cycle;
%             % Axes
%             \draw[thick,->] ({\lx-0.2},0) -- ({\ux+0.3},0) node[right] {$x$};
%             \draw[thick,->] (0,{-0.6}) -- (0,{\ux+0.2}) node[above] {$y$};
%             % Bounded region
%             \draw[dashed] (\lx,{-0.6}) -- (\lx,{\ux+0.1});
%             \draw[dashed] (\ux,{-0.6}) -- (\ux,{\ux+0.1});
%             % Zonotope boundaries
%             \draw[dashed] (\lx, 0.2) -- (\ux, \ux+0.01);
%             \draw[dashed] (\lx, \d*\lx+0.1) -- (\ux, \ux-\d*\ux-0.1);
%             % ReLU line
%             \draw[ultra thick,myred] (\lx,0) -- (0,0) -- (\ux,\ux);
%             % Labels
%             \node[below] at (\lx-0.1,0) {$l_x$};
%             \node[below] at (\ux+0.12,-0.05) {$u_x$};
%             \node[below] at ({\lx/2},-0.3) {$l_{y}(x)$};
%             \node[above] at (\ux/2,\ux/2+0.3) {$u_{y}(x)$};
%             % Origin
%             \node[below right] at (0,0) {$0$};
%         \end{tikzpicture}
%     \end{subfigure}

%     \caption{Zonotope abstraction for ReLU: $y = \max(0,x)$, with $x \in [l_x, u_x]$ and $y \in [l_y(x), u_y(x)]$.}
%     \label{fig:relu-zonotope-abstraction2}
% \end{figure}


% \begin{figure}[h]
%     \centering
%     \begin{subfigure}{0.49\linewidth}
%         \begin{tikzpicture}[scale=2]
%             % Colors
%             \definecolor{myred}{RGB}{255,100,100}
%             \definecolor{yellowfill}{RGB}{255,245,200}
%             % Parameters
%             \def\lx{-1.0}
%             \def\ux{1.0}
%             % Zonotope (band width)
%             \def\d{0.5}
%             % Zonotope corners
%             \coordinate (A) at (\lx, 0);    % bottom left
%             \coordinate (B) at (\lx, 0.01);    % top left
%             \coordinate (C) at (0, \d*0);          % top middle
%             \coordinate (D) at (0, -\d*0);         % bottom middle
%             \coordinate (E) at (\ux, \ux+0.01);  % top right
%             \coordinate (F) at (\ux, 0);  % bottom right
%             % Fill zonotope
%             \fill[yellowfill] (A) -- (B) -- (E) -- (F) -- cycle;
%             % Axes
%             \draw[thick,->] ({\lx-0.2},0) -- ({\ux+0.3},0) node[right] {$x$};
%             \draw[thick,->] (0,{-0.4}) -- (0,{\ux+0.2}) node[above] {$y$};
%             % Bounded region
%             \draw[dashed] (\lx,{-0.3}) -- (\lx,{\ux+0.1});
%             \draw[dashed] (\ux,{-0.3}) -- (\ux,{\ux+0.1});
%             % Zonotope boundaries
%             \draw[dashed] (\lx, 0) -- (\ux, \ux+0.01);
%             \draw[dashed] (\lx, 0) -- (\ux, 0);
%             % ReLU line
%             \draw[ultra thick,myred] (\lx,0) -- (0,0) -- (\ux,\ux);
%             % Labels
%             \node[below] at (\lx-0.1,0) {$l_x$};
%             \node[below] at (\ux+0.12,-0.05) {$u_x$};
%             \node[below] at ({\lx/2},-0.01) {$l_{y}(x)$};
%             \node[above] at (\ux/2,\ux/2+0.3) {$u_{y}(x)$};
%             % Origin
%             \node[below right] at (0,0) {$0$};
%         \end{tikzpicture}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}{0.49\linewidth}
%         \begin{tikzpicture}[scale=2]
%             % Colors
%             \definecolor{myred}{RGB}{255,100,100}
%             \definecolor{yellowfill}{RGB}{255,245,200}
%             % Parameters
%             \def\lx{-1.0}
%             \def\ux{1.0}
%             % Zonotope (band width)
%             \def\d{0.5}
%             % Zonotope corners
%             \coordinate (A) at (\lx, -0.2);    % bottom left
%             \coordinate (B) at (\lx, 0.01);    % top left
%             \coordinate (C) at (0, \d*0);          % top middle
%             \coordinate (D) at (0, -\d*0);         % bottom middle
%             \coordinate (E) at (\ux, \ux+0.01);  % top right
%             \coordinate (F) at (\ux, 0.2);  % bottom right
%             % Fill zonotope
%             \fill[yellowfill] (A) -- (B) -- (E) -- (F) -- cycle;
%             % Axes
%             \draw[thick,->] ({\lx-0.2},0) -- ({\ux+0.3},0) node[right] {$x$};
%             \draw[thick,->] (0,{-0.4}) -- (0,{\ux+0.2}) node[above] {$y$};
%             % Bounded region
%             \draw[dashed] (\lx,{-0.3}) -- (\lx,{\ux+0.1});
%             \draw[dashed] (\ux,{-0.3}) -- (\ux,{\ux+0.1});
%             % Zonotope boundaries
%             \draw[dashed] (\lx, 0) -- (\ux, \ux+0.01);
%             \draw[dashed] (\lx, -0.2) -- (\ux, 0.2);
%             % ReLU line
%             \draw[ultra thick,myred] (\lx,0) -- (0,0) -- (\ux,\ux);
%             % Labels
%             \node[below] at (\lx-0.1,0) {$l_x$};
%             \node[below] at (\ux+0.12,-0.05) {$u_x$};
%             \node[below] at ({\lx/2},-0.1) {$l_{y}(x)$};
%             \node[above] at (\ux/2,\ux/2+0.3) {$u_{y}(x)$};
%             % Origin
%             \node[below right] at (0,0) {$0$};
%         \end{tikzpicture}
%     \end{subfigure}

%     \caption{Polytop abstraction for ReLU: $y = \max(0,x)$, with $x \in [l_x, u_x]$ and $y \in [l_y(x), u_y(x)]$.}
%     \label{fig:relu-polytope-abstraction2}
% \end{figure}


% \tvn{Hai, create concrete examples with numbers to show how the abstractions work, e.g., for interval, zonotope, polytope, etc. We want to use one example to show the differences in the approximation,  not multiple examples which would be less effective.}

\subsection{Geometric Representations}\label{sec:geometric-representations} 
Because our abstract domains are interval, zonotope, and polytopes, it is useful to understand how these shapes can be represented. There are two common ways to describe a geometric shape:

\begin{itemize}
  \item \textbf{Corner-based representation:} Define the shape by listing all of its corner points (vertices). For example, a rectangle in 2D is defined by its four corners, and a box in 3D is defined by its eight corners. This representation is intuitive and directly shows the boundaries of the shape.
        
  \item \textbf{Generator-based representation:} Define the shape using a \emph{center point} and several direction vectors (\emph{generators}) that define how the shape can stretch or tilt. Instead of listing all corners, it specifies how to reach any point in the shape by starting from the center and moving along the generators within certain limits.  This representation is often more compact, especially for higher-dimensional shapes.
\end{itemize}

\autoref{fig:interval-rectangle-two-views} uses corner-based and generator-based representations to represent a 2D rectangle, which is an interval abstraction over two variables.  The left side shows the corner-based view, where the rectangle is defined by its 4 corners.  The right side shows the generator-based view, where the rectangle is represented as a zonotope with a center point \(c\) and two orthogonal generators \(g_1\) and \(g_2\).

\begin{figure}
\centering
\begin{tikzpicture}[scale=1.1,>=stealth]

% === LEFT: corner-based rectangle ===
\begin{scope}[shift={(-3.8,0)}]
  % rectangle
  \fill[blue!10] (0,0) rectangle (2,1.4);
  \draw[blue!70!black, thick] (0,0) rectangle (2,1.4);

  % corner points
  \foreach \x/\y in {0/0,2/0,0/1.4,2/1.4}{
    \fill[blue!70!black] (\x,\y) circle (1.5pt);
  }

  % labels
  \node[blue!70!black] at (1.0,1.8) {\small Corner-based view};
  \node at (1.0,-0.4) {\small Defined by vertices};
\end{scope}


% === RIGHT: Generator-based rectangle (interval abstraction) ===
\begin{scope}[shift={(3.8,0)}]
  % rectangle (same shape)
  \fill[orange!15] (0,0) rectangle (2,1.4);
  \draw[orange!80!black, thick] (0,0) rectangle (2,1.4);

  % center
  \coordinate (c) at (1.0,0.7);
  \filldraw[blue!80!black] (c) circle (1.5pt) node[below left] {\small $c$};

  % generator arrows
  \draw[->,blue!70!black,thick] (c) -- ++(1.0,0) node[right] {\small $g_1$};
  \draw[->,blue!70!black,thick] (c) -- ++(0,0.7) node[above] {\small $g_2$};

  % labels
  \node[orange!80!black] at (1.0,1.8) {\small Generator-based view};
  \node at (1.0,-0.4) {\small Built from $c+\epsilon_1g_1+\epsilon_2g_2$};
\end{scope}

% center arrow
\node at (0,0.7) {\Large $\Longleftrightarrow$};

\end{tikzpicture}
\caption{Two equivalent descriptions of a 2D interval abstraction (a rectangle).  
Left: defined by its four corners (independent variable bounds).  
Right: represented as a zonotope with center $c$ and orthogonal generators $g_1$, $g_2$.}
\label{fig:interval-rectangle-two-views}
\end{figure}



\begin{example}\label{ex:interval-zonotope}
  An interval for a single variable is simply a line segment defined by its \emph{two} endpoints (corners)---the lower and upper bounds. Equivalently, it can be represented using a zonotope with a center point and a single generator vector that points in both directions (left and right) from the center:
  \[
    [l, u] = \{ c + \epsilon g \mid \epsilon \in [-1, 1] \}
  \]
    where \(c = \frac{l + u}{2}\) is the center, \(g = \frac{u - l}{2}\) is the generator, and \(\epsilon\) controls how far we move along the generator.
\end{example}

\begin{example}

    Consider the interval:
    \[
    x \in [-2, 3].
    \]
    We can express this interval using a single generator as shown in~\autoref{fig:interval-zonotope}. 

    \begin{figure}
    \centering
    \begin{tikzpicture}[scale=1.2,>=stealth]

    % number line
    \draw[->, thick] (-3.0,0) -- (3.5,0) node[right] {$x$};

    % interval region
    \fill[orange!20] (-2,0) rectangle (3,0.25);
    \draw[orange!70!black, thick] (-2,0) -- (3,0);

    % center point
    \filldraw[blue!70!black] (0.5,0.12) circle (1.5pt) node[above] {$c=0.5$};

    % labels
    \draw[dashed] (-2,0) -- (-2,0.5) node[above, black] {$-2$};
    \draw[dashed] (3,0) -- (3,0.5) node[above, black] {$3$};
    \node at (0.5,-0.4) {\small $x = c + \epsilon g$};

    % epsilon arrows
    \draw[<->, orange!80!black, thick] (-2,0.25) -- (3,0.25);
    \node[orange!70!black] at (0.5,0.7) {\small $\epsilon \in [-1,1]$ moves along $g=2.5$};

    \end{tikzpicture}
    \caption{An interval $[-2,3]$ is a 1D zonotope with center $c=0.5$, generator $g=2.5$, and parameter $\epsilon\in[-1,1]$. Varying $\epsilon$ covers the entire interval.}
    \label{fig:interval-zonotope}
    \end{figure}


    \begin{equation}
    \begin{aligned}
    c = \frac{-2 + 3}{2} = 0.5, & \quad\text{the midpoint of the interval}\\
    \quad g = \frac{3 - (-2)}{2} = 2.5, &  \quad\text{the half-width (distance from the center to each end)}\\
    \epsilon \in [-1, 1], & \quad\text{acts as a knob to move along the generator}
    \end{aligned}
    \end{equation}

    Thus, any point \(x\) in this interval can be written as:
    \[
    x = c + \epsilon g \text{ or } x = 0.5 + \epsilon \cdot 2.5,
    \quad \text{where} \quad \epsilon \in [-1, 1].
    \]


    For example:
    \[
    \epsilon = -1 \Rightarrow x = -2, 
    \quad
    \epsilon = 0 \Rightarrow x = 0.5, 
    \quad
    \epsilon = +1 \Rightarrow x = 3.
    \]

    As \(\epsilon\) varies between \(-1\) and \(+1\), we cover the entire interval \([-2, 3]\).  

\end{example}



\subsection{Transformer Functions}\label{sec:transformer-functions}

The concept of computing abstractions is central to program analysis, e.g., through \emph{abstract interpretation} techniques. 
It allows us reason about the behavior of a program without evaluating it on all concrete inputs---which may be infinite. Instead, we use an \emph{abstract domain}, such as interval, to summarize sets of concrete values, enabling sound and scalable approximation.


\subsubsection{Abstraction Functions} In abstraction interpretation, we have the \emph{abstraction function}
\[
\alpha : D \to D^a,
\]
which maps a concrete value from the domain $D$ to an element in a finite or simpler abstract domain $D^a$. 

\begin{example}[Odd/Even]
    The \texttt{odd/even} or parity abstraction is defined as:
\[
\alpha_{\texttt{parity}}(x \in \mathbb{Z}) =
\begin{cases}
\texttt{even} & \text{if } x \bmod 2 = 0 \\
\texttt{odd}  & \text{if } x \bmod 2 = 1
\end{cases}
\]
Even though $\mathbb{Z}$ is infinite, this abstraction maps all integers to a finite set $\{\texttt{odd}, \texttt{even}\}$. 
\end{example}

\subsubsection{Transformer Functions} Once we have values in the abstract domains, we often define an \emph{abstract transformer function} 
\[
f^a : D^a \to D^a,
\]
for each operation \(f\) to reason about its behavior on abstract values.


\begin{example}
 Consider the function $f(x) = x + 1$. We define the abstract transformers $f^a$ for different abstract domains $D^a$:

 \begin{itemize}
\item \textbf{Odd/Even abstraction}:  $D^a = \{\texttt{odd}, \texttt{even}\}$. Then:
\[
f^a(\texttt{odd}) = \texttt{even}, \quad
f^a(\texttt{even}) = \texttt{odd}
\]

\item \textbf{Sign abstraction}: $D^a = \{\texttt{neg}, \texttt{zero}, \texttt{pos}\}$. Then: 
\[
f^a(\texttt{neg}) = \{\texttt{neg}, \texttt{zero}\}, \quad
f^a(\texttt{zero}) = \texttt{pos}, \quad
f^a(\texttt{pos}) = \texttt{pos}
\]


\item \textbf{Interval abstraction}: $D^a = \{ [a, b] \mid a \leq b \in \mathbb{Z} \cup \{-\infty, +\infty\} \}$. Then:
\[
f^a([a, b]) = [a+1, b+1]
\]

 \end{itemize}

 Notice that the input and output of the abstract transformer $f^a$ are both in the abstract domain $D^a$ (e.g., odd/even, sign, or interval).
\end{example}



\section{Abstract Domains}\label{sec:abstract-domains}

We now introduce several abstract domains that are commonly used in DNN verification. Each domain has its own abstract transformer functions  to compute the bounds of neurons. 

Note that the input to the transformer functions (\autoref{sec:transformer-functions}) are the abstract values and the output is also an abstract value.  For example, for interval transformers, the input is an interval $[l, u]$ and the output is also an interval $[l', u']$. Similarly for zonotope transformers, the input is a zonotope defined by center and generators, and the output is also a zonotope.

\subsection{Interval}\label{sec:interval-abstraction}

Interval is a very simple abstraction which represents the possible values of a variable as an interval $[l, u]$, where $l$ is the lower bound and $u$ is the upper bound.
For example, the set of values $\{-2.5, -8.2, -10.7, 2, 4.7, 5.1\}$ can be represented as $[-10.7, 5.1]$.

\paragraph{Definition}
The interval for one variable \(v\) is defined as:
\[
v \in [l, u] = \{v \in \mathbb{R} \mid l \le v \le u\}
\]


For $n$ variables, the interval becomes a box (like a rectangle in 2D, a cuboid in 3D, or a hyperrectangle in $n$D):
\[
[v_1, v_2, \ldots, v_n] \in [l_1, u_1] \times [l_2, u_2] \times \cdots \times [l_n, u_n]
\]


\subsubsection{Affine Transformer}\label{sec:interval-affine-transformer}

For the linear or affine function \(f\) in~\autoref{sec:affine}
\[f(v_1, v_2, ...,v_n) = \sum_{i=1}^{n} w_i v_i + b\]
where $w_i$ is the weight for the input \(v_i\), $n$ is the number of output nodes from the previous layer and \(b\) is the bias term, the abstract transformer \(f^a\) is:
\[
f^{a}([l_1, u_1],..., [l_n, u_n]) = [f^a_L, f^a_U] = 
\Bigg[b + \sum_{i=1}^{n}\big(\min(w_il_i, w_iu_i\big),\; b+ \sum_{i=1}^{n}\big(\max(w_il_i + w_iu_i\big)\Bigg].
\]



\begin{example}\label{ex:transformer-affine1}

\begin{figure}
\centering
\mydnn{1}
\caption{\label{fig:dnn-abs}A simple DNN (similar to~\autoref{fig:dnn}).}
\end{figure}    

Consider the DNN in~\autoref{fig:dnn-abs} with inputs \(x_1 \in [1, 2]\) and \(x_2 \in [-1, 3]\). The affine function for the neuron \(x_3\) is:
\[
f(x_1,x_2) = -0.5\,x_1 + 0.5\,x_2 + 1.0
\]

Then the interval for \(x_3\) can be computed as:
\small{
\[
\begin{aligned}
f^a([1,2],[-1,3]) = & \Bigg[ 1 + \min(-0.5 \cdot 1,~ -0.5 \cdot 2) + \min(0.5 \cdot -1,~ 0.5 \cdot 3),\\
& ~~1 + \max(-0.5 \cdot 1,~ -0.5 \cdot 2) + \max(0.5 \cdot -1,~ 0.5 \cdot 3)\Bigg]\\
= & [1 - 1.0 - 0.5,~ 1 - 0.5 + 1.5]\\
= & [-0.5,~ 2.0]
\end{aligned}
\]
}
\end{example}
\subsubsection{ReLU Transformer}
For \(\myrelu(x) = \max(0, x)\), the abstract transformer is defined as:

\[
\myrelu^a([l, u]) = [ \myrelu(l), \myrelu(u)] = [\max(0, l), \max(0, u)]
\]

This is equivalent to three cases shown in \autoref{fig:relu-interval-cases}:
\begin{enumerate}
\item If $u < 0$, then $\myrelu^a([l, u]) = [0, 0]$.  If inputs are negative, the output is also negative.
\item If $l \ge 0$, then $\myrelu^a([l, u]) = [l, u]$. If inputs are positive, the output is exactly the same.
\item If $l < 0 < u$, then $\myrelu^a([l, u]) = [0, u]$. If inputs are mixed, the output is approximated to $[0, u]$

\end{enumerate}
\begin{figure}
\centering
\begin{tikzpicture}[scale=1.2,>=stealth]

% Common settings
\tikzstyle{axis}=[->, thick]
\tikzstyle{relu}=[very thick, black]
\tikzstyle{rangebox}=[fill=blue!15, draw=blue!70!black, thick]
\tikzstyle{outputbox}=[fill=orange!20, draw=orange!70!black, thick]

%% --- (1) Inactive case: [l,u] below 0 ---
\begin{scope}[shift={(-4,0)}]
  \draw[axis] (-1.5,0) -- (2.0,0) node[right] {$x$};
  \draw[axis] (0,-0.3) -- (0,1.5) node[above] {$y$};

  % ReLU curve
  \draw[relu] (-1.5,0) -- (0,0) -- (1.8,1.3);

  % Interval below zero
  \fill[blue!10] (-1.0,0) rectangle (-0.3,0.2);
  \draw[blue!80!black,thick] (-1.0,0) rectangle (-0.3,0.2);
  \node[blue!80!black] at (-0.65,-0.3) {\scriptsize input $[l,u]$};

  % Output collapsed to zero
  \fill[orange!20] (1.0,0.0) rectangle (1.7,0.2);
  \draw[orange!70!black,thick] (1.0,0.0) rectangle (1.7,0.2);
  \node[orange!70!black] at (1.35,-0.3) {\scriptsize output $[0,0]$};

  
\end{scope}


%% --- (2) Active case: [l,u] above 0 ---
\begin{scope}
  \draw[axis] (-1.5,0) -- (2.0,0) node[right] {$x$};
  \draw[axis] (0,-0.3) -- (0,1.5) node[above] {$y$};
  \draw[relu] (-1.5,0) -- (0,0) -- (1.8,1.3);

  % Input interval (above zero)
  \fill[blue!10] (0.5,0.0) rectangle (1.5,0.2);
  \draw[blue!80!black,thick] (0.5,0.0) rectangle (1.5,0.2);
  \node[blue!80!black] at (1.0,-0.3) {\scriptsize input $[l,u]$};

  % Output interval (same)
  \fill[orange!20] (0.5,0.5) rectangle (1.5,0.7);
  \draw[orange!70!black,thick] (0.5,0.5) rectangle (1.5,0.7);
  \node[orange!70!black] at (1.0,0.9) {\scriptsize output $[l,u]$};


\end{scope}


%% --- (3) Unstable case: [l,u] crosses 0 ---
\begin{scope}[shift={(4,0)}]
  \draw[axis] (-1.5,0) -- (2.0,0) node[right] {$x$};
  \draw[axis] (0,-0.3) -- (0,1.5) node[above] {$y$};
  \draw[relu] (-1.5,0) -- (0,0) -- (1.8,1.3);

  % Input interval crossing zero
  \fill[blue!10] (-0.8,0.0) rectangle (0.8,0.2);
  \draw[blue!80!black,thick] (-0.8,0.0) rectangle (0.8,0.2);
  \node[blue!80!black] at (0,-0.3) {\scriptsize input $[l,u]$};

  % Output interval [0,u]
  \fill[orange!20] (0,0.0) rectangle (0.8,0.7);
  \draw[orange!70!black,thick] (0,0.0) rectangle (0.8,0.7);
  \node[orange!70!black] at (0.4,0.9) {\scriptsize output $[0,u]$};

\end{scope}

\end{tikzpicture}
\caption{
ReLU transformer for intervals.  
Left: all inputs negative $\Rightarrow [0,0]$.  
Middle: all inputs positive $\Rightarrow$ unchanged.  
Right: interval crosses zero $\Rightarrow [0,u]$.  
The ReLU function clamps negative parts to zero while preserving positive regions.
}
\label{fig:relu-interval-cases}
\end{figure}


\begin{example}
For~\autoref{ex:transformer-affine1}, applying ReLU$^a$ to neuron $x_3$ gives:

\[
\myrelu^a([-0.5, 2.0]) = [\myrelu(-0.5), \myrelu(2.0)] 
= [0, 2.0].
\]
\end{example}


\begin{problem}\label{prob:int-abs}
  Apply interval abstraction to the DNN in~\autoref{fig:dnn-abs} with inputs \(x_1 \in [1, 2]\) and \(x_2 \in [-1, 3]\). Compute the bounds for all neurons.  Clearly indicate the steps (e.g., results after affine and ReLU transformers).
\end{problem}

\subsubsection{Efficiency and Precision}

Intervals is very efficient and scales  well to large networks. The affine transformer only requires a linear number of multiplications and min/max operations, and ReLU reduces to only three matching cases.
However, the cost of efficiency is precision.

\begin{example}\label{ex:interval-overapproximation}

Suppose we have $v_1 \in [0, 1]$, $v_2 = -v_1$, and $z = v_1 + v_2$. 
The concrete value of $z$ would be always 0, but interval abstraction gives $z \in [-1, 1]$, which is a very loose over-approximation. 
Moreover, if we apply ReLU, then the output would be $\myrelu(z) = \myrelu(0) = 0$, but the interval gives $\myrelu^a([-1, 1]) = [0, 1]$, which is again a loose over-approximation.
\end{example}

Interval overapproximation grows quickly as we propagate through many layers of a large network, i.e., it keeps ``inflating'' the bounds, leading to a loose approximation of the output and becoming unable to verify valid properties.  For example, $z \leq 0$ is a valid property for~\autoref{ex:interval-overapproximation}, but the interval abstractions gives $z \in [0,1]$, which is not tight (precise) enough to show this property. 

Nonetheless, interval domain remains popular due to its simplicity and efficiency. In some cases, despite being imprecise, it can still successfully verify properties of neural networks, e.g., for~\autoref{ex:interval-overapproximation} if we want to verify that $z \le 2$, then the interval $z\in [0, 1]$ would suffice.

\begin{problem}\label{prob:correct-abs}
    Suppose $y$ can take values from 0 to 3. Student A computes an interval abstraction $y \in [-2,4]$, while student B computes $y \in [1,2]$. 
    \begin{enumerate}
        \item Which student's abstraction is correct?  If both are correct, which is more precise? Explain your answer.
        \item Using the correct abstraction (if both are correct, use the more precise one), can we use it verify the property $y \leq 3$? How about $y \le 5$? Explain your answers.
    \end{enumerate}
\end{problem}
\subsection{Zonotope}\label{sec:zonotope-abstraction}

Interval abstraction (\autoref{sec:interval-abstraction}) treats each variable independently. For example, if \(x_1 \in [1,2]\) and \(x_2 \in [3,4]\), interval assumes any combination of \(x_1\) and \(x_2\) is possible. But variables can correlate: e.g., when \(x_1\) increases, \(x_2\) also increases\tvn{but this doesn't happens in DNN, so why do we need zonotope? does it help with ReLU abstraction?}.  Zonotopes can capture such correlations and therefore  provide a tighter abstraction.
% A \emph{zonotope} captures this correlation by encoding both variables as linear combinations of a few shared ``uncertainty sourcesâ€™â€™ (\(\epsilon_i\)â€™s).  
%In geometric terms while intervals form axis-aligned boxes, zonotopes form \emph{tilted boxes} (parallelograms or higher-dimensional analogues) that can stretch, rotate, and capture relationships between variables (like ``when $x_1$ goes up, $x_2$ also goes up'').


% \begin{figure}[h!]
% \centering
% \begin{tikzpicture}[scale=0.90,>=stealth]
% \tikzstyle{shp}=[thick]
% \tikzstyle{cent}=[blue!80!black]
% \tikzstyle{gen}=[->, blue!70!black, thick]
% \tikzstyle{lab}=[font=\small]

% % =========================
% % Panel A: m = 1 (line)
% % =========================
% \begin{scope}[shift={(-6,0)}]
%   % center
%   \coordinate (cA) at (0,0);
%   \filldraw[cent] (cA) circle (1.6pt) node[below left,lab] {$c$};

%   % generator g1
%   \coordinate (g1A) at (2,0.5);
%   % endpoints of the segment: c +/- g1
%   \coordinate (A1) at (-2,-0.5);
%   \coordinate (A2) at ( 2, 0.5);

%   % shape (line segment)
%   \draw[blue!15, line width=5pt] (A1) -- (A2); % thick faint band
%   \draw[shp, blue!70!black] (A1) -- (A2);

%   % generator arrow
%   \draw[gen] (cA) -- (g1A) node[right,lab] {$g_1$};

%   % labels
%   \node[lab] at (0,2.0) {1 generator ($m{=}1$): line segment};
%   \node[lab] at (0,-1.6) {$x = c + \epsilon_1 g_1,\ \epsilon_1\in[-1,1]$};
% \end{scope}

% % =========================
% % Panel B: m = 2 (parallelogram)
% % =========================
% \begin{scope}[shift={(0,0)}]
%   \coordinate (cB) at (0,0);
%   \filldraw[cent] (cB) circle (1.6pt) node[below left,lab] {$c$};

%   % generators
%   \coordinate (g1B) at (2,0.5);
%   \coordinate (g2B) at (0.5,1.6);

%   % corners: c Â± g1 Â± g2  (center at origin)
%   \coordinate (B1) at (-2.5,-2.1);
%   \coordinate (B2) at (-1.5, 1.1);
%   \coordinate (B3) at ( 2.5, 2.1);
%   \coordinate (B4) at ( 1.5,-1.1);

%   % shape
%   \fill[orange!15] (B1)--(B2)--(B3)--(B4)--cycle;
%   \draw[shp, orange!80!black] (B1)--(B2)--(B3)--(B4)--cycle;

%   % generator arrows
%   \draw[gen] (cB) -- (g1B) node[right,lab] {$g_1$};
%   \draw[gen] (cB) -- (g2B) node[above right,lab] {$g_2$};

%   % labels
%   \node[lab] at (0,2.6) {2 generators ($m{=}2$): parallelogram};
%   \node[lab] at (0,-2.6) {$x = c + \epsilon_1 g_1 + \epsilon_2 g_2$};
% \end{scope}

% % =========================
% % Panel C: m = 3 (hexagon)
% % =========================
% \begin{scope}[shift={(6,0)}]
%   \coordinate (cC) at (0,0);
%   \filldraw[cent] (cC) circle (1.6pt) node[below left,lab] {$c$};

%   % generators
%   \coordinate (g1C) at (2,0.5);
%   \coordinate (g2C) at (0.5,1.6);
%   \coordinate (g3C) at (-0.7,0.8);

%   % hexagon vertices = convex hull of c + sum eps_i g_i, eps_i in {-1,1}
%   \coordinate (C1) at (-3.2,-1.3);
%   \coordinate (C2) at (-1.8,-2.9);
%   \coordinate (C3) at ( 2.2,-1.9);
%   \coordinate (C4) at ( 3.2, 1.3);
%   \coordinate (C5) at ( 1.8, 2.9);
%   \coordinate (C6) at (-2.2, 1.9);

%   % shape
%   \fill[green!15] (C1)--(C2)--(C3)--(C4)--(C5)--(C6)--cycle;
%   \draw[shp, green!50!black] (C1)--(C2)--(C3)--(C4)--(C5)--(C6)--cycle;

%   % generator arrows
%   \draw[gen] (cC) -- (g1C) node[right,lab] {$g_1$};
%   \draw[gen] (cC) -- (g2C) node[above right,lab] {$g_2$};
%   \draw[gen] (cC) -- (g3C) node[above left,lab] {$g_3$};

%   % labels
%   \node[lab] at (0,3.1) {3 generators ($m{=}3$): hexagon (richer shape)};
%   \node[lab] at (0,-3.2) {$x = c + \epsilon_1 g_1 + \epsilon_2 g_2 + \epsilon_3 g_3$};
% \end{scope}

% \end{tikzpicture}
% \caption{Zonotopes in 2D with $m=1,2,3$ generators (center $c$ at the origin for clarity).  
% More generators $\Rightarrow$ more directions of variability $\Rightarrow$ a richer convex polygon.}
% \label{fig:zonotope-1-2-3-generators}
% \end{figure}


\paragraph{Definition}

A zonotope is often represented using a generator-based representation as illustrated in~\autoref{sec:geometric-representations}.
It is built by starting from a center point and then stretching along several directions defined by generator vectors.
Each generator can move forward or backward within a certain range, and together these movements sweep out the entire shape.
Zonotope generalizes the idea of an interval, which itself is a zonotope (e.g., see \autoref{ex:interval-zonotope}).

Formally, a \textbf{zonotope} \(\mathcal{Z}\) in \(\mathbb{R}^n\) is defined as:
\[
\mathcal{Z} = \left\{ c + \sum_{i=1}^{m} \epsilon_i g_i \mid \epsilon_i \in [-1, 1] \right\}
\]
where:
\begin{itemize}
\item \(c \in \mathbb{R}^n\) is the \textit{center} (analogous to the midpoint of an interval),  
\item \(g_i \in \mathbb{R}^n\) are \textit{generator vectors} (directions of variability), and  
\item \(\epsilon_i \in [-1,1]\) are independent coefficients that determine how much we move along each generator.  
For example, \(\epsilon_i = -1\) moves in the negative direction, \(\epsilon_i = 0\) stays at the center, and \(\epsilon_i = +1\) moves in the positive direction.
\end{itemize}

\begin{figure}
\centering
\begin{tikzpicture}[scale=1.0,>=stealth]

% === Left: independent generators ===
\begin{scope}[shift={(-3.8,0)}]
  \fill[blue!10] (0,0) -- (2,0) -- (2,1.5) -- (0,1.5) -- cycle;
  \draw[blue!70!black,thick] (0,0) rectangle (2,1.5);
  \coordinate (c) at (1,0.75);
  \filldraw[blue!80!black] (c) circle (1.5pt);
  \draw[->,blue!70!black,thick] (c)--++(1,0) node[right]{\small $g_1=(1,0)$};
  \draw[->,blue!70!black,thick] (c)--++(0,0.75) node[above]{\small $g_2=(0,1)$};
  \node at (1,-0.5) {\small Independent $\Rightarrow$ Rectangle};
\end{scope}

% === Right: correlated generators ===
\begin{scope}[shift={(3.8,0)}]
  \fill[orange!15] (0,0) -- (2,0.5) -- (1,2.0) -- (-1,1.5) -- cycle;
  \draw[orange!80!black,thick] (0,0)--(2,0.5)--(1,2.0)--(-1,1.5)--cycle;
  \coordinate (c2) at (0.5,1.0);
  \filldraw[orange!80!black] (c2) circle (1.5pt);
  \draw[->,orange!80!black,thick] (c2)--++(1,0.25) node[right]{\small $g_1=(1,0.25)$};
  \draw[->,orange!80!black,thick] (c2)--++(0.5,1.0) node[above right]{\small $g_2=(0.5,1)$};
  \node at (0.5,-0.5) {\small Correlated $\Rightarrow$ Parallelogram};
\end{scope}

\end{tikzpicture}
\caption{
Left: independent generators produce an axis-aligned rectangle (interval abstraction).  
Right: correlated generators tilt the shape into a parallelogram, capturing dependency between $x_1$ and $x_2$.}\label{fig:zonotope-correlated-generators}
\end{figure}


\begin{example}
    A common zonotope in 2D is a parallelogram. It can be defined by its center point and two generator vectors that define its sides. For instance, parallelogram on the left side of~\autoref{fig:zonotope-correlated-generators} has the center \(c = (1, 1)\) and the generators \(g_1 = (1, 0.25)\) and \(g_2 = (0.5, 1)\). This zonotope represents all points that can be reached by moving along these generators within the range \([-1, 1]\):
  \[
    \mathcal{Z} = \left\{ (1, 1) + \epsilon_1 (1, 0.25) + \epsilon_2 (0.5, 1) \mid \epsilon_1, \epsilon_2 \in [-1, 1] \right\}
  \]
  This zonotope includes points like:
    \[
      (1, 1) + (-1)(1, 0.25) + (1)(0.5, 1) = (-1, 2.5)
    \]
    \[
      (1, 1) + (1)(1, 0.25) + (-1)(0.5, 1) = (3, -0.5)
    \]
\end{example}


\begin{example}
In~\autoref{fig:zonotope-correlated-generators} the parallelogram zonotope on the right of captures   points with correlated \(x_1\) and \(x_2\) values, e.g., increasing \(x_1\) by moving along \(g_1\) also increases \(x_2\) due to the non-zero second component of \(g_1\). 
In contrast, the rectangle zonotope on the left, which represents an interval abstraction, has independent generators, i.e., changing \(x_1\) does not affect \(x_2\), and therefore cannot capture the correlation.
\end{example}

\subsection{Computing Bounds of a Zonotope}\label{sec:zonotope-bounds}
In DNN verification, we often need to compute the bounds of each variable represented by a zonotope. This allows us to determine stable neurons, which in turn helps optimize the verification process.

For each coordinate (dimension) of the zonotope, we compute its lower and upper bounds as follows:
\[
l_j = \min_{\epsilon_i \in [-1,1]} \left(c_j + \sum_{i=1}^{m} \epsilon_i g_{i,j}\right), 
\quad
u_j = \max_{\epsilon_i \in [-1,1]} \left(c_j + \sum_{i=1}^{m} \epsilon_i g_{i,j}\right),
\]
where \(c_j\) is the \(j\)-th component of the center and \(g_{i,j}\) is the \(j\)-th component of the \(i\)-th generator.

\paragraph{A simpler way.}
Since each \(\epsilon_i \in [-1,1]\), each term \(\epsilon_i g_{i,j}\) can vary between \(-|g_{i,j}|\) and \(+|g_{i,j}|\).  
Hence:
\[
\boxed{
l_j = c_j - \sum_{i=1}^{m} |g_{i,j}|, \qquad
u_j = c_j + \sum_{i=1}^{m} |g_{i,j}|.
}
\]

\paragraph{Example (1D).} Given the interval zonotope:
\[
x = 3 + \epsilon_1(2), \quad \epsilon_1 \in [-1,1],
\]
the bounds are computed as:
\[
[l, u] = [3 - |2|, 3 + |2|] = [1, 5].
\]

\paragraph{Example (2D).}
\[
\mathcal{Z} =
\left\{
\begin{bmatrix} 1 \\ 2 \end{bmatrix}
+ \epsilon_1
\begin{bmatrix} 0.5 \\ 1.0 \end{bmatrix}
+ \epsilon_2
\begin{bmatrix} -0.3 \\ 0.2 \end{bmatrix},
\quad \epsilon_1, \epsilon_2 \in [-1,1]
\right\}.
\]
Then for each coordinate:
\[
\begin{aligned}
l_1 &= 1 - (|0.5| + |{-0.3}|) = 0.2, &
u_1 &= 1 + (|0.5| + |{-0.3}|) = 1.8,\\
l_2 &= 2 - (|1.0| + |0.2|) = 0.8, &
u_2 &= 2 + (|1.0| + |0.2|) = 3.2.
\end{aligned}
\]



% \begin{figure}
% \centering
% \begin{tikzpicture}[scale=1.1,>=stealth]

% % === LEFT: Vertex-based ===
% \begin{scope}[shift={(-3.8,0)}]
%   % Parallelogram (same shape as right)
%   \fill[blue!10] (0,0) -- (2,0.4) -- (2.4,1.6) -- (0.4,1.2) -- cycle;
%   \draw[blue!70!black, thick] (0,0) -- (2,0.4) -- (2.4,1.6) -- (0.4,1.2) -- cycle;
  
%   % Corner dots
%   \foreach \x/\y in {0/0, 2/0.4, 2.4/1.6, 0.4/1.2} {
%     \fill[blue!70!black] (\x,\y) circle (1.5pt);
%   }

%   % Labels
% %<<<<<<< HEAD
% %  \node[blue!70!black] at (1.2,1.8) {\small corner-based view};
% %=======
%   \node[blue!70!black] at (1.2,2.0) {\small Corner-based view};
% %>>>>>>> 2cfddab7333b5cd686921149b6294ce8261c1eb7
%   \node at (1.2,-0.4) {\small Defined by vertices};
% \end{scope}

% % === RIGHT: Generator-based ===
% \begin{scope}[shift={(3.8,0)}]
%   % Parallelogram (same shape)
%   \fill[orange!15] (0,0) -- (2,0.4) -- (2.4,1.6) -- (0.4,1.2) -- cycle;
%   \draw[orange!80!black, thick] (0,0) -- (2,0.4) -- (2.4,1.6) -- (0.4,1.2) -- cycle;

%   % Center
%   \coordinate (c) at (1.2,0.8);
%   \filldraw[blue!80!black] (c) circle (1.5pt) node[below left] {\small $c$};

%   % Generators
%   \draw[->,blue!70!black,thick] (c) -- ++(1.0,0.2) node[right] {\small $g_1$};
%   \draw[->,blue!70!black,thick] (c) -- ++(0.2,0.6) node[above right] {\small $g_2$};

%   % Labels
%   \node[orange!80!black] at (1.4,2.0) {\small Generator-based view};
%   \node at (1.2,-0.4) {\small Built from $c+\epsilon_1g_1+\epsilon_2g_2$};
% \end{scope}

% % Connecting text
% \node at (1.5,0.8) {\Large $\Longleftrightarrow$};

% \end{tikzpicture}
% \caption{Two equivalent descriptions of a 2D zonotope (a parallelogram).}
% \label{fig:zonotope-two-views}
% \end{figure}


% \paragraph{Zonotope vs Box (Interval)}

% \autoref{fig:zonotope-vs-box} illustrates the difference between zonotopes and boxes (intervals) in 2D. 
% The blue box represents an interval abstraction, which is axis-aligned and cannot capture correlations between variables. 
% The orange parallelogram represents a zonotope, which can tilt and better fit the shape of correlated variables. 

% \begin{figure}
% \centering
% \begin{tikzpicture}[scale=1.3,>=stealth]

% % Axes
% \draw[->, thick] (-0.5,0) -- (3.5,0) node[right] {$x_1$};
% \draw[->, thick] (0,-0.5) -- (3.5,3.5) node[above] {$x_2$};

% % Interval box
% \fill[blue!10] (0.5,0.5) rectangle (2.5,2.5);
% \draw[blue, thick] (0.5,0.5) rectangle (2.5,2.5);
% \node[blue!60!black] at (1.5,2.7) {\small Interval (Box)};

% % Zonotope parallelogram
% \fill[orange!15, rotate around={20:(2,1)}] (1,0.5) rectangle (3,2.5);
% \draw[orange, thick, rotate around={20:(2,1)}] (1,0.5) rectangle (3,2.5);
% \node[orange!70!black] at (3.3,2.1) {\small Zonotope (Tilted Box)};

% % Legend arrows
% \draw[blue,->] (2.6,2.0) to[bend left] (3.3,2.0);
% \draw[orange,->] (1.8,0.8) to[bend right] (0.6,0.8);

% \end{tikzpicture}
% \caption{Intervals produce axis-aligned boxes (blue), while zonotopes can tilt to fit correlated variables (orange).}
% \label{fig:zonotope-vs-box}
% \end{figure}

\subsubsection{Affine Transformer} 

For the affine function \(f\) in~\autoref{sec:affine}  
\[
f(v_1, v_2, \ldots, v_n) = \sum_{i=1}^{n} w_i v_i + b
\]
where \(w_i\) is the weight associated with input \(v_i\), \(n\) is the number of inputs, and \(b\) is the bias term.  

Applying an affine transformation to a zonotope transforms its center by the same affine rule (weights and bias) and transforms each generator by the linear part (weights only).
In other words, affine operations \emph{preserve} the structure of zonotopes exactly: no approximation needed.  Imagine a %tilted box in space, then an affine transformation just stretches, rotates, and shifts it---the result is still a tilted box.


More formally, given a zonotope  
\[
\mathcal{Z} = \left\{ c + \sum_{j=1}^{m} \epsilon_j g_j \mid \epsilon_j \in [-1, 1] \right\},
\]
the abstract transformer \(f^a\) for the affine function computes the new zonotope as:
\[
f^a(\mathcal{Z}) = \left\{ f(c) + \sum_{j=1}^{m} \epsilon_j f(g_j) \mid \epsilon_j \in [-1, 1] \right\}
\]

That is, the new zonotope has:
\begin{itemize}
  \item \textbf{center:} \(f(c) = \sum_{i=1}^{n} w_i c_i + b\)
  \item \textbf{generators:} each \(f(g_j) = \sum_{i=1}^{n} w_i (g_j)_i\)
\end{itemize}

% For the affine function \(f\) in~\autoref{sec:affine}
% \[
% f(x) = Wx + b
% \]
% where \(W\) is a weight matrix and \(b\) is a bias vector. Given an input zonotope \(\mathcal{Z} = (c, G)\) where \(G = [g_1, g_2, \ldots, g_m]\) is the generator matrix, the abstract transformer \(f^a\) for zonotopes is:
% \[
% f^a(\mathcal{Z}) = (Wc + b, WG)
% \]
% The new center becomes \(Wc + b\) and the new generator matrix becomes \(WG\). 

% Affine operations \emph{preserve} the structure of zonotopes exactly: no approximation needed.  
% Imagine a tilted box in space, then an affine transformation just stretches, rotates, and shifts it---the result is still a tilted box.

\begin{example}\label{ex:zonotope_linear_example}
Consider the DNN in~\autoref{fig:dnn-abs} with inputs \(x_1 \in [1, 2]\) and \(x_2 \in [-1, 3]\).  
The affine function for neuron \(x_3\) is:
\[
f(x_1, x_2) = -0.5\,x_1 + 0.5\,x_2 + 1.0
\]
We want to compute the bounds for \(x_3\) using zonotope abstraction.
%\mathcal{Z} = \left\{ c + \sum_{i=1}^{m} \epsilon_i g_i \mid \epsilon_i \in [-1, 1] \right\}
\paragraph{Represent the input as a zonotope}  
We represent the input intervals \(x_1 \in [1, 2]\) and \(x_2 \in [-1, 3]\) as a zonotope $\{ c + \sum_{i=1}^{m} \epsilon_i g_i \mid \epsilon_i \in [-1,1] \}$.

The center $c_i$ represents the midpoint of each input interval:
\[
c_1 = \frac{1 + 2}{2} = 1.5, \quad c_2 = \frac{-1 + 3}{2} = 1.0, 
\]
and the generator \(g_i\) captures the half-width of each interval:
\[
g_1 = \frac{2 - 1}{2} = 0.5, \quad g_2 = \frac{3 - (-1)}{2} = 2.0
\]


Thus, the input zonotope is
{\small
\[
\mathcal{Z} = \{(1.5, 1.0) + \epsilon_1(0.5, 0) + \epsilon_2(0, 2.0), \quad \epsilon_1, \epsilon_2 \in [-1,1]\}.
\]
}

\paragraph{Apply the affine transformation} We apply the affine function \(f(x_1, x_2) = -0.5\,x_1 + 0.5\,x_2 + 1.0\),  
to the input zonotope $\mathcal{Z}$:

\begin{equation}
\small
\begin{aligned}
f^a(\mathcal{Z})
  &= f(c_1, c_2)
     + \epsilon_1\, f(g_1)
     + \epsilon_2\, f(g_2) \\[4pt]
  &= \big(-0.5\,c_1 + 0.5\,c_2 + 1.0\big)
     + \epsilon_1\big(-0.5\,g_{1x} + 0.5\,g_{1y}\big)
     + \epsilon_2\big(-0.5\,g_{2x} + 0.5\,g_{2y}\big) \\[4pt]
  &= \big(-0.5(1.5) + 0.5(1.0) + 1.0\big)
     + \epsilon_1\big(-0.5(0.5) + 0.5(0)\big)
     + \epsilon_2\big(-0.5(0) + 0.5(2.0)\big) \\[4pt]
  &= 0.75 - 0.25\,\epsilon_1 + 1.0\,\epsilon_2.
\end{aligned}
\end{equation}
Hence, the output zonotope for \(x_3\) is
{\small
\[
\{0.75 + \epsilon_1(-0.25) + \epsilon_2(1.0), \quad \epsilon_1, \epsilon_2 \in [-1,1]\}.
\]
}
\paragraph{Compute output bounds} From the output zonotope, we can compute the lower and upperbounds for \(x_3\) by subtracting and adding the absolute values of the generator coefficients:

\begin{equation}
    \small
\begin{aligned}
f^a_L &= c' - (|g'_1| + |g'_2|) = 0.75 - (0.25 + 1.0) = -0.5, \\
f^a_U &= c' + (|g'_1| + |g'_2|) = 0.75 + (0.25 + 1.0) = 2.0.
\end{aligned}
\end{equation}
Thus, the output range is \(x_3 \in [-0.5, 2.0]\).

% \begin{figure}[h!]
% \centering
% \begin{tikzpicture}[scale=1.0, thick]

% % (a) input intervals
% \node at (1.5,4.2) {(a) Input intervals};
% \draw[->,gray!70] (0,3.6)--(3.4,3.6) node[right]{$x_1$};
% \draw[fill=green!20,draw=green!50!black] (1,3.5) rectangle (2,3.7);
% \node at (1.5,3.9){$[1,2]$};
% \draw[->,gray!70] (0,2.8)--(3.4,2.8) node[right]{$x_2$};
% \draw[fill=green!20,draw=green!50!black] (0.5,2.7) rectangle (3,2.9);
% \node at (1.75,3.1){$[-1,3]$};

% % (b) input zonotope
% \node at (8,4.2) {(b) Input zonotope};
% \draw[->,gray!70] (5.5,2.0)--(10,2.0) node[right]{$x_1$};
% \draw[->,gray!70] (6.0,1.5)--(6.0,5) node[left]{$x_2$};
% \coordinate (A) at (7,1);
% \coordinate (B) at (8,1);
% \coordinate (C) at (8,5);
% \coordinate (D) at (7,5);
% \filldraw[fill=green!15,draw=green!60!black] (A)--(B)--(C)--(D)--cycle;
% \coordinate (c) at (7.5,3);
% \filldraw[red!70] (c) circle (1.5pt) node[below right]{$c=(1.5,1.0)$};
% \draw[->,blue!70,thick] (c)--++(0.5,0) node[midway,below]{$g_1=(0.5,0)$};
% \draw[->,orange!80,thick] (c)--++(0,2.0) node[midway,right]{$g_2=(0,2.0)$};

% % (c) output zonotope (1-D range)
% \node at (13.8,4.2) {(c) Output zonotope};
% \draw[->,gray!70] (12,2.0)--(15.5,2.0) node[right]{$x_3$};
% \draw[fill=green!15,draw=green!60!black] (13.0,1.9) rectangle (14.5,2.1);
% \node at (13.75,2.4){$[-0.5,2.0]$};
% \filldraw[red!70] (13.75,2.0) circle (1.5pt) node[below]{$c'=0.75$};
% \draw[<->,blue!70,thick] (13.75,2.0)--++(-0.25,0) node[midway,below]{$g'_1$};
% \draw[<->,orange!80,thick] (13.75,2.0)--++(1.0,0) node[midway,below]{$g'_2$};

% \end{tikzpicture}
% \caption{(a) Independent input intervals; (b) combined as a 2-D input zonotope; (c) 1-D output zonotope after affine transformation $f(x_1,x_2)=-0.5x_1+0.5x_2+1$.}
% \end{figure}

The reason for computing the bounds from the zonotope representation is to determine stable neurons as described in~\autoref{sec:pre-relu-bounds}. If the lower bound is non-negative, ReLU will be active; if the upper bound is non-positive,  ReLU will be inactive. In these cases, ReLU can be simplified to either the identity function or zero, respectively, which helps reduce overapproximation in subsequent layers.

Note that for this simple example, both interval (\autoref{sec:interval-affine-transformer}) and zonotope abstractions yield identical bounds \([-0.5, 2.0]\).  
The benefit of zonotopes becomes clear in deeper layers, where they preserve linear correlations that interval abstractions lose.
\end{example}

% \begin{example}\label{ex:zonotope_linear_example}
% Consider the DNN in~\autoref{fig:dnn-abs} with inputs \(x_1 \in [1, 2]\) and \(x_2 \in [-1, 3]\). The affine function for neuron \(x_3\) is $f(x_1,x_2) = -0.5\,x_1 + 0.5\,x_2 + 1.0$. We want to compute the bounds for \(x_3\) using zonotope abstraction.

% First, we need to represent the bounds of \(x_1\) and \(x_2\) as a zonotope.
% The center \(c\) represents the midpoint of each input interval:
% {\small
% \[
% c_1 = \frac{1+2}{2} = 1.5, \quad c_2 = \frac{(-1)+3}{2} = 1.0
% \]
% }
% The generator matrix \(G\) captures the half-widths of each interval as diagonal entries:
% {\small
% \[
% G_{11} = \frac{2-1}{2} = 0.5, \quad G_{22} = \frac{3-(-1)}{2} = 2.0
% \]
% }
% This construction creates the zonotope 
% {\small
% \[
% c = \begin{bmatrix}1.5 \\ 1.0\end{bmatrix}, \quad G = \begin{bmatrix}0.5 & 0 \\ 0 & 2.0\end{bmatrix},
% \]
% }
% \noindent which represents exactly the input box: \(x_1 \in [1.5-0.5, 1.5+0.5] = [1,2]\) and \(x_2 \in [1.0-2.0, 1.0+2.0] = [-1,3]\).


% Now we can apply the affine transformation to the input zonotope.  For the weight \(w = [-0.5, 0.5]^\top\) and bias \(b = 1.0\), applying the affine transformer:
% \begin{equation}
%     \small
% \begin{aligned}
% c' &= w^\top c + b = [-0.5, 0.5] \begin{bmatrix}1.5 \\ 1.0\end{bmatrix} + 1.0 = -0.75 + 0.5 + 1.0 = 0.75 \\
% g'_1 &= w^\top g_1 = [-0.5, 0.5] \begin{bmatrix}0.5 \\ 0\end{bmatrix} = -0.25 \\
% g'_2 &= w^\top g_2 = [-0.5, 0.5] \begin{bmatrix}0 \\ 2.0\end{bmatrix} = 1.0 \\
% \end{aligned}
% \end{equation}
% This produces the output zonotope \((0.75, [-0.25, 1.0])\) for \(x_3\).

% Finally, we compute the bounds of \(x_3\) from the zonotope representation:

% \begin{equation}
%     \small
% \begin{aligned}
%     f^a_L &= c' - |g'_1| - |g'_2| = 0.75 - 0.25 - 1.0 = -0.5 \\
%     f^a_U &= c' + |g'_1| + |g'_2| = 0.75 + 0.25 + 1.0 = 2.0
% \end{aligned}
% \end{equation}

%     Note that for this affine operation over a box input, both interval (\autoref{sec:interval-affine-transformer}) and zonotope abstractions yield identical bounds \([-0.5, 2.0]\). The advantage of zonotopes becomes apparent when propagating through multiple layers, where zonotopes preserve linear correlations that intervals lose.
% \end{example}

\subsubsection{ReLU Transformer}

Activation functions like ReLU are non-affine and do not preserve zonotope structure.  
For \(\text{ReLU}(x) = \max(0, x)\), the shape of the input region changes at \(x = 0\): $x < 0$ maps to $0$ (a flat line), while $x \ge 0$ maps to $x$ (a slanted line). Thus, we will over-approximate these shapes with a new zonotope---a parallelogram---that contains the entire ReLU output region.


We can distinguish three possible cases of ReLU depending on the bounds $[l,r]$ of the input zonotope.

\begin{itemize}
    \item \textbf{Active case} (\(l \geq 0\)):  
    All values are non-negative, so \(\text{ReLU}^a(x) = x\) (identity function), i.e., the output zonotope is the same as the input zonotope.  
    

    \item \textbf{Inactive case} (\(u \leq 0\)):  
    All values are negative, so \(\text{ReLU}^a(x) = \{0\}\), i.e., the output zonotope is a single point at zero.  
    

    \item \textbf{Unstable case} (\(l < 0 < u\)):  
    The range crosses zero, requiring over-approximation using a parallelogram that bounds ReLU over \([l, u]\) as described below.
\end{itemize}

\paragraph{Building parallelogram}
Given the input zonotope  $x = \{(c + \sum_{i=1}^m \epsilon_i g_i) \mid \epsilon_i \in [-1,1]\}$ with $x$ ranging over \([l, u]\) where \(l < 0 < u\) (i.e., the unstable case), we construct a parallelogram that bounds the ReLU function over this interval. We capture the parallelogram using two linear constraints representing its upper and lower edges as shown in~\autoref{fig:relu-parallelogram}.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{zonotope_bounds.png}
    \caption{Lower and upper bounds computation for a zonotope input.}\label{fig:relu-parallelogram}
\end{figure}


\begin{itemize}
    \item \textbf{Upper bound constraint:} \(y \leq \lambda x - \lambda l\), where \(\lambda = \frac{u}{u-l}\) is the slope of the line connecting points \((l, 0)\) and \((u, u)\)  
    \item \textbf{Lower bound constraint:} \(y \geq \lambda x\) is the line with the same slope \(\lambda\) passing through \((0, 0)\).
\end{itemize}

Mergining these two constraints, we get the following equation describing all points \((x, y)\) within the parallelogram:
\begin{align*}
    \lambda x \leq \quad &y \quad \leq \lambda x - \lambda l \\
    \Leftrightarrow \quad &y = \lambda x - \alpha \lambda l, \quad \alpha \in [0, 1]
\end{align*}
The parameter \(\alpha\) interpolates between the lower and upper bounds of the parallelogram.  
When \(\alpha = 0\), we are on the lower bound \(y = \lambda x\); when \(\alpha = 1\), we are on the upper bound \(y = \lambda x - \lambda l\).

Our zonotope requires $\epsilon_i \in [-1,1]$, thus we substitute:
\[
\alpha = \frac{1 + \epsilon_{new}}{2}, \quad \epsilon_{new} \in [-1, 1]
\]

For example, when \(\epsilon_{new} = -1\), we have \(\alpha = 0\) (lower bound); when \(\epsilon_{new} = 1\), we have \(\alpha = 1\) (upper bound).

The output zonotope after ReLU transformation is then:
\begin{align*}
    y  & = \lambda x - \alpha \lambda l \\
    &= \lambda x - \frac{1 + \epsilon_{new}}{2} \lambda l\\
      &= \lambda \underbrace{\left(c + \sum_{i=1}^m \epsilon_i g_i\right)}_{x} - \epsilon_{new} \frac{\lambda l }{2} - \frac{\lambda l }{2}  \\
      &= \underbrace{\left(\lambda c -  \frac{\lambda l }{2}\right)}_{\text{new center}} +  \underbrace{\sum_{i=1}^m \epsilon_i (\lambda g_i) - \epsilon_{new} \frac{\lambda l }{2}}_{\text{new generator}}
\end{align*}



\begin{example}[ReLU on zonotope]\label{ex:zonotope_relu_example}
Continuing from~\autoref{ex:zonotope_linear_example}, applying ReLU to the zonotope output

\[
x_3 = 0.75 + \epsilon_1(-0.25) + \epsilon_2(1.0), \quad \epsilon_1, \epsilon_2 \in [-1,1].
\]

\textbf{Determine the bounds of the input zonotope} As shown in~\autoref{ex:zonotope_linear_example}, the output zonotope (before ReLU) has bounds \([-0.5, 2.0]\).   So the input zonotope to ReLU has bounds \([-0.5, 2.0]\). Since \(l = -0.5 < 0 < 2.0 = u\), this is an unstable neuron requiring over-approximation.

\textbf{Approximate Slope}
We compute the slope of the upper bound line of the parallelogram (which connects points \((-0.5, 0)\) and \((2.0, 2.0)\)):

\[
\lambda = \frac{u-0}{u-l} = \frac{2.0}{2.0-(-0.5)} = \frac{2.0}{2.5} = 0.8.
\]

\textbf{Transform zonotope}
The new center becomes:
\[
c' = \lambda c - \frac{\lambda l }{2} = 0.8 \cdot 0.75 - \frac{0.8 \cdot (-0.5) }{2} = 0.6 + 0.2 = 0.8
\]

Existing generators are scaled by \(\lambda\):
\begin{align*}
g'_1 &= \lambda g_1 = 0.8 \cdot (-0.25) = -0.2, \\
g'_2 &= \lambda g_2 = 0.8 \cdot 1.0 = 0.8  
\end{align*}

\textbf{Create new generator for approximation error}
A new generator is introduced to capture the ReLU approximation error:
\[
g'_3 = -\frac{\lambda l }{2} = -\frac{0.8 \cdot (-0.5) }{2} = 0.2
\]

\textbf{Result:} The output zonotope is 

\[
0.8 + \epsilon_1(-0.2) + \epsilon_2(0.8) + \epsilon_3(0.2), \quad \epsilon_i \in [-1,1].
\]
with concrete bounds:
%\((0.8, [-0.2, 0.8, 0.2])\) with concrete bounds:
\begin{align*}
l' &= 0.8 - 0.2 - 0.8 - 0.2 = -0.4 \rightarrow 0 \text{ (clamp negative values)}\\
u' &= 0.8 + 0.2 + 0.8 + 0.2 = 2.0
\end{align*}

Thus, the final bounds after ReLU are \([0, 2.0]\).

\end{example}

\input{longtable_interval_zonotope_simple.tex}



\section{Polytope}
\tvn{not yet done, skip}
% In the previous section, we have seen the abstract domain of zonotopes, which is more expressive than the interval domain. Specifically, instead of approximating functions using a hyper-rectangle, the zonotope domain allows us to approximate functions using a zonotope, e.g., a parallelogram, capturing relations between different dimensions. In this section, we look at an even more expressive abstract domain, the polyhedron (or polytope) domain. 

% Unlike the zonotope domain, the polyhedron domain allows us to approximate functions using arbitrary convex polyhedra. A polyhedron in \(\mathbb{R}^n\) is a region made of straight (as opposed to curved) faces; a convex shape is one where the line between any two points in the shape is completely contained in the shape. Convex polyhedra can be specified as a set of linear inequalities of the form:

% \[
% Ax \leq b
% \]

% where \(A \in \mathbb{R}^{m \times n}\) and \(b \in \mathbb{R}^m\) for some \(m\), specifying \(m\) half-spaces whose intersection forms the polyhedron.

% Using a set of convex polyhedra, we can more precisely approximate activation functions like ReLU. For instance, to approximate ReLU, we can describe the tightest convex over-approximation by the following constraints:

% \[
% x \leq y, \quad 0 \leq y, \quad y \leq \lambda x + \mu
% \]

% where \(\lambda\) and \(\mu\) are parameters chosen based on the bounds of \(x\).

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.5\linewidth]{figure/3-lines-polytope.png}
%     \caption{The tightest Convex Polyhedral Approximation of ReLU.}
%     \label{fig:enter-label}
% \end{figure}
% % \begin{figure}
% %     \centering
% %     \includegraphics[width=0.5\linewidth]{3-lines-polytope.png}
% %     \caption{Enter Caption}
% %     \label{fig:enter-label}
% % \end{figure}

% This is the smallest convex polyhedron that soundly approximates ReLU, and is strictly more precise than the interval and zonotope abstractions, as can be seen visually.

% \subsection{Affine Functions}

% Affine transformations map convex polyhedra to convex polyhedra.  
% Given an affine transformation \(f(x) = Wx + b\), where \(W\) is a matrix and \(b\) is a bias vector, we can transform a polyhedron \(\{x \mid A x \leq b\}\) through \(f\) by substitution:

% \[
% \{x \mid A (W^{-1}(x - b)) \leq b\}
% \]

% if \(W\) is invertible. More commonly in practice, when applying affine transformations in neural networks (layer-wise), we modify the constraints accordingly by propagating through the weights and biases.

% Thus, affine layers can be handled exactly under polyhedral abstraction without any need for relaxation or over-approximation.

% \subsection{Activation Functions}

% Handling non-linear activation functions, such as ReLU, with polyhedral abstraction is challenging because non-linearities generally map polytopes to non-convex shapes. Therefore, over-approximations are required.

% The key idea is to approximate the graph of the non-linear function by a convex polyhedron that covers all possible cases. For ReLU, the previously mentioned three constraints:

% \begin{equation}\label{minimum_polyhedron}
% x \leq y, \quad 0 \leq y, \quad y \leq \lambda x + \mu
% \end{equation}


% construct a tight convex relaxation.

% For other activations like sigmoid or tanh, the approximation involves linearizing the curve between the lower and upper bounds of the input variable, but the number of constraints can quickly grow, increasing computational complexity.

% \paragraph{DeepPoly.}  
% By containing two lower polyhedra constraints for \(y\), the approximation in \ref{minimum_polyhedron} inherently suffers from a potential blow-up in number of constraints as the analysis proceeds. Due to scalability issues associated with general polyhedral representations, DeepPoly \cite{singh2019abstract} was proposed as a precise and scalable abstract domain. DeepPoly introduces a specialized form of polyhedral abstraction combined with interval bounds. 

% More specifically,  DeepPoly only allows for one lower bound in \ref{minimum_polyhedron}, the selection of which lower constraint depends on which constraint provides the tighter approximation.

% Returning to our example, the area of the approximation in Fig.~4(b) is given by \( 0.5 \cdot u \cdot (u - l) \), while the area in Fig.~4(c) is given by \( 0.5 \cdot (-l_i) \cdot (u_i - l_i) \). To achieve a tighter relaxation, we select the approximation with the smaller area. Specifically, when \( u \leq -l \), we apply the constraints and bounds derived from \(x \leq y\).
% In addition, each neuron \(x_j\) is bounded above and below by affine expressions of the input neurons:

% \[
% l_j(x) \leq x_j \leq u_j(x)
% \]

% where \(l_j\) and \(u_j\) are affine functions.

% \subsection{DeepPoly Transformers}

% The DeepPoly abstract domain defines a scalable and precise framework for verifying deep neural networks by combining interval and polyhedral abstractions. Each neuron is bounded from above and below using affine expressions of the input neurons:

% \[
% l_j(x) \leq x_j \leq u_j(x)
% \]

% where \(l_j(x)\) and \(u_j(x)\) are affine functions representing lower and upper bounds respectively. DeepPoly then defines **abstract transformers** to propagate these bounds through different types of neural network layers.

% \subsubsection{Affine Layer Transformer}

% Given an affine transformation:
% \[
% x^{(l+1)} = W x^{(l)} + b
% \]

% we define the transformation of the bounds by propagating the affine expressions directly:
% \begin{align*}
% l_j^{(l+1)}(x) &= \sum_i w_{ji}^+ \cdot l_i^{(l)}(x) + w_{ji}^- \cdot u_i^{(l)}(x) + b_j \\
% u_j^{(l+1)}(x) &= \sum_i w_{ji}^+ \cdot u_i^{(l)}(x) + w_{ji}^- \cdot l_i^{(l)}(x) + b_j
% \end{align*}

% Here, \(w^+_{ji} = \max(w_{ji}, 0)\), and \(w^-_{ji} = \min(w_{ji}, 0)\), ensuring correct handling of sign-dependent propagation.

% \subsubsection{ReLU Transformer}

% The ReLU transformer in DeepPoly uses a convex relaxation that is tighter than previous abstractions by selecting only one lower bound constraint depending on the sign and tightness. Suppose \(x_j = \text{ReLU}(x_i)\). Let \([l_i, u_i]\) be the lower and upper bounds for \(x_i\).

% \begin{itemize}
%     \item If \(l_i \geq 0\): ReLU is linear, so
%     \[
%     l_j(x) = l_i(x), \quad u_j(x) = u_i(x)
%     \]

%     \item If \(u_i \leq 0\): ReLU is constant 0, so
%     \[
%     l_j(x) = u_j(x) = 0
%     \]

%     \item If \(l_i < 0 < u_i\): ReLU is approximated with:
%     \[
%     u_j(x) = \frac{u_i}{u_i - l_i} \cdot (x_i - l_i)
%     \]
%     and only one lower bound is selected:
%     \[
%     l_j(x) =
%     \begin{cases}
%         0, & \text{if area under lower 0 line is smaller} \\
%         x_i, & \text{if area under identity line is smaller}
%     \end{cases}
%     \]
% \end{itemize}

% The decision is made based on which convex region has smaller area to achieve a tighter abstraction, following the principle:
% \[
% \text{Choose constraint with smaller area:} \quad 0.5 \cdot u_i \cdot (u_i - l_i) \quad \text{vs} \quad 0.5 \cdot (-l_i) \cdot (u_i - l_i)
% \]


% By maintaining only upper and lower affine bounds, DeepPoly avoids the full complexity of manipulating arbitrary polytopes while retaining significantly more precision than intervals or zonotopes. 

% ...

% Thus, DeepPoly achieves a practical balance between precision and scalability for verifying deep neural networks.

% \subsection{Example}

% Consider again the DNN in~\autoref{fig:dnn}. Suppose the input set is defined by box constraints \(x_1 \in [-1,1]\) and \(x_2 \in [-2,2]\). These can be represented initially by 4 inequalities.

% Applying the affine transformation for the hidden layer, we obtain a new set of inequalities describing the hidden layer nodes. Upon applying ReLU, we would use the convex polyhedral relaxation as depicted in~\autoref{fig:3_lines_polytope}. The output layer similarly results from affine operations on the polyhedra describing the hidden layer.

% In a DeepPoly setting, instead of carrying full inequalities, we track only the lower and upper affine bounds per neuron, leading to an efficient verification process.

% \subsection{Comparison to Zonotope Abstraction}

% While zonotope abstraction captures dependencies between variables better than intervals, it still assumes symmetrical dependencies around a center point and cannot easily model arbitrary convex shapes.

% Polyhedral abstraction, on the other hand, allows representing arbitrary convex shapes precisely, enabling much tighter approximations, especially after ReLU activations.

% However, traditional polyhedral methods suffer from:
% \begin{itemize}
%     \item High computational complexity,
%     \item Rapid growth in the number of constraints,
%     \item Difficulty scaling to large networks.
% \end{itemize}

% DeepPoly addresses these challenges by:
% \begin{itemize}
%     \item Restricting to simple upper and lower affine bounds,
%     \item Maintaining polynomial scalability,
%     \item Achieving higher precision than zonotopes or intervals,
%     \item Providing efficient transformers for common layers in DNNs.
% \end{itemize}

% Therefore, DeepPoly achieves a balance, combining the expressiveness of polyhedral domains with the efficiency required for deep network verification.


% \section{Abstractions for Other Activation Functions}

% \section{Problems}
% \subsection{Interval Abstraction}

% \begin{example}[Full Example of Interval Abstraction]\label{ex:interval-abstraction-full}
% \begin{figure}[h]
%     \centering
%     \includegraphics[width=1.2\linewidth]{figure/2_layers_example.png}
%     \caption{Feed-forward neural network with 6 layers and 2 neurons per layer.}
%     \label{fig:interval-network}
% \end{figure}
% In~\autoref{fig:interval-network}, we aim to verify whether \(x_{11}\ \geq\ x_{12}\) given a bounded input range on \(x_1\) and \(x_2\). To do this using interval abstraction, we propagate intervals layer by layer.

% Suppose the inputs \(x_1\) and \(x_2\) satisfy:
% \[
% x_1 \in [-1, 1], \quad x_2 \in [-1, 2]
% \]

% Let an affine neuron (e.g., \(x_3\)) compute:
% \[
% x_3 = 1 x_1 + 1 x_2 + 2
% \]

% Then we apply the affine abstract transformer:
% \begin{equation}
% \begin{aligned}
%   x_3 \in & ~[\min(1\times-1, 1\times1) + \min(1\times-1, 1\times3) + 2, \\
%           & ~\max(1\times-1, 1\times-1) + \max(-1\times-1, -1\times3) + 2] = \\
%           & [0,6]
% \end{aligned}         
% \end{equation}

% So we over-approximate \(x_3\) as:
% \[
% x_3 \in [0, 6]
% \]

% This process is repeated for each layer until we reach the output layer.
% Here we can see that by using Interval abstraction, the property \(x_{11}\ \geq\ x_{12}\) or  \(x_{11}\ - x_{12} \geq 0\) is \textit{UNSAT}\hd{seems incorrect} due to
% \[
% -2.5 - 0  \leq x_{11}\ -\ x_{12} \leq 12 - 5
% \]
% \end{example}



\part{The Branch and Bound Approach}\label{part:bab}
\chapter{The Branch and Bound Search Algorithm}\label{chap:bab}

As shown in~\autoref{chap:constraint-solving}, the NNV verification problem can be formulated as a satisfiability problem, solvable using a constraint solver,  e.g., SMT and MILP solvers.  However, such solvers not scale to large DNNs due to the complexity of the underlying formulae. Thus, modern DNN verification techniques reframe the problem to search for \emph{activation patterns} that satisfy the constraints, and use the \emph{Branch-and-Bound} algorithm to explore the space of possible activation patterns.

%These activation patterns fix the activation status (active/inactive) of each neuron, allowing us to simplify involved constraints to linear constraints that are easier to solve. 

%In addition, 



\section{Activation Pattern Search}\label{sec:activation-patterns}

DNNs with piecewise linear activation functions have a special structure that can be exploited for verification.
For example, each ReLU (\autoref{sec:relu}) function partitions the input space into two regions---active and inactive.
Within each region, the DNN behavior can be encoded as \emph{a linear constraint}, which can be efficiently analyzed.

Thus, verifying a DNN reduces to checking that none of these linear regions contains a counterexample. More specifically, we can rewrite the satisfiability formulation in~\autoref{eq:nnv2} as a disjunction:
\begin{equation}\label{eq:nnv3}
  \bigvee_{p \in P} \left( \alpha_p \land \phi_{in} \land \neg \phi_{out} \right)
\end{equation}
where $P$ is the set of all possible \emph{activation patterns}---boolean assignments of activation statuses of all neurons-- of the DNN, and $\alpha_p$ is the formula $\alpha$ restricted to the linear region defined by the activation pattern $p$. This means that $\alpha_p$ includes additional constraints that fix the activation status of each neuron according to $p$. For example, if $p$ specifies that neuron $n_i$ is active, then $\alpha_p$ includes the constraint $z_i \ge 0$, indicating that the pre-activation value $z_i$ of neuron $n_i$ is non-negative. Similarly, if $n_i$ is inactive, then $\alpha_p$ includes $z_i < 0$.

As long as one of the disjuncts in~\autoref{eq:nnv3} is satisfiable, i.e., we could find a counterexample in one of the linear regions, the entire formula is satisfiable, indicating that the property is invalid. Conversely, if all disjuncts are unsatisfiable, the property is valid.

This allows us to break down the verification problem into smaller subproblems, each searches for an activation pattern that satisfies the formula in~\autoref{eq:nnv2}.
Modern DNN verification techniques~\cite{bunel2020branch,wang2021beta,ferrari2022complete,duong2024harnessing,duong2023dpllt,ovalbab,katz2019marabou,bak2021nnenum} all adopt this idea and search for a satisfying activation pattern to find a counterexample.

\subsection{Activation Patterns}
\begin{definition}[Activation Pattern]\label{def:activation-pattern}
Let $N$ be a DNN with ReLU neurons $n_1,\dots,n_m$.  
An \emph{activation pattern} is a Boolean assignment of the activation status of a subset (or all) of the neurons.  
If a neuron $n_i$ is active, we set $b_i = \texttt{true}$ (meaning $z_i \geq 0$); if it is inactive, $b_i = \texttt{false}$ (meaning $z_i < 0$). 
\end{definition}

\begin{definition}[Complete Activation Pattern]\label{def:complete-pattern}
A \emph{complete activation pattern} assigns an activation status to \emph{every} neuron in the DNN:
\[
p = \langle b_1, b_2, \dots, b_m \rangle \in \{\texttt{true},\texttt{false}\}^m .
\]
\end{definition}


\begin{definition}[Partial Activation Pattern]\label{def:partial-pattern}
A \emph{partial activation pattern} assigns activation statuses to only a \emph{subset} of the neurons.  
\[
q = \langle b_1, b_2, *, b_4, *, \dots, b_m \rangle \in \{\texttt{true},\texttt{false},*\}^m ,
\]
where $*$ means ``undetermined'' or ``don't care''. Each partial activation pattern represents multiple complete activation patterns.
\end{definition}




\begin{example}  
Consider a DNN with three ReLU neurons $n_1,n_2,n_3$.  
A complete activation pattern might be 
\[
p = \langle \texttt{true}, \texttt{false}, \texttt{true} \rangle ,
\]
which means $n_1$ and $n_3$ are active while $n_2$ is inactive.  


In contrast, a partial activation pattern such as
\[
q = \langle \texttt{true}, \texttt{false}, * \rangle
\]
represents \emph{both} complete patterns  
$\langle \texttt{true}, \texttt{false}, \texttt{true} \rangle$ and  
$\langle \texttt{true}, \texttt{false}, \texttt{false} \rangle$.  
\end{example}


\begin{definition}[Empty Activation Pattern]\label{def:empty-pattern}
An \emph{empty} activation pattern is a partial pattern that assigns \emph{no} activation statuses to any neurons:
\[
p = \langle *, *, \dots, * \rangle \in \{\texttt{true},\texttt{false},*\}^m .
\]
It thus represents all $2^m$ complete activation patterns.
\end{definition}





\begin{problem}[Pattern Enumeration]\label{problem:pattern-enumeration}
Consider an NN with 3 ReLU neurons:
\begin{enumerate}
  \item How many complete activation patterns are there?
  \item How many partial patterns of size 2 (i.e., fixing 2 neurons but leaving 1 unspecified) are there?
  \item Give an explicit example of one partial pattern and list all the complete patterns it represents.
\end{enumerate}

\begin{solution}
(a) $2^3 = 8$ complete patterns.  
(b) Choose 2 neurons to fix: $\binom{3}{2}=3$ ways. For each, $2^2=4$ assignments. Total = $12$ partial patterns.  
(c) Example: $p'=\{n_1=\mathsf{true}, n_3=\mathsf{false}\}$ represents  
$\{n_1=\mathsf{true},n_2=\mathsf{true},n_3=\mathsf{false}\}$ and  
$\{n_1=\mathsf{true},n_2=\mathsf{false},n_3=\mathsf{false}\}$.  
\end{solution}
\end{problem}


\begin{problem}[Counting Complete Patterns Compatible with a Partial Pattern]
Suppose we have a DNN with $m=10$ ReLU neurons. Consider a partial pattern $p'$ that fixes 4 neurons.
\begin{enumerate}
  \item How many complete patterns extend $p'$?
  \item Suppose we restrict $p'$ further by adding 2 more neuron assignments. How many extensions now?
  \item Generalize: If $p'$ fixes $k$ neurons out of $m$, how many complete patterns are there?
\end{enumerate}

\begin{solution}
(a) $2^{10-4}=2^6=64$.  
(b) $2^{10-6}=2^4=16$.  
(c) General: $2^{m-k}$.
\end{solution}
\end{problem}

\subsection{Set Notation of Activation Patterns}\label{sec:pattern-notation} 
We can use set notation to represent activation patterns more concisely by listing only the neurons whose activation statuses are fixed.
For example, the activation pattern
\[p = \langle \texttt{true}, \texttt{false}, *, \texttt{true}, \texttt{false} \rangle\]
can be represented as
\[p = \{ n_1 = \texttt{true}, n_2 = \texttt{false}, n_3 = *, n_4 = \texttt{true}, n_5 = \texttt{false} \},\]
or more compactly
\[
p = \{n_1, \overline{n_2}, n_4, \overline{n_5}\},
\]
where $n_i$ indicates that neuron $n_i$ is active, $\overline{n_i}$ indicates that it is inactive, and the absence of $n_3$ indicates that its activation status is unspecified.

Thus, given a set of neurons, we can construct an activation pattern by specifying which neurons are active and which are inactive. If the set includes all neurons, it is a complete pattern; otherwise, it is a partial pattern (and if it is an empty set $\emptyset$, it is the empty pattern as shown in~\autoref{def:empty-pattern}).


\subsection{State Space Reduction}\label{sec:pattern-reduction}
Once having an activation pattern $p$, we can simplify the formula $\alpha$ representing the DNN by replacing each ReLU function with a linear constraint according to the activation status specified in $p$. For example, if $p$ specifies that neuron $n_i$ is active, we replace $\relu{z_i}$ with $z_i$ and add the constraint $z_i \ge 0$; if $n_i$ is inactive, we replace $\relu{z_i}$ with $0$ and add the constraint $z_i < 0$.
This gives us the formula $\alpha_p$ corresponding to the linear region defined by $p$.

A complete activation pattern $p$ defines a unique linear region of the DNN. This is because with a complete pattern $p$, $\alpha_p$ becomes a purely linear formula.
In contrast, a partial activation pattern $q$ defines multiple linear regions, one for each complete pattern it represents.  With $q$, $\alpha_q$ may still contain some ReLU functions that are not fixed by $q$.  However, since $q$ fixes the status of some neurons, we can simplify $\alpha$ by replacing the ReLU functions of those neurons with linear constraints.

In any case, given an activation pattern, we can reduce the complexity of the satisfiability check by fixing the activation status of some neurons. Thus, checking the satisfiability of $\alpha_p \land \phi_{in} \land \neg \phi_{out}$ is easier than checking that of $\alpha \land \phi_{in} \land \neg \phi_{out}$.


\begin{example}  
Recall the DNN from~\autoref{fig:dnn-b} can be represented as the formula $\alpha$
\[
\begin{aligned}
& \hat{x}_3 = -0.5x_1 + 0.5x_2 + 1.0 ~\land\\
& \hat{x}_4 = 0.5x_1 - 0.5x_2 + 1.0 ~\land\\    
& x_3 = \relu{\hat{x}_3} ~\land \\
& x_4 = \relu{\hat{x}_4} ~\land \\
& x_5 = -x_3 + x_4 - 1.0,
\end{aligned}
\]

Here $\hat{x}_3$ and $\hat{x}_4$ are the pre-activation values of the ReLU neurons $x_3$ and $x_4$, respectively. 
Thus, if we fix the activation status of $x_3$ and $x_4$, we can simplify $\alpha$ by replacing the ReLUs with linear constraints.


\begin{itemize}
  \item \textbf{Complete activation pattern.}  
  A complete activation pattern specifies the status of both ReLU neurons.  
  For instance,
  \[
  p = \{x_3, \overline{x_4}\}
  \]
  means that $x_3$ is active while $x_4$ is inactive; that is, $\hat{x}_3 \geq 0$ (so $x_3 = \hat{x}_3$) while $\hat{x}_4 < 0$ (so $x_4 = 0$).  
  In this case, $\alpha$ reduces to a single linear constraint (region):
  \[
  x_5 = -(-0.5x_1 + 0.5x_2 + 1.0) + 0 - 1.0 = 0.5x_1 - 0.5x_2 - 2.0 .
  \]

  \item \textbf{Partial activation pattern.}  
  A partial pattern specifies only some activation statuses.  
  For example,
  \[
  q = \{x_3\}
  \]
  means $\hat{x}_3 \geq 0$ but places no restriction on $\hat{x}_4$.  Here, $\alpha$ reduces to
\[
\begin{aligned}
& \hat{x}_4 = 0.5x_1 - 0.5x_2 + 1.0 ~\land\\    
& x_4 = \relu{\hat{x}_4} ~\land \\
& x_5 = -(-0.5x_1 + 0.5x_2 + 1.0) + x_4 - 1.0,
\end{aligned}
\]

Because $q$ does not fix the status of $x_4$, we cannot simplify the ReLU for $x_4$. Thus, the formula still contains a ReLU function which splits $x_4$ into two linear regions corresponding to the two possible activation statuses of $x_4$.
\end{itemize}
\end{example}



\begin{problem}\label{problem:nnv-pattern}
Consider the DNN in \autoref{fig:dnn-b}. Suppose we fix the activation pattern $p=\{x_3, x_4\}$.

\begin{enumerate}
  \item Provide the constraints $\alpha$ induced by $p$.
  \item Consider an invalid property $x_5 > 0$ for inputs $x_1 \in [-1,1], x_2 \in [-2,2]$. Find an activation pattern that satisfies the formula $\alpha_p \land \phi_{in} \land \neg \phi_{out}$. In other words, find a pattern that contains a counterexample to the property.
\end{enumerate}

% \textbf{Solution Sketch:}  
% $b_3=\mathsf{true}$ means $-0.5x_1+0.5x_2+1 \ge 0$.  
% $b_4=\mathsf{false}$ means $0.5x_1-0.5x_2+1 < 0$.  
% Thus, region = $\{(x_1,x_2)\mid -0.5x_1+0.5x_2+1 \ge 0,\;0.5x_1-0.5x_2+1 < 0\}$, a convex polyhedron.  
\end{problem}

%\textbf{Notation}:  e.g.,  {x, notx}  means x is true, not x is false.


% \begin{problem}[Satisfiability via Partial Patterns]
% Let $N$ be a DNN with ReLU neurons $n_1,\dots,n_4$. Suppose we want to verify the property
% \[
% x_1 \in [-1,1],\;x_2 \in [-1,1] \implies y \ge 0.
% \]
% \begin{enumerate}
%   \item Explain how partial activation patterns can be used to prune the search space when checking satisfiability of $\alpha \land \phi_{in} \land (y < 0)$.
%   \item For each partial pattern that fixes $n_1,n_2$ only, describe how you would test whether it is feasible (i.e., corresponds to a non-empty input region).
%   \item Argue why infeasible partial patterns can be safely discarded in verification search.
% \end{enumerate}

% \textbf{Solution Sketch:}  
% (a) Instead of enumerating all $2^4=16$ complete patterns, use partial patterns like $\{n_1=\text{true},n_2=\text{false}\}$ to check feasibility early.  
% (b) Translate ReLU conditions into linear constraints and check satisfiability with an LP/SMT solver.  
% (c) If infeasible, then no input activates that pattern, so no counterexample can lie there.  
% \end{problem}

% \begin{problem}[Overlapping Regions]
% Consider a network with 3 ReLU neurons: $n_1,n_2,n_3$.
% \begin{enumerate}
%   \item Show that the regions defined by different complete activation patterns are disjoint.
%   \item Show that regions defined by different partial activation patterns can overlap. Give an explicit example.
% \end{enumerate}

% \textbf{Solution Sketch:}  
% (a) Complete patterns differ in at least one activation assignment $\Rightarrow$ disjoint regions since ReLU sign constraints are mutually exclusive.  
% (b) Partial patterns donâ€™t fix all neurons. Example: $p'=\{n_1=\mathsf{true}\}$ overlaps with $p''=\{n_2=\mathsf{true}\}$ because both allow different settings of unfixed neurons; their corresponding regions may intersect.  
% \end{problem}


%\tvn{may need to add some trees}


\section{The Branch and Bound Algorithm}\label{sec:bab-alg}

Many modern DNN verifiers adopt the Branch-and-Bound (BaB) approach to explore the space of possible neuron activation patterns (\autoref{sec:activation-patterns}). BaB splits (\emph{branch}) the verification problem into smaller subproblems by fixing activation statuses of neurons, and uses abstraction (\emph{bound}) techniques to compute upper and lower bounds on the output values for these subproblems. If the bounds, computed using abstraction (\autoref{chap:abstractions}), indicate infeasible (cannot contain a counterexample), the subproblem is pruned from the search space. This process continues until either a counterexample is found or all subproblems are exhausted, proving the property holds. 

Note that because BaB splits ReLU neurons into active/inactive cases, it is also called \emph{``neuron-splitting''}, which contrasts with \emph{``input-splitting''} techniques (\autoref{sec:input-splitting}) that partition the input space.

\SetKwData{nextlayer}{layer$_{i+1}$}
\SetKwData{status}{status}
\SetKwData{minimum}{objval}

\SetKwFunction{InputMILP}{AddInputConstrs}
\SetKwFunction{GetUnstableNeurons}{GetUnstableNeurons}
\SetKwFunction{PiecewiseLinearMILP}{AddConstrsPWL}
\SetKwFunction{LinearMILP}{AddConstrsLinear}
\SetKwFunction{Maximize}{Maximize}
\SetKwFunction{Minimize}{Minimize}
\SetKwFunction{Feasible}{CheckFeasibility}
\SetKwFunction{Optimize}{Optimize}
\SetKwFunction{isPiecewiseLinear}{isPiecewiseLinear}
\SetKwFunction{CreateStabilizedMILP}{CreateStabilizedMILP}
\SetKwFunction{GetLeafNodes}{GetLeafNodes}
\SetKwFunction{AddConstrs}{AddConstrs}
\SetKwFunction{RemoveConstrs}{RemoveConstrs}
\SetKwFunction{AddObjective}{AddObjectives}
\SetKwFunction{ShortenSplitConstrs}{ShortenSplitConstrs}
\SetKwFunction{RemoveLeafNodes}{RemoveLeaves}
\SetKwFunction{StoppingConditions}{StoppingConditions}
\SetKwFunction{RepOK}{RepOK}
\SetKwFunction{RaiseError}{RaiseError}
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\SetKw{Break}{break}
\SetKw{Continue}{continue}
\SetKwFunction{Backtrack}{Backtrack}
\SetKwFunction{Select}{Select}
\SetKwFunction{Decide}{Decide}
\SetKwFunction{BCP}{BCP}
\SetKwFunction{Deduce}{Deduce}
\SetKwFunction{AnalyzeConflict}{AnalyzeConflict}
\SetKwFunction{BooleanAbstraction}{BooleanAbstraction}
\SetKwFunction{AddClause}{AddClause}
\SetKwFunction{isTotal}{isTotal}
\SetKwFunction{randomattack}{RandomAttack}
\SetKwFunction{pgd}{PGDAttack}

\SetKwFunction{DPLLT}{DPLLT}
\SetKwFunction{isValid}{isValid}
\SetKwFunction{isEmpty}{isEmpty}
\SetKwFunction{LPSolver}{LPSolver}
\SetKwFunction{Solve}{Solve}
\SetKwFunction{FindLayerNodes}{FindLayerNodes}
\SetKwFunction{TightenInputBounds}{TightenInputBounds}
\SetKwFunction{Abstract}{Abstract}
\SetKwFunction{Check}{Check}
\SetKwFunction{Decide}{Decide}
\SetKwFunction{Imply}{Imply}
\SetKwFunction{Lower}{LowerBound}
\SetKwFunction{Upper}{UpperBound}
\SetKwFunction{GetInputBounds}{GetInputBounds}
\SetKwFunction{GetInputs}{GetInputs}
\SetKwFunction{GetNumInputs}{GetNumInputs}
\SetKwFunction{CurrentConflictClause}{CurrentConflictClause}
\SetKwFunction{StopCriterion}{StopCriterion}
\SetKwFunction{LastAssignedLiteral}{LastLiteral}
\SetKwFunction{LiteralToVariable}{LiteralToVariable}
\SetKwFunction{Antecedent}{Antecedent}
\SetKwFunction{BinRes}{BinRes}
\SetKwFunction{BacktrackLevel}{BacktrackLevel}
\SetKwFunction{AddClause}{AddClause}
\SetKwFunction{ActivationStatus}{ActivationStatus}
\SetKwFunction{Backjump}{Backjump}
\SetKwFunction{EstimateBounds}{EstimateBounds}
\SetKwFunction{LP}{LP}

\SetKwData{implicationgraph}{igraph}
\SetKwData{literal}{lit}
\SetKwData{variable}{var}
\SetKwData{antecedent}{ante}
\SetKwData{conflict}{conflict}
\SetKwData{none}{none}
\SetKwData{layerid}{lid}
\SetKwData{hiddenbounds}{hidden\_bounds}
\SetKwData{inputs}{inputs}
\SetKwData{inputbounds}{input\_bounds}
\SetKwData{outputbounds}{output\_bounds}
\SetKwData{infeasible}{INFEASIBLE}
\SetKwData{unreachable}{UNREACHABLE}
\SetKwData{maxinputs}{MAX\_NUM\_INPUT}
\SetKwData{assignment}{$\sigma$}
\SetKwData{dl}{dl}
\SetKwData{lpmodel}{solver}
\SetKwData{clauses}{clauses}
\SetKwData{conflict}{conflict}
\SetKwData{clause}{clause}
\SetKwData{igraph}{igraph}
\SetKwData{cex}{cex}
\SetKwData{mysat}{sat}
\SetKwData{myunsat}{unsat}


\SetKwData{submodel}{sub\_model}

\SetKwData{true}{true}
\SetKwData{false}{false}
    
\SetKwFunction{Restart}{Restart}

\SetKwData{counterexample}{cex}
\SetKwData{conflictclause}{conflict\_clause}
\SetKwData{isconflict}{is\_conflict}


\SetKwData{problems}{ActPatterns}
\begin{algorithm}[t]
    \small
    \Input{DNN $\mathcal{N}$, property $\phi_{in} \Rightarrow \phi_{out}$}
    \Output{$\myunsat$ if property is valid, otherwise ($\mysat, \counterexample$)}
    \BlankLine

    $\problems \leftarrow \{ \emptyset \}$ \tcp{initialize verification problems}\label{line:babinit}  
    % $\prooftree \gets \{ ~ \}$ \tcp{initialize proof tree}\label{line:prooftree}
    
    \While(\tcp*[h]{main loop}){$\problems$}{\label{line:babstart}
        $\sigma_i \gets \Select(\problems)$ \tcp{process problem $i$-th}\label{line:babselect}
        % \Parfor(\tcp*[h]{process in parallel}){$\sigma_i ~\In~ \problems$}{ \label{line:parfor}
            \If{\Deduce{$\mathcal{N}, \phi_{in}, \phi_{out}, \sigma_i$}}{\label{line:babdeduce}
                $\counterexample \leftarrow \LP(\mathcal{N}, \phi_{in}, \phi_{out}, \sigma_i)$ \tcp{check satisfiability}\label{line:bablp}
                \If(\tcp*[h]{found a valid cex}){$\counterexample$}{
                    \Return{$(\mysat, \counterexample)$}\label{line:babsat} 
                }
                $v_i \leftarrow \Decide(\mathcal{N}, \sigma_i)$\label{line:babdecide}\\
                \tcp{create new activation patterns}
                $\problems \leftarrow \problems \cup \{ \sigma_i \cup \{v_i\} ~;~ \sigma_i \land \{\overline{v_i}\} \}$
            }
            %\Else(\tcp*[h]{detect a conflict}){
                % $\clauses \leftarrow \clauses \cup \AnalyzeConflict(\igraph_i)$ \\ \label{line:analyze_conflict}
            %    $\prooftree \leftarrow \prooftree \cup \{ \sigma_i \}$ \tcp{build proof tree} \label{line:record_proof}
            %}
        % }
        % \If(\tcp*[h]{no more problems}){$\isEmpty(\problems)$}{
        % }
        
    }\label{line:babend}
    \Return{\myunsat}\label{line:babunsat}
    
    \caption{The \bab{} algorithm.}\label{alg:bab}
\end{algorithm}


\paragraph{Reference Alg} \autoref{alg:bab} shows \bab{}, a reference~\cite{nakagawa2014consolidating} BaB architecture for DNN verification. \bab{} takes as input a ReLU-based DNN $\mathcal{N}$ and a formulae $\phi_{in}\Rightarrow \phi_{out}$ representing the property of interest.
\bab{} maintains a set of activation patterns (\problems) that represent the current activation pattern of the network. Initially, \problems is initialized with an empty activation pattern (\autoref{line:babinit}).


In each BaB iteration $i$ (\autoref{line:babstart}), the algorithm selects and removes an activation pattern $\sigma_i$ from \problems (\autoref{line:babselect}).  
It then calls \Deduce to \emph{quickly} determine if the current problem, i.e., the original satisfiability problem with  activation pattern $\sigma_i$,
is feasible. For example, it can use interval abstraction (\autoref{chap:abstractions}) to quickly computes the bounds of the output values with respect to $\sigma_i$, e.g., by replacing ReLU functions according to the activation statuses specified in $\sigma_i$ (\autoref{sec:pattern-reduction}). 

If the computed bounds indicate that no counterexample can exist, e.g., the lower bound of the output is greater than 0 when checking $y < 0$, then the problem is \emph{infeasible}. Otherwise, the problem is \emph{potentially feasible} (because the bounds are over-approximations).

(Note that we do this even on the empty activation pattern, which is the initial state of the search, because the problem might be trivially infeasible, in which case we can exit and return \unsat{} immediately (\autoref{line:babunsat}).)
\begin{itemize}

\item If \Deduce determines that the problem is infeasible, \bab{} discards the current processing activation pattern and loops back (to~\autoref{line:babstart}) to process the next activation pattern. In other words, it prunes the current search branch with activation pattern $\sigma_i$.
When there are no more activation patterns to process, \bab{} returns \unsat{} (\autoref{line:babunsat}), indicating that it cannot find counterexamples and the property is valid.


\item If \Deduce determines that the problem is feasible, \bab{} checks the satisfiability of the problem using an LP solver (\autoref{line:bablp})\footnote{The problem is formulated as a MILP problem as described in~\autoref{sec:using-milp} and checked using an LP solver. Note that we use LP and MILP interchangeably here for simplicity. In practice, most LP solvers such as Gurobi handles MILP problems as well. Just like SMT solvers handle both SAT and SMT problems.}. If the solver finds a satisfying assignment, it returns \sat{} and the counterexample represented by the satisfying assignment (\autoref{line:babsat}), indicating that the property is invalid.
Otherwise, \mycode{LP} returns unsatisfiable, and \bab{} calls \Decide to select a neuron $v_i$ to split, i.e., to fix the activation status of $v_i$ as either active or inactive (\autoref{line:babdecide}).  This means the problem is split into two independent subproblems: one with $v_i$ (active) and the other with $\overline{v_i}$ (inactive). 
By splitting (or fixing the neuron status), we create two \emph{simpler} subproblems (less neurons to abstract) that are easier to solve. Thus, this step \emph{refines} the precision of abstract interpretation.
\bab{} then adds the two new activation patterns $\sigma_i \land v_i$ and $\sigma_i \land \overline{v_i}$ to \problems. \bab{} then loops back to~\autoref{line:babstart} to process the next activation pattern.
\end{itemize}


\paragraph{\textbf{Deduce vs. LP}} Note the difference between \Deduce and \mycode{LP} is that the former uses abstraction to compute over-approximated bounds to determine feasibility, while the latter uses an LP solver to check exact satisfiability. 
Abstraction is quick but may yield false positives (declaring feasible when it is not), while LP is precise but more computationally expensive.  Their combination allows \bab{} to efficiently prune infeasible branches while accurately checking for counterexamples.


%\tvn{shows that \bab{} often does not exhaust all activation patterns, but rather prunes the search space by deducing infeasibility of some activation patterns.  May be use a tree example to illustrate this?}

%it analyzes the conflict and adds a new clause to the set of clauses (\texttt{clauses}) to prevent the same activation pattern from being selected again.
%The algorithm continues until there are no more activation patterns to process, at which point it returns \unsat, indicating that the property is valid. If a counterexample is found during the search, it returns \sat along with the counterexample. 




%To add proof generation capability, \bab{} is instrumented with a proof tree (\texttt{proof}) variable (\autoref{line:prooftree}) to record these branching decisions. The proof is represented as a binary tree structure, where each node represents a neuron and its left and right edges represent its activation decision (active or inactive). %The proof tree is then used to generate a proof in the \prooflang{} format (\autoref{sec:proof-format}).





\begin{example}\label{ex:bab} 
\autoref{fig:bab-example}a illustrates a DNN and how \bab{} verifies that this DNN has the property 
\[
(x_1, x_2) \in [-2.0, 2.0] \times [-1.0, 1,0] \Rightarrow (y_1 > y_2),
\] 
by showing that counterexample exists, i.e., no inputs $(x_1,x_2)$ in the given input range such that $y_1 \le y_2$.

\begin{figure}
    \begin{minipage}[b]{\linewidth}
        \centering
        \begin{minipage}[t]{0.52\textwidth}
            \centering  
            \proofnet{0.8}
            \caption*{(a)}
        \end{minipage}
        \begin{minipage}[t]{0.45\textwidth}
            \centering
            \includegraphics[width=\linewidth]{figure/proof_tree.pdf}
            \caption*{(b)}
        \end{minipage}
        \caption{(a) A simple DNN  (similar to~\autoref{fig:proofnet}), and (b) BaB search tree. White nodes correspond to \bab{} neuron splitting. Red nodes correspond to leaf nodes where \bab{}determines infeasibility and prunes the branch.}
        \label{fig:bab-example}
    \end{minipage}
\end{figure}


First, \bab{} initializes \problems{}\footnote{\mycode{Queue} is often used to implement the problems set \problems.} with an empty activation pattern $\emptyset$ (i.e., no neurons fixed). 
Then \bab{} enters its main loop.

\begin{enumerate}
\item \textbf{First iteration}~\bab{} selects the only available activation pattern $\emptyset$, i.e., $\sigma_i = \emptyset$,
and  calls \Deduce to check the feasibility of the problem based $\sigma_i$.

Here, \Deduce determines that the problem is feasible, e.g., the bounds of $y_1$ and $y_2$ indicate that $y_1 \le y_2$ can be satisfied. Thus, \bab{} calls \mycode{LP} to check the satisfiability of the problem using an LP solver. The LP solver returns unsatisfiable (or unknown)--meaning no counterexample is found in this activation pattern.  \bab{} then randomly selects a neuron to split (\Decide). Assume that it chooses $v_4$ to split, i.e., the problem spawns two independent subproblems: one with $v_4$ active and the other with $v_4$ inactive.
It does so by unioning $\{v_4\}$ and $\{\overline{v_4}\}$ with $\sigma_i$ and adds both new activation patterns to \problems. Next, \bab{} loops back to process the next activation pattern.


\item \textbf{Second iteration}~\bab{} has two subproblems. For the subproblem with activation pattern $\{v_4\}$, \Deduce decides feasibility but \mycode{LP} returns unsatisfiable (or unknown), 
so it selects $v_2$ to split by adding $\{v_4, v_2\}$ and $\{v_4, \overline{v_2}\}$ to \texttt{ActPatterns}. 
For the other subproblem with $\overline{v_4}$ inactive, \Deduce determines infeasibility and thus discards this subproblem.

\item \textbf{Third iteration}~\bab{} has two subproblems corresponding to activation patterns $\{v_4, v_2\}$ and $\{v_4, \overline{v_2}\}$. For the first subproblem, \bab{} selects $v_1$ to split by unioning $v_1$ and then $\overline{v_1}$ to the current activation pattern $v_4 \land v_2$ and adds them to \problems. For the second subproblem, \Deduce determines infeasibility and \bab{} discards this subproblem.

\item \textbf{Fourth iteration}~\bab{} has two subproblems corresponding to activation patterns $\{v_4, v_2, v_1\}$ and $\{v_4, v_2, \overline{v_1}\}$, both which are then determined infeasible and discarded.

\item \textbf{Fith iteration}~Finally, \bab{} has no more activation patterns in \problems, stops the search, and returns \unsat{}, indicating that the property is valid.
\end{enumerate}

\autoref{fig:bab-example}b illustrates the BaB search tree corresponding to the above process. Each white node represents a branching decision where \bab{} splits a neuron, while each red node represents a leaf node where \Deduce determines infeasibility and prunes the branch. Notice that not all activation patterns are explored because some branches are pruned early due to infeasibility. In other words, while there are $2^4=16$ possible complete activation patterns for the three ReLU neurons, \bab{} only explores 6 of them in this example.
\end{example}


\begin{problem}\label{prob:bab-detailed}
Do~\autoref{ex:bab} but come up with concrete values for each step, e.g., what are the bounds computed by \Deduce, what does \mycode{LP} return, etc to illustrate the process in more detail.
\end{problem}


\begin{problem}\label{prob:bab-counterexample}
Do~\autoref{ex:bab} but assume the property is invalid and find a counterexample. It is also OK to change the problem, e.g., the input bounds or the property itself, to make it invalid.
\end{problem}


\begin{problem}\label{prob:bab-interval}
\begin{figure}
\centering
\mydnn{1}
\caption{\label{fig:dnn-bab}A simple DNN (similar to~\autoref{fig:dnn}).}
\end{figure}

Apply BaB on the DNN in \autoref{fig:dnn-bab} to verify the property $x_5 > 0$ for any inputs $x_1 \in [-1,1], x_2\in[-2,2]$.  Use interval abstraction to compute bounds. For LP solving, you can use any LP solver or solve it manually. Show all steps, e.g., iterations, activation patterns, bounds computed, LP results, etc.

\end{problem}


\begin{problem}\label{prob:bab-understanding}
Test your understanding of BaB and activation patterns by answering the following questions:
\begin{enumerate}

  \item In \autoref{alg:bab}, what happens if \Deduce always returns infeasible?
  \item What happens if \Deduce always returns feasible but \mycode{LP} always returns satisfiable?
  \item What is the maximum number of activation patterns that \bab{} may need to explore in the worst case for a DNN with $m$ ReLU neurons?
  \item What is the minimum number of activation patterns that \bab{} may need to explore in the best case for a DNN with $m$ ReLU neurons? What are these patterns?
\end{enumerate}
\end{problem}

\subsection{Beyond the Basic} What described above is the basic and minimal BaB algorithm. Modern DNN verifiers implement many optimizations and strategies to improve the performance of the search. For example, they apply various engineering tricks to eliminate easy cases or find easy counterexamples (\autoref{chap:adversarial-attacks}) before running the full BaB search. 


Even the BaB search itself is optimized to avoid exploring the entire search space. For example, if \Deduce step determines infeasibility, a smarter \bab{} variant (e.g., the \neuralsat{} tool) can analyze the conflict and add a new clause to the set of clauses (\texttt{clauses}) to prevent the same activation pattern from being selected again. This is similar to conflict-driven clause learning (CDCL) in modern SAT solvers and is implemented in the \neuralsat{} DNN verification tool~\cite{duong2025neuralsat}. In addition, heuristics are also used to select, e.g., which neuron to split next (\Decide). We explore these optimizations and strategies in later chapters (e.g.,~\autoref{chap:neuralsat}).

% \tvn{TODO: this basic BaB is also used to create a proof tree, which is used to generate a proof in the \prooflang{} format. We will discuss this in~\autoref{chapter:proof-gen-check}.}





\chapter{Adversarial Attacks}\label{chap:adversarial-attacks}


A full branch and bound (BaB) search (\autoref{chap:bab}) is typically expensive and slow on large networks. Thus most DNN verification tools implement optimizations to improve performance. A common optimization is to use \emph{adversarial attack} techniques to find counterexamples before running BaB. 
Examples of such techniques include randomized attacks~\cite{das2021fast} and gradient-based attacks~\cite{madry2017towards}, described in \autoref{chap:adversarial-attacks}.

Thus, modern verification tools have two phases: (i) attempt to \emph{falsify} the property with adversarial attacks, and (ii) if no counterexample is found, attempt to \emph{verify} the property using search algorithms such as \bab{} (\autoref{chap:bab}). Of course, during the verification phase, the verifier may also discover counterexamples that the falsify phase misses.


\section{Random Search Attack}
\textbf{Random search} is a simple adversarial attack method.  It randomly samples points in the allowed input ranges and checks if any samples violate the property; if so, a counterexample is found.

\begin{example}\label{ex:random-search}
Suppose the DNN input ranges are:
\[
-1 \leq x_1 \leq 1,\quad -2 \leq x_2 \leq 2
\]
and the network output is:
\[
y = 2x_1 - 1.5x_2 + 1.
\]
We wish to use random search to find a counterexample to the property $y > 0$; i.e.,  trying random inputs $(x_1, x_2)$ satisfying the given ranges and producing $y \leq 0$.


\begin{itemize}
    \item Try 1: $x_1 = 0.2,\ x_2 = -0.5$
    \[
    y = 2 \times 0.2 - 1.5 \times (-0.5) + 1 = 0.4 + 0.75 + 1 = 2.15 > 0
    \]
    Not a violation.

    \item Try 2: $x_1 = -1,\ x_2 = 2$
    \[
    y = 2 \times (-1) - 1.5 \times 2 + 1 = -2 - 3 + 1 = -4 < 0
    \]
    \textbf{Counterexample found}: $(x_1 = -1,\ x_2 = 2)$.
\end{itemize}
\end{example}

\begin{problem}
Consider the input ranges
\[
-1 \le x_1 \le 1, \quad -1 \le x_2 \le 1,
\]
and network output
\[
y = 3x_1 + 2x_2 - 2.
\]

Use random search to find a counterexample to the property $y > 0$:
\begin{enumerate}
    \item Randomly sample three valid points and compute $y$ at each point.
    \item Check if any sample violates the property. Note, if none violates, that's OK; just report the results.
    \item Based on your samples, discuss whether random search is likely to be efficient for this problem.
\end{enumerate}
\end{problem}



\section{Projected Gradient Descent (PGD)}

\textbf{PGD} is a powerful and widely used adversarial attack that builds on the idea of \emph{gradient descent}.
Gradient descent is the procedure of repeatedly moving the input a small amount in the direction that most rapidly \emph{decreases} (or, for an attack, increases the likelihood of) some objective by following the negative (or positive) gradient.

Specifically, at each step PGD computes the gradient of the network output with respect to the input and takes a small gradient-descent step that pushes the input toward a stronger property violation. Next, PGD \emph{projects} (clips) the updated input back into the allowed domain if the step goes outside the input bounds.

We will reuse~\autoref{ex:random-search} to illustrate PGD. Here,  the DNN input ranges are $-1 \leq x_1 \leq 1,~-2 \leq x_2 \leq 2$, and the output is $y = 2x_1 - 1.5x_2 + 1$, and the goal is to find a counterexample that satisfies the input ranges and produces $y \leq 0$.


\begin{enumerate}
    \item \textbf{Initialize}  
    Choose a valid starting input, for example:
    \[
    (x_1^{(0)}, x_2^{(0)}) = (0, 0)
    \]
    This point is within the allowed input ranges, but does not violate the property $y > 0$ because $y = 2*0-1.5*0 + 1 = 1 > 0$. So we need to continue.

    \item \textbf{Iterative update}  
    For each step $t = 0, 1, 2, \ldots$:
    \begin{enumerate}
        \item \textbf{Compute the gradient.}  
        The gradient $\nabla_x y$ tells us how sensitive the output $y$ is to each input variable:
        \[
        \nabla_x y = \left( \frac{\partial y}{\partial x_1}, \frac{\partial y}{\partial x_2}, \ldots, \frac{\partial y}{\partial x_n} \right)
        \]
        It represents the direction of steepest \emph{increase} in $y$.  
        To move toward a smaller $y$ (to make violation $y \le 0$ more likely), we go in the \emph{opposite} direction, i.e., $-\nabla_x y$.

        For example, if:
        \[
        y = 2x_1 - 1.5x_2 + 1,
        \]
        then the partial derivatives are:
        \[
        \frac{\partial y}{\partial x_1} = 2, \qquad
        \frac{\partial y}{\partial x_2} = -1.5,
        \]
        resulting in the gradient:
        \[
        \nabla_x y = (2, -1.5).
        \]
        This gradient means that increasing $x_1$ by a small amount increases $y$ by about twice that amount, while increasing $x_2$ by a small amount decreases $y$ by about 1.5 times that amount.

         
         
        \item \textbf{Gradient update}  
        Move a small distance $\eta$ (called the \emph{step size} or \emph{learning rate}) in the negative gradient direction:
        \[
        x_1^{(t+1)} = x_1^{(t)} - \eta \cdot 2, \qquad
        x_2^{(t+1)} = x_2^{(t)} - \eta \cdot (-1.5)
        \]
        This decreases $y$ as quickly as possible.

        For example, if $\eta = 0.5$ and starting from $(x_1^{(0)}, x_2^{(0)}) = (0, 0)$:
        \[
        x_1^{(1)} = 0 - 0.5 \times 2 = -1.0, \qquad
        x_2^{(1)}   = 0 - 0.5 \times (-1.5) = +0.75
        \]
        Thus, the candidate input after one step is $(-1.0, +0.75)$.

        \item \textbf{Project (Clip) to valid input range}  
        If the new values go outside the valid range, bring them back to the closest valid boundary:
        \[
        x_1^{(t+1)} = \max(-1, \min(x_1^{(t+1)}, 1)), \qquad
        x_2^{(t+1)} = \max(-2, \min(x_2^{(t+1)}, 2))
        \]
        This ensures every step stays within $[-1, 1] \times [-2, 2]$.

        Our candidate input $(-1.0, +0.75)$ is already within the valid ranges, so no clipping is needed.    

        \item \textbf{Check for violation}  
        Compute the output at the new input.  
        If $y(x^{(t+1)}) \le 0$, then a counterexample has been found, and the attack succeeds.

        In our example, compute:
        \[
        y = 2(-1) - 1.5(0.75) + 1 = -2 - 1.125 + 1 = -2.125 <   0
        \]
        Thus, PGD finds a counterexample at $(x_1, x_2) = (-1, 0.75)$.

    \end{enumerate}
\end{enumerate}


\begin{example}[PGD with Clipping]
We continue the example above but with a larger step size $\eta = 1.0$. Starting again from $(x_1^{(0)}, x_2^{(0)}) = (0, 0)$:
\[
\begin{aligned}
x_1^{(1)} &= 0 - 1.0 \times 2 = -2.0 \\
x_2^{(1)} &= 0 - 1.0 \times (-1.5) = +1.5
\end{aligned}
\]
Here, $x_1^{(1)} = -2.0$ is outside the allowed range $[-1, 1]$, so we \emph{clip} it:
\[
x_1^{(1)} = -1 \quad (\text{projected to boundary})
\]
Meanwhile, $x_2^{(1)} = 1.5$ is within $[-2, 2]$, so it remains unchanged.

After projection, we have:
\[
(x_1^{(1)}, x_2^{(1)}) = (-1, 1.5)
\]

Compute the output:
\[
y = 2(-1) - 1.5(1.5) + 1 = -2 - 2.25 + 1 = -3.25 < 0,
\]
which is a counterexample.

\end{example}


\begin{example}
Consider
\[
y = x_1^2 + 3x_2.
\]
The gradient of $y$ with respect to $(x_1, x_2)$ is
\[
\nabla_x y = \left( \frac{\partial y}{\partial x_1}, \frac{\partial y}{\partial x_2} \right).
\]
Compute each partial derivative:

\[
\frac{\partial y}{\partial x_1} = 2x_1, \qquad
\frac{\partial y}{\partial x_2} = 3.
\]
Therefore the gradient is
\[
\nabla_x y = (2x_1,\ 3).
\]

For instance, at point $(x_1, x_2) = (1, 2)$,
\[
\nabla_x y = (2 \times 1,\ 3) = (2, 3).
\]
This means that near $(1,2)$, increasing $x_1$ by a small amount increases $y$ twice as fast as that same increase in $x_2$ would.
\end{example}


\begin{problem}\label{prob:compute-gradients}
For each of the following output functions, compute the gradient
\[
\nabla_x y = \left( \frac{\partial y}{\partial x_1}, \frac{\partial y}{\partial x_2} \right).
\]
\begin{enumerate}
    \item $y = 2x_1 - x_2 + 1$
    \item $y = -x_1^2 + 4x_2$
    \item $y = 3x_1x_2 - x_2^2$
\end{enumerate}
Explain what the gradient tells you about how $y$ changes with $x_1$ and $x_2$.
\end{problem}

\begin{problem}\label{prob:pgd-iterations}
Let
\[
y = 2x_1 - 3x_2 + 1, \quad -1 \le x_1, x_2 \le 1.
\]
Starting from $(x_1^{(0)}, x_2^{(0)}) = (0, 0)$ with some step size $\eta > 0$, use PGD to minimize $y$ so that it violates the property $y > 0$. Show all steps (e.g., computing gradient, updating point, clipping, etc) until a counterexample is found.

Depend on your choice of step size $\eta$, your PGD might have one or more iterations before finding a counterexample. Thus, for this problem, identify at least two different step sizes $\eta_1$ and $\eta_2$ such that:
\begin{itemize}
    \item With step size $\eta_1$, PGD finds a counterexample in one iteration.
    \item With step size $\eta_2$, PGD finds a counterexample in two or more iterations.
\end{itemize}   

\end{problem}





\chapter{Proof Generation and Checking}\label{chap:proof-gen-check}

%Advances in DNN verification have made it possible to reason about the safety and robustness of complex DNNs. 
As DNN tools become more complex (e.g., state-of-the-art tools have 20K+ LoCs), they are more prone to bugs. VNN-COMP'23~\cite{brix2023fourth} showed that 3 of the top 7 participants produced unsound results by claiming unsafe DNNs are safe, i.e., they produce \unsat{} on problems that are actually \sat{}. %This is a serious issue, as it can lead to unsafe DNNs being deployed in safety-critical applications, such as autonomous driving and medical diagnosis.

While checking counterexamples is relatively straightforward (we can just evaluate the DNN on the input), checking \unsat{} results---proving no counterexample exists---is more challenging as it requires tracing the reasoning steps of the verifier.
In this chapter, we discuss work~\cite{duong2025generating} on generating and checking proofs of \unsat{} results generated by BaB-based DNN verifiers.


%Moreover, there are many verification approaches (e.g., branch and bound, conflict-driven learning, abstraction and refinement), making it difficult to standardize and compare results across different tools.
%This is unlike SAT solving, where most tools adopt the standard DPLL framework and thus allows for unified techniques in proof generation and checking (e.g., the DRAT family of algorithms for UNSAT proofs).

%\section{Proof Generation}\label{sec:proofgen}

% To successfully deploy DNN verification tools in safety-critical applications, it is essential to provide guarantees that the verification results are correct, i.e., it won't claim an unsafe DNN as safe. One way to achieve this is to generate proofs of the verification results, i.e., a sequence of logical steps that demonstrates the validity of the verification result.
% Ideally, the proof generation process should be automated and integrated into the verification tool, so that the proof can be generated and checked automatically. The challenge is that there are many different DNN verification techniques, each with its own decision-making process, making it difficult to standardize proof generation across different tools. 


%A proof of satisfiability (sat) is an input that violates the property, i.e., a counterexample.  We can easily  check such a counterexample $c$ by evaluating $\phi(c,N(c))$ (i.e., running the DNN on the counterexample).
%In fact, VNN-COMPs already requires competing DNN verification tools to return counterexamples demonstrating satisfiability.  

%In contrast, the proof of an unsatisfiability result---which explains why \emph{no possible inputs} can violate %the property---is inherently more complex to generate (\autoref{sec:proofgen}), requires a more sophisticated encoding (\autoref{sec:prooflang}), and an efficient checking algorithm (\autoref{sec:proofchecking}). We are mainly interested in \unsat{} proofs.





%\emph{Branch-and-bound} (BaB) is a common approach to DNN verification and used by major DNN verification tools including~\cite{bunel2020branch,wang2021beta,ferrari2022complete,duong2024harnessing,duong2023dpllt,ovalbab}.
%In BaB algorithms, ``branch'' means splitting the problem into smaller subproblems (like a search tree), and ``bound'' means computing the upper and lower bounds, using abstraction, of the problem to prune the search space. 



%Among modern DNN verification techniques, only the simplex-based approach attempts to generate proofs~\cite{desmartin2023towards,barbosa2023generating}. However, generating a proof for simplex-based approaches is non-trivial and incurs a significant overhead during the verification process~\cite{desmartin2023towards,barbosa2023generating}.

%Recently, an approach based on the DPLL(T) algorithm in SAT/SMT solving has shown much promise~\cite{duong2023dpllt}. For example, in its debut year, the DPLL(T)-based \neuralsat{} DNN verifier~\cite{duong2023dpllt} won the New Comer Award at VNN-COMP'23~\cite{brix2023fourth} and outperformed other state-of-the-art DNN verification tools, especially for very large networks~\cite{duong2024harnessing}. More importantly, DPLL(T) approach maintains \emph{implication graph}, an internal data structure to keep track of assignments, which essentially represent a  proof of the verification result. In other words, proofs are a built-in feature of DPLL(T) approach, and thus can be generated with minimal (in fact, \emph{zero}) overhead.

\section{Proof Generation for Branch and Bound Algorithms}\label{sec:proofgen}



\begin{algorithm}
    \small
  
    \Input{DNN $\mathcal{N}$, property $\phi_{in} \Rightarrow \phi_{out}$}
    \Output{($\unsat, \blue{\prooftree}$) if property is valid, otherwise ($\sat, \counterexample$)}
    \BlankLine


    $\problems \leftarrow \{ \emptyset \}$ \tcp{initialize verification problems}
    $\blue{\prooftree \gets \{ ~ \}}$ \tcp{initialize proof tree}\label{line:prooftree}
    
    \While(\tcp*[h]{main loop}){$\problems$}{
        $\sigma_i \gets \Select(\problems)$ \tcp{process problem $i$-th}
        % \Parfor(\tcp*[h]{process in parallel}){$\sigma_i ~\In~ \problems$}{ \label{line:parfor}
            \If{\Deduce{$\mathcal{N}, \phi_{in}, \phi_{out}, \sigma_i$}}{
$\counterexample \leftarrow \LP(\mathcal{N}, \phi_{in}, \phi_{out}, \sigma_i)$ \tcp{check satisfiability}
                \If(\tcp*[h]{found a valid cex}){$\counterexample$}{
                    \Return{$(\mysat, \counterexample)$}
                }
                $v_i \leftarrow \Decide(\mathcal{N}, \sigma_i)$\\
                \tcp{create new activation patterns}
                $\problems \leftarrow \problems \cup \{ \sigma_i \cup \{v_i\} ~;~ \sigma_i \land \{\overline{v_i}\} \}$
            }
            \Else(\tcp*[h]{detect infeasibility}){
                $\blue{\prooftree \leftarrow \prooftree \cup \{ \sigma_i \}}$ \tcp{build proof tree}\label{line:record_proof}
            }
    }
    \Return{$(\unsat, \blue{\prooftree})$}
    \caption{The \proofgen{} DNN verification with proof generation.}\label{alg:bab-proof}
\end{algorithm}

Recall that the BaB algorithm, shown in~~\autoref{alg:bab}, splits the problem into smaller subproblems and use abstraction to compute bounds to prune the search space. This structure allows us to bring proof generation capabilities with minimal overhead to existing DNN verification tools that use BaB.

\autoref{alg:bab-proof} extends~\autoref{alg:bab} to show \proofgen, a BaB-based DNN verification algorithm with proof generation capability. The key idea is to introduce a \textbf{proof tree} (\autoref{line:prooftree}) and recording the branching decisions to the proof tree (\autoref{line:record_proof}).
The proof tree is a binary tree structure, where each node represents a neuron and its left and right edges represent its activation decision (active or inactive).
At the end of the verification process, the proof tree is returned as the proof of \unsat{} result.


%White nodes correspond to branching nodes where \neuralsat{} makes decisions to split ReLU neurons.

\begin{example} 
    
\begin{figure}
    \begin{minipage}[b]{\linewidth}
        \centering
        \begin{minipage}[t]{0.52\textwidth}
            \centering  
            \proofnet{0.8}
            \caption*{(a)}
        \end{minipage}
        \begin{minipage}[t]{0.45\textwidth}
            \centering
            \includegraphics[width=\linewidth]{figure/proof_tree.pdf}
            \caption*{(b)}
        \end{minipage}
        \caption{(a) A simple DNN  (similar to~\autoref{fig:proofnet}), and (b) A proof tree produced by \proofgen{}. White nodes correspond to \bab{} neuron splitting. Red nodes correspond to leaf nodes where \bab{}determines infeasibility and prunes the branch.}
        \label{fig:proof-example}
    \end{minipage}
\end{figure}
    
    
We reuse the example in~\autoref{chap:bab} to illustrate \proofgen{}. Recall the goal is to verify that the DNN in~\autoref{fig:proof-example}(a) has the property $(x_1, x_2) \in [-2.0, 2.0] \times [-1.0, 1,0] \Rightarrow (y_1 > y_2)$. 


For this problem \proofgen{} generates the proof tree in~\autoref{fig:proof-example}(b) to show unsatisfiability, i.e., the property is valid. \proofgen{} first splits neuron $v_4$, creating two subproblems: one with $v_4$ active and the other with $v_4$ inactive (split node 1). The inactive $v_4$ subproblem is determined to be unsatisfiable (leaf node 3). The active $v_4$ subproblem is further split on $v_2$ (split node 2). The inactive $v_2$ subproblem is determined to be unsatisfiable (leaf node 5). The active $v_2$ subproblem is further split on $v_1$ (split node 4). Both the active and inactive $v_1$ subproblems are determined to be unsatisfiable (leaf nodes 6 and 7). Since all branches lead to unsatisfiability, the property is valid.

\end{example}
\section{Proof Language}\label{sec:prooflang}


\newcommand{\lra}[1]{
    \textcolor{green!40!black}{\langle} 
    \textit{\textcolor{green!40!black}{#1}} 
    \textcolor{green!40!black}{\rangle}
}

\begin{figure}
\begin{minipage}[b]{0.54\textwidth}
    \scriptsize
\begin{align*}
    \lra{proof}         &::= \lra{declarations} \ \lra{assertions} \\
    \lra{declarations}  &::= \lra{declaration} \ | \ \lra{declaration} \ \lra{declarations} \\
    \lra{declaration}   &::= (\textbf{declare-const} \ \lra{input-vars} \ \textbf{Real}) \\
                        & \quad ~| \ (\textbf{declare-const} \ \lra{output-vars} \ \textbf{Real}) \\
                        & \quad ~| \ (\textbf{declare-pwl} \ \lra{hidden-vars} \ \lra{activation}) \\
    \lra{input-vars}    &::= \lra{input-var} \ | \ \lra{input-var} \ \lra{input-vars} \\
    \lra{output-vars}    &::= \lra{output-var} \ | \ \lra{output-var} \ \lra{output-vars} \\
    \lra{hidden-vars}    &::= \lra{hidden-var} \ | \ \lra{hidden-var} \ \lra{hidden-vars} \\
    \lra{activation}    &::= ~\text{ReLU} \ | \ \text{Leaky ReLU} \ | \ \ldots \\
    \lra{assertions}    &::= \lra{assertion} \ | \ \lra{assertion} \ \lra{assertions} \\
    \lra{assertion}     &::= (\textbf{assert} \ \lra{formula}) \\
    \lra{formula}       &::= (\lra{operator} \ \lra{term} \ \lra{term}) \\
                        & \quad ~| \ (\textbf{and} \ \lra{formula}+) \ | \ (\textbf{or} \ \lra{formula}+) \\
                        % & \quad ~| \ (\textbf{and} \ \lra{formula} \ \lra{formula}) \\
                        % & \quad ~| \ (\textbf{or} \ \lra{formula}+) \\
                        % & \quad ~| \ (\textbf{or} \ \lra{formula} \ \lra{formula}) \\
    \lra{term}          &::= \lra{input-var} \ | \ \lra{output-var} \\ 
                        & \quad ~| \ \lra{hidden-var} \ | \ \lra{constant} \\
    \lra{operator}      &::= ~ < \ | \ \leq \ | \ > \ | \ \geq \\
    \lra{input-var}     &::= ~\text{X\_}\lra{constant} \\
    \lra{output-var}    &::= ~\text{Y\_}\lra{constant} \\
    \lra{hidden-var}    &::= ~\text{N\_}\lra{constant} \\
    \lra{constant}      &::= ~\textbf{Int} \ | \ \textbf{Real}
\end{align*}
\caption{The \prooflang{} proof language.}\label{fig:grammar}
\end{minipage}
\hfill
\begin{minipage}[b]{0.45\textwidth}
\begin{lstlisting}[style=SMTLIB-style, language=SMTLIB, basicstyle=\ttfamily\scriptsize,numbers=none]
; Declare variables
(declare-const X_0 X_1 Real)
(declare-const Y_0 Y_1 Real)
(declare-pwl N_1 N_2 N_3 N_4 ReLU)

; Input constraints
(assert (>= X_0 -2.0))
(assert (<= X_0  2.0))
(assert (>= X_1 -1.0))
(assert (<= X_1  1.0))

; Output constraints
(assert (<= Y_0 Y_1)) 

; Hidden constraints
(assert (or 
    (and (<  N_4 0))
    (and (<  N_2 0) 
        (>= N_4 0))
    (and (>= N_2 0) 
        (>= N_1 0) 
        (>= N_4 0))
    (and (>= N_2 0) 
        (<  N_1 0) 
        (>= N_4 0)
    )))
\end{lstlisting}
\caption{\prooflang{} example format of the proof tree in~\autoref{fig:proof-example}b.
}
\label{fig:proof_example}
\end{minipage}
\end{figure}


Rather than recording the generated proof tree in an verifier-specific format, it is more desirable to have a standard format
that is human-readable, is compact, can be efficiently generated by verification tools, and can
be efficiently and independently processed by proof checkers.  

The proof language \prooflang{} is designed to meet these requirements.
\prooflang{} is inspired by the SMTLIB format~\cite{barrett2010smt} used for SMT solving, which has also been adopted by the  VNNLIB language~\cite{vnnlib} to specify DNNs and their properties for verification (see~\autoref{sec:vnnlib} for examples).

%accepted by our proof check algorithm (\autoref{sec:proof-checker}

\autoref{fig:grammar} outlines the \prooflang{} syntax and grammar, represented as production rules. 
A proof is composed of \textit{declarations} and \textit{assertions}. Declarations define the variables and their types within the proof. Specifically, \textit{input variables} (prefixed with \mycode{X}) and \textit{output variables} (prefixed with \mycode{Y}) are declared as real numbers, representing the inputs and outputs of the neural network, respectively. Additionally, \textit{hidden variables}, which correspond to internal nodes of the neural network, are declared with specific piece-wise linear (PWL) activation functions, such as ReLU or Leaky ReLU. 
Assertions are logical statements that specify the conditions or properties that must hold within the proof. Assertions over input variables are \emph{preconditions} and those over output variables are \emph{post-conditions}. %Each assertion is composed of a \textit{formula}, which can involve terms and logical operators. Formulas include simple comparisons between terms (e.g., less than, greater than) or more complex logical combinations using \mycode{and} and \mycode{or} operators. The terms used in these formulas can be input variables, output variables, hidden variables, or constants.

%\begin{figure}
%\end{figure}

%\autoref{fig:proof_example} shows an example of a proof in \prooflang{} using the network in~\autoref{fig:example}a. 

The \texttt{declare-*} statements declare input, output, and hidden variables, while the \texttt{assert} statements specify the constraints on these variables (i.e., the pre and postcondition of the desired property).
The hidden constraints represent the activation patterns of the hidden neurons in the network (i.e., the proof tree). Each \texttt{and} statement represents a tree path that represents an activation pattern. 

\begin{example} 
    The proof in~\autoref{fig:proof_example} corresponds to the proof tree in~\autoref{fig:proof-example}b. The statement \texttt{(and (< N\_4 0))} corresponds to the rightmost path of the tree with $\overline{v_4}$ decision (leaf 3).  The statement \texttt{(and (< N\_2 0) (>= N\_4 0))} corresponds to the path with $v_4 \land \overline{v_2}$ (leaf 5). 
\end{example}

The \prooflang{} language is intentionally designed to (a) not explicitly include weights/bias terms to minimize size of the proof structure, and (b) explicitly reflect a DNF structure to enable easy parallelization.
The DNN weight and bias terms are readily available in the standard ONNX~\cite{onnx} format, which is typically used to represent the DNN input to a \proofgen{}-based DNN verification tool and can be accessed by any \prooflang{} checker like the one described next in~\autoref{sec:proofchecking}.


\section{Proof Checker}\label{sec:proofchecking}
Finally, we need to check that the generated proof is correct and that the original DNN verification problem is indeed \unsat{}. The checker must be efficient to handle large proofs and trusted of its results (if it verifies the proof, then the original NNV problem is proved).


To achieve this, we present \proofcheck{}, a proof checker for \prooflang{} proofs.
\proofcheck{} is verifier-independent and support \prooflang{} proofs generated by different verification tools. \proofcheck{} also has several optimizations to handle large proofs efficiently.

\subsection{The Core \proofcheck{} Algorithm}


The goal of \proofcheck{} is to verify that the \prooflang{} tree generated by a DNN verification tool is correct (i.e., the proof tree is a proof of unsatisfiability of the DNN verification problem).
\proofcheck{} thus must verify that the constraint represented by each \emph{leaf} node in the proof tree is unsatisfiable. To check each node, \proofcheck{} forms an MILP problem (\autoref{sec:using-milp}) consisting of the constraint in~\autoref{eq:nnv2} (the DNN, the input condition, and the negation of the output) with the constraints representing the activation pattern encoded by the tree path to the leaf node. \proofcheck{} then invokes an LP solver to check that the MILP problem is infeasible, which indicates unsatisfiability of the leaf node. 

\begin{algorithm}[t]
    \small

    \Input{DNN $\mathcal{N}$, property $\phi_{in} \Rightarrow \phi_{out}$, $\prooftree$}
    \Output{\certified if proof is valid, otherwise \uncertified}
    \BlankLine

    \If{$\neg$ \RepOK(\prooftree)}{
        \RaiseError{Invalid proof tree}
    }

    \tcp{initialize MILP model with inputs}
    $\model \leftarrow \CreateStabilizedMILP(\mathcal{N}, \phi_{in}, \phi_{out})$ \label{line:build_model}

    
    $\leaf \gets \mynull$ \tcp{initialize current processing node}
    
    \While{$\prooftree$}{\label{line:proof_loop}
        
        % \tcp{Get $k$ leaf nodes from $\prooftree$}
        % $[\leaf_1, ..., \leaf_k] \gets \GetLeafNodes(\prooftree, k)$ \\ \label{line:get_leaf}
        $\leaf \gets \Select(\prooftree, \leaf)$ \tcp{get next node to check} \label{line:select} \label{line:get_leaf}

        % \tcp{Process $k$ nodes in parallel}
        % \Parfor{$\leaf_i ~\In~ [\leaf_1, ..., \leaf_k]$}{ \label{line:parfor}
        
        $\model \gets \AddConstrs(\model, \leaf)$  \tcp{add constraints} \label{line:add_proof_leaf_constrs}
        
        % $\minimum \gets \Minimize(\model)$ \tcp{} \label{line:optimize1}
        \If{$\Feasible(\model)$}{\label{line:proof_check_objective1}
            \Return{\uncertified} \tcp{cannot certify}
        }
        
        % $\Backtrack(\prooftree, \leaf)$ \tcp{process interior node}
        
        % \While{$\StoppingConditions(\leaf_i)$}{ \label{line:stop_condition}
        %     % \tcp{remove constraints of old $\leaf_i$ }
        %     % $\model \gets \RemoveConstrs(\model, \leaf_i)$  \\
        %     % \tcp{move to $\leaf_i$'s parent}
        %     % $\leaf_i \gets \ShortenSplitConstrs(\leaf_i)$ \\
        %     % \tcp{add constraints of new (looser) $\leaf_i$ }

        %     \tcp{move to $\leaf_i$'s parent}
        %     $\model \gets \Backjump(\leaf_i)$  \\ \label{line:proof_backjump}

        %     \tcp{Prove the new $\leaf_i$}
        %     $\minimum \gets \Minimize(\model)$ \\ \label{line:optimize2}
        %     \If(\tcp*[h]{cannot certify}){$\minimum \le 0$}{
        %         \Break
        %     }
        %     \tcp{if parent is proved, remove its children}
        %     $\prooftree \gets \RemoveLeafNodes(\prooftree, \leaf_i)$ \label{line:proof_prune}
        % }
        }
    % }
    \Return{\certified}

    \caption{\proofcheck{} algorithm.}
    % \Description{}
    \label{fig:algorithm}
\end{algorithm}


\autoref{fig:algorithm} shows a minimal (core)  \proofcheck{} algorithm, which takes as input a DNN $\mathcal{N}$, a property $\phi_{in} \Rightarrow \phi_{out}$, a proof tree $\prooftree$, and returns \certified if the proof tree is valid and \uncertified otherwise. 
\proofcheck{} first checks the validity of the proof tree (\autoref{line:build_model}), i.e., the input must represent a proper \prooflang{} proof tree (\autoref{sec:prooflang}).  
If the proof tree is invalid, \proofcheck{} raises an error.
\proofcheck{} next creates a MILP model (\autoref{line:build_model}) representing the input. % (\autoref{sec:neuron-stabelization}).
\proofcheck{} then enters a loop (\autoref{line:proof_loop}) that selects a (random) leaf node from the proof tree (\autoref{line:select}) and adds its MILP constraint to the model (\autoref{line:add_proof_leaf_constrs}). It then checks the model using an LP solver to determine whether the leaf node is unsatisfiable. If the LP solver returns feasibility, \proofcheck{} returns \uncertified, i.e., it cannot verify the input proof tree. 
\proofcheck{} continues until all leaf nodes are checked and returns \certified, indicating the proof tree is valid.



\begin{example} 
    For the \prooflang{} proof in~\autoref{fig:proof_example}, we need to check that the four leaf nodes 3, 5, 6, and 7 of the proof tree in~\autoref{fig:example}b are unsatisfiability. Assume \proofcheck{} first selects node 3, it forms the MILP problem for leaf node 3 by conjoining the constraint representing $0.6v_1 + 0.9v_2 - 0.1 \le 0$ (i.e., $\overline{v_4}$) %\tvn{Hai check}\hd{by setting $a_1^{(2)}=0$ representing that $\hat{z}_1^{(2)} \le 0$ (see~\autoref{eq:mip}e) or \emph{implicitly} conjoining the inequality $0.6\hat{z}^{(1)}_0 + 0.9\hat{z}^{(1)}_1 - 0.1 \le 0$ (or ${z}_1^{(2)} \le 0$), where $\hat{z}^{(1)}_0$, $\hat{z}^{(1)}_1$ represent the outputs of $v_1$ and $v_2$, respectively.} 
with the constraints in~\autoref{eq:nnv2} representing the input ranges and the DNN with the objective of optimizing the output. \proofcheck{} then invokes an LP solver, which determines that this MILP is infeasible, i.e., leaf node 3 indeed leads to unsatisfiability. \proofcheck{} continues this process for the other three leaf nodes and returns \certified as all leaf nodes are unsatisfiable.
\end{example}

% \subsubsection{MILP Formulation}\label{sec:milp-formulation}

% \proofcheck{} formulates MILP problems~\cite{tjeng2019evaluating} and check for feasible solutions using off-the-shelf LP solving. Formally, the MILP problem is defined as:
% \begin{equation}
%     \begin{aligned}
%         &\mbox{(a)}\quad z^{(i)} = W^{(i)} \hat{z}^{(i-i)} + b^{(i)};\\
%         &\mbox{(b)}\quad y = z^{(L)};  x = \hat{z}^{(0)}; \\
%         &\mbox{(c)}\quad \hat{z}_j^{(i)} \ge {z}_j^{(i)}; \hat{z}_j^{(i)} \ge 0; \\
%         &\mbox{(d)}\quad a_j^{(i)} \in \{ 0, 1\} ;\\
%         &\mbox{(e)}\quad \hat{z}_j^{(i)} \le {a}_j^{(i)} {u}_j^{(i)}; \hat{z}_j^{(i)} \le {z}_j^{(i)} - {l}_j^{(i)}(1 - {a}_j^{(i)}); \\
%     \end{aligned}
%     \label{eq:mip2}
% \end{equation}

% \noindent where $x$ is input, $y$ is output, and $z^{(i)}$, $\hat{z}^{(i)}$, $W^{(i)}$, and $b^{(i)}$ are the pre-activation, post-activation, weight, and bias vectors for layer $i$, respectively. 
% This encodes the semantics of a ReLU-based DNN:  
% (a) the affine transformation computing the pre-activation value for a neuron in terms of outputs in the preceding layer;
% (b) the inputs and outputs in terms of the adjacent hidden layers;
% (c) assertion that post-activation values are non-negative and no less than pre-activation values;
% (d) neuron activation status indicator variables that are either 0 or 1; and
% (e) constraints on the upper, $u_j^{(i)}$, and lower, $l_j^{(i)}$, bounds of the pre-activation value of the $j$th neuron in the $i$th layer.
% Deactivating a neuron, $a_j^{(i)} = 0$, simplifies the first of the (e) constraints to $\hat{z}_j^{(i)} \le 0$, and activating a neuron simplifies the second to $\hat{z}_j^{(i)} \le z_j^{(i)}$, which is consistent with the semantics of $\hat{z}_j^{(i)} = max(z_j^{(i)},0)$.


% \subsubsection{Correctness}\label{sec:checker-core-correctness}

% ~\autoref{fig:algorithm} returns \certified iff the input \prooflang{} proof tree is unsatisfiable. This proof tree encodes a disjunction of constraints, one per tree path, where each constraint represents an activation pattern of the network (the leaf node). The algorithm checks each constraint using LP solving and only returns certified iff every one of them is unsatisfiable.  
% %Moreover, while pruning optimization (\autoref{sec:pruning}) in~\autoref{fig:algorithm} allows the checker to skip children nodes if the parent node is unsatisfiable, this is still sound because the structure of the proof tree guarantees that the constraints of a child is more restricted its parent, and thus if the parent node is unsatisfiable, the children nodes must also be unsatisfiable. The algorithm  terminates because the proof tree (or the DNF) is finite and the checker will eventually check all nodes.
% We note that this correctness argument assumes that the LP solver is correct -- in practice
% multiple solvers could be used to guard against errors in that component.  We note that
% it is standard for proof checkers to assume the correctness of a small set of external tools, e.g., checkers that use  theorem provers assume the correctness of the underlying prover~\cite{lammich2023grat}.

\subsection{Optimizations}
While the core \proofcheck{} algorithm in~\autoref{fig:algorithm} is minimal, it can be inefficicient for large proofs.
\proofcheck{} employs several optimizations to improve its efficiency. These are crucial for checking large proof trees generated by DNN verification tools for challenging problems.


\subsubsection{Neuron Stabilization}\label{sec:neuron-stabelization} 

\begin{algorithm}
    \small

    \Input{DNN $\mathcal{N}$, property $\phi_{in} \Rightarrow \phi_{out}$, parallel factor $k$}
    \Output{MILP $\model$}
    \BlankLine
    

    $\model \leftarrow \InputMILP(\phi_{in})$  \tcp{input property}    \label{line:create_input}

    \tcp{Add MILP constraints for each layer of network}
    \For{$\layer ~\In ~\mathcal{N}$}{
        \If{$\isPiecewiseLinear(\layer)$}{
            \tcp{add constraints~\autoref{eq:mip2} (c), (d), (e)} 
            $\model \leftarrow \PiecewiseLinearMILP(\layer, \phi_{in}, \phi_{out})$ \\ \label{line:create_pwl_layer}
        }
        \Else(\tcp*[h]{this layer is linear}){
            \tcp{add constraints~\autoref{eq:mip2} (a), (b)} 
            $\model \leftarrow \LinearMILP(\layer, \phi_{in}, \phi_{out})$ \\ \label{line:create_linear_layer}

            \tcp{estimate upper and lower bounds} 
            $\layerbounds \gets \EstimateBounds(\layer)$ \\ \label{line:estimate_bounds}
            
            \tcp{select unstable neurons to be stabilized} 
            $[v_1, ..., v_k] \leftarrow \GetUnstableNeurons(\layerbounds)$ \\ \label{line:find_unstable}
        
            \tcp{stabilize selected neurons in parallel}
            \Parfor{$v_i ~\In~[v_1, ..., v_k]$}{ \label{line:parallel_stabilize}
                % \tcp{lower is closer to 0 than upper}
                \tcp{optimize lower first}
                \If{$(v_i.lower + v_i.upper) \ge 0$}{
                    $\Maximize(\model, v_i.lower)$ \\ \label{line:maximize1}
                    \If(\tcp*[h]{still unstable}){$v_i.lower < 0$}{
                        $\Minimize(\model, v_i.upper)$ \label{line:minimize1}
                    }
                }
                % \tcp{upper is closer to 0 than lower}
                % \tcp{optimize upper first}
                \Else(\tcp*[h]{optimize upper first}){
                    $\Minimize(\model, v_i.upper)$ \\ \label{line:minimize2}
                    \If(\tcp*[h]{still unstable}){$v_i.upper > 0$}{
                        $\Maximize(\model, v_i.lower)$  \label{line:maximize2}
                    }
                }
            }
        }
    }

    $\model \gets \AddObjective(\model, \phi_{out})$ \tcp{output property}
    
    \Return{$\model$}
    
    % \vspace*{-0.2in}
    \caption{\texttt{CreateStabilizedMILP} procedure.}
    \label{fig:stabilize}
    % \Description{}
\end{algorithm}

A primary challenge in DNN analysis is the presence of large numbers of piecewise-linear constraints (e.g., ReLU) which generate a large number of branches and yield large proof trees. In the MILP formulation, this creates many disjunctions which are hard to solve. To reduce the number of disjunctions, \proofcheck{} uses \emph{neuron stabilization}~\cite{duong2024harnessing}
to determine neurons that are \emph{stable}, either active or inactive, for all inputs defined by the property pre-condition.
For all stable neurons, the disjunctive ReLU constraint is replaced with a linear constraint that represents the neuron's value.   This simplifies the MILP problem.

\proofcheck{} uses the algorithm in~\autoref{fig:stabilize} to traverse the DNN and compute stable neurons. The algorithm initializes the MILP model with input constraints (\autoref{line:create_input}) and then iterates over each layer of the network. 
%follows the~\autoref{eq:mip} to create corresponding 
Next, for each layer, it creates constraints (\autoref{line:create_pwl_layer} or~\autoref{line:create_linear_layer}) depending on the layer type.
Moreover,  it uses approximation to estimate bounds of neuron values to determine neuron stability (\autoref{line:estimate_bounds}).
Next, it filters unstable neurons (\autoref{line:find_unstable}) and attempt to make them stable by optimizing either their lower ($\Maximize$) or upper ($\Minimize$) bounds.



\subsubsection{Pruning Leaf Nodes}\label{sec:pruning}
%\hd{``Pruning'' sounds better}

Another optimization \proofcheck{} employs is that it does not check child nodes if the parent node is unsatisfiable.
In an \prooflang{} proof tree, a child node adds constraints to the parent (e.g., node 6 adds the constraint of $v_1$ to node 4, which adds the constraint of $v_2$ to node 2 in~\autoref{fig:example}b). Thus, if we determine that the constraint of the parent is unsatisfiable, we can skip the child nodes, which must also be unsatisfiable.  

%Simply checking parent nodes would actually increase MILP cost, because they have shorter tree paths and thus have a greater number of disjunctive constraints.

\proofcheck{} uses a backtracking mechanism to check the parent node only when the child nodes are infeasible. Specifically, it starts checking a leaf node $l$. If it determines unsatisfiability it will check the parent $p$ of $l$. If $p$ is unsatisfiable it immediately removes the children of $p$ (more specifically the sibling of $l$). Next it backtracks to the parent of $p$ and repeats until meeting a stopping criteria. This optimization reduces the number of LP problems that need to be solved, making the proof checking process more efficient. 

We implement a backjumping strategy that allows for backtracking multiple levels, $N$, rather than a single level at a time.
A large value of $N$ offers the chance for greater pruning if an unsatisfiable node is found by
backjumping, but such nodes also represent less constrained, and therefore, more complex MILP problems
and are less likely to be unsatisfiable.
The default value in $\proofcheck{}$ is $N=2$ is selected to enable a modest degree of pruning,
while being close enough to a proven unsatisfiable node that it has a reasonable chance of itself being unsatisfiable.
Future work will explore tuning $N$ to a given verification problem.


% \hd{Without X, \proofcheck{} will have to check all the children.}

% \hd{It backjumps when the leave node is proved and X optimization is enabled. 
% We can keep backing up until it cannot prove anymore, however, after N times, each time half the length of an activation pattern, an activation pattern is shortened to $1 / 2^{N}$ (e.g., if $N=2$, after 2 times of backing up, an activation pattern is shortened to 1/4 of its length). 
% This is when the pruned leaves by those proved interiors are getting overlapped (due to parallelization, we backjump on multiple leaves), so more backjumps might not helpful. 
% Instead, we start over with a new iteration with remaining leaves.
% I experienced with $N = \{1, 2, 3, 4, 5\}$ and I settled down $N=2$ for all experiments (fixed N) which seems to be good enough in our experiments. 
% Increasing $N$ does not improve the performances but hurts especially when dealing with CNNs.
% }
% \matt{I think my main point is ``How much of this is important to \proofcheck{}?'' whatever is important needs to be described.  You don't need to describe all of the discarded alternatives.  If we settled on a particular strategy, then define that strategy and say why it works well, e.g., balances cost of failing to prove unsat for parents with ability to prune sub-trees.  Right now we just say "simple backtracking mechanism", but your description makes seem like it is not all that simple.}
% This optimization reduces the number of LP problems that need to be solved, making the proof checking process more efficient.

%. \proofcheck{} thus uses a simple backtracking mechanism to check the parent node only when the child nodes are infeasible. This optimization reduces the number of LP problems that need to be solved, making the proof checking process more efficient.
%However, checking the parent node is more expensive than checking the child nodes (otherwise we can just directly check the root node). \proofcheck{} thus uses a simple backtracking mechanism to check the parent node only when the child nodes are infeasible. This optimization reduces the number of LP problems that need to be solved, making the proof checking process more efficient.

\subsubsection{Parallelization} Finally, the structure of \prooflang{} proof tree is designed to be easily parallelized.  Each tree path is an independent sub-proof and partitions of the tree allow checker to leverage multiprocessing to check large proof trees efficiently. \proofcheck{} uses a parameter $k$ to control the number of leaf nodes to be checked in parallel.

%\section{Rounding Errors}\label{sec:rounding-errors}

%\tvn{Give concrete examples of rounding errors in VNN-COMP}


% \section{Evaluation}\label{sec:evaluation}  
% Our goals are to understand how checking of \prooflang{}s performs, how it can be optimized, and how robust checking is to
% verification optimizations.
% We focus our evaluation on the following research questions:

% \noindent\mbox{~~}\textbf{RQ1} (\autoref{sec:rq1}): How does \proofcheck{} perform and how does it compare prior work? 

% \noindent\mbox{~~}\textbf{RQ2} (\autoref{sec:rq2}): How does proof checking optimization improve performance?

% \noindent\mbox{~~}\textbf{RQ3} (\autoref{sec:rq3}): How does proof checking performance vary with verification algorithms and optimizations?



% \subsection{Experimental Design}\label{sec:exp_design}
% We describe the selection of benchmarks, baselines, metrics, and treatments used
% to explore the above RQs.

% \ignore{
% \begin{table*}[t]
%     \footnotesize
%     \centering
%     \caption{Benchmark instances. U: \texttt{unsat}, S: \texttt{sat}, ?: \texttt{unknown}.}\label{tab:benchmarks}
%     % \vspace*{-3mm}
%     % \resizebox{\textwidth}{!}{
%     \begin{tabular}{c|ccrr|cc}
%         \toprule
%         % \multirow{2}{*}{\textbf{Benchmarks}} &\multicolumn{3}{c}{\textbf{Networks}}  &\multicolumn{2}{|c}{\textbf{Tasks}}\\
%         % \multirow{2}{*}{\textbf{Benchmarks}} &\multicolumn{2}{c}{\textbf{Networks}} &  \multicolumn{2}{c|}{\textbf{Per Network}} &\multicolumn{2}{c}{\textbf{Tasks}}\\
%         \multirow{2}{*}{\textbf{Benchmarks}} &\multicolumn{4}{c}{\textbf{Networks}} & \multicolumn{2}{|c}{\textbf{Tasks}}\\
%         & Type & Networks & Neurons & Parameters & Properties & Instances (U/S/?)\\
  
%         \midrule
%         \multirow{4}{*}{FNN\_SMALL}         & \multirow{4}{*}{FNN + ReLU} & 2 x FNN(32) &   64 & 27K & 25 & 25/0/0 \\
%                                             &                             & 4 x FNN(32) &  128 & 29K & 25 & 25/0/0 \\
%                                             &                             & 2 x FNN(64) &  128 & 55K & 25 & 25/0/0 \\
%                                             &                             & 4 x FNN(64) &  256 & 63K & 25 & 25/0/0 \\
        
%         \midrule
%         \multirow{4}{*}{FNN\_MEDIUM}        & \multirow{4}{*}{FNN + ReLU} & 2 x FNN(256)  &    512 &  269K & 25 & 25/0/0 \\
%                                             &                             & 4 x FNN(256)  &   1024 &  401K & 25 & 25/0/0 \\
%                                             &                             & 6 x FNN(256)  &   1536 &  532K & 25 & 25/0/0 \\
%                                             &                             & 6 x FNN(512)  &   3072 & 1.7M & 25 & 25/0/0 \\
%         \midrule
%         \multirow{4}{*}{CNN\_SMALL}         & \multirow{4}{*}{CNN + ReLU} & 1 x CNN(3, 21), 1 x FNN(128)  &   320 & 27K & 25 & 25/0/0 \\
%                                             &                             & 1 x CNN(3, 19), 1 x FNN(128)  &   428 & 41K & 25 & 25/0/0 \\
%                                             &                             & 1 x CNN(3, 17), 1 x FNN(128)  &   560 & 58K & 25 & 25/0/0 \\
%                                             &                             & 1 x CNN(3, 13), 1 x FNN(128)  &   896 & 100K & 25 & 25/0/0 \\
%         \midrule
%         \multirow{4}{*}{CNN\_MEDIUM}        & \multirow{4}{*}{CNN + ReLU} & 1 x CNN(3, 9), 1 x CNN(5, 11), 1 x FNN(128)  &   1828 & 67K & 25 & 25/0/0 \\
%                                             &                             & 1 x CNN(3, 7), 1 x CNN(5, 9),  1 x FNN(128)  &   2560 & 128K & 25 & 25/0/0 \\
%                                             &                             & 1 x CNN(5, 9), 1 x CNN(7, 11), 1 x FNN(128)  &   2828 & 96K & 25 & 25/0/0 \\
%                                             &                             & 1 x CNN(5, 7), 1 x CNN(7, 9),  1 x FNN(128)  &   3920 & 180K & 25 & 25/0/0 \\
%         \midrule
%         \textbf{Total}                      &                             & \textbf{16}                  &     &   & \textbf{400} & \textbf{400/0/0} \\
%         \bottomrule
%     \end{tabular}
%     % }
% \end{table*}
% }


% \paragraph{Benchmarks}
% Evaluating these research questions requires neural network verification problems
% that are valid, i.e., their formulation as satisfiability problems is UNSAT.

% The yearly VNN-COMP competitions~\cite{brix2023first,brix2023fourth,bak2021second} includes a wide-variety of benchmarks,
% but the competitions organizers observed that many benchmarks are too easy.
% They contain large numbers SAT problems that can be solved by adversarial attacks 
% or UNSAT problems that can be solved, without any state splitting, using coarse overapproximations.
% They conclude that there is a need 
% for benchmarks to be ``not so easy that every tool can solve all of them''~\cite{brix2023first}.
% For this reason, we base our benchmark selection on a recent paper~\cite{duong2024harnessing} that developed harder
% UNSAT benchmarks including:
% ACAS Xu, RESNET\_A/B, CIFAR2020, MNISTFC, and MNIST\_GDVB.

% We selected problems from these based on the applicability of our
% current \proofcheck{} implementations.

% We chose not to use ACAS Xu, because those problems have a very small
% input dimension (5 dimensions) which triggers a divide-and-conquer problem
% decomposition optimization in verifiers, like \neuralsat{} and \crown{}.
% This results in a set of relatively small proofs, each of which
% can be expressed in \prooflang{}, but whose simplicity do not add
% value beyond the selected benchmarks discussed below.

% We chose not to use the RESNET benchmarks because  \proofcheck{} does not currently handle residual blocks.  This is an engineering limitation and there is no fundamental reason the checking algorithm is not applicable.  

% Of the CIFAR2020 networks, one contains BatchNorm layers which are not currently
% supported by \proofcheck{}, but we note that adding this support is a straightforward
% engineering issue.
% The remaining CIFAR2020 benchmarks contain very large numbers of convolutional
% kernels, which generates complex constraints that can be challenging to solve.
% We adapt the smallest of the CIFAR2020 benchmarks, by varying the size of the
% convolutional kernels and the number of CNN layers, to produce 
% the CNN benchmark in the second row of~\autoref{tab:benchmarks}.
% \begin{table}[t]
%     \footnotesize
%     \centering
%     \caption{Benchmarks consist of a 8 neural networks comprised of varying numbers of CNN (C) and FNN (F) layers, neurons, and parameters, each paired with 25 properties to form verification instances that have been confirmed to be UNSAT.}\label{tab:benchmarks}
%     % \vspace*{-3mm}
%     % \resizebox{\textwidth}{!}{
%     \begin{tabular}{c|cccc|c}
%         \toprule
%         \multirow{2}{*}{\textbf{Name}} &\multicolumn{4}{c|}{\textbf{Networks}} & \textbf{Properties}\\
%         & Num. & Layers & Neurons & Param. & Num. \\

%         \midrule
%         FNN        & 8 & 2-6F &  64-3072 & 27K-1.7M & 200  \\
%         \midrule
%         CNN        & 8 & 1-2C;1F  &  320-3920 & 41K-180K & 200  \\
%         \bottomrule
%     \end{tabular}
%     % }
% \end{table}

% The MNISTFC and MNIST\_GDVB benchmarks contain 41 networks and a total of 106 UNSAT verification problems.
% From those we selected 8 networks with varying numbers of layers and neurons, resulting
% in models spanning several orders of magnitude in terms of parameters, to produce
% the FNN benchmark in the first row of~\autoref{tab:benchmarks}.

% For each of the networks, following the approach from~\cite{duong2024harnessing}, 
% we randomly selected centerpoints and radii for local-robustness properties until we found 25 property specifications that yielded UNSAT results.  This yielded 200 properties
% each for the FNN and CNN benchmarks for a total of 400 verification problems and
% their associated proofs.

% \paragraph{Baselines}
% To the best of our knowledge there is a single prior work published
% on DNN verification proof checking~\cite{desmartin2023towards}.
% That checker is designed to work only with a single verifier, \marabou{}, 
% unlike \proofcheck{}.

% While not strictly a baseline we also use the time to verify problems
% as a baseline.  This is because it is instructive to understand 
% the cost of proof checking after having generated a proof.
% We have adapted two verifiers: \crown{} and \neuralsat{}, to 
% generate \prooflang{} proofs for this study.

% For RQ1 our focus is on proof checking performance, so we compare
% \marabou{} and its proof checker with a single verifier, \neuralsat{},
% and \proofcheck{}.  
% RQ2 explores \proofcheck{} optimizations and it uses the unoptimized
% \proofcheck{} performance as a baseline.
% For RQ3 our goal is to understand how well \proofcheck{} accommodates
% proofs generated by different verification algorithm variants, since no
% other proof checker can do this there is no baseline for comparison.

% \begin{figure}[t]
%     \centering
%     \begin{minipage}[t]{0.4\textwidth}
%         \centering  
%         \includegraphics[width=\linewidth]{figure/fnn.pdf}
%     \end{minipage}
%     \begin{minipage}[t]{0.4\textwidth}
%         \centering  
%         \includegraphics[width=\linewidth]{figure/cnn.pdf}
%     \end{minipage}

%     % \begin{minipage}[t]{0.45\textwidth}
%     %     \centering  
%     %     \includegraphics[width=\linewidth]{figure/MNIST_CNN_SMALL.pdf}
%     % \end{minipage}
%     % \hfill
%     % \begin{minipage}[t]{0.45\textwidth}
%     %     \centering  
%     %     \includegraphics[width=\linewidth]{figure/MNIST_CNN_MEDIUM.pdf}
%     % \end{minipage}
%     \caption{Cactus-plots for verifiers and proof checkers of FNN (top) and CNN (bottom) benchmarks.}
%     \label{fig:cactus-plots}
% \end{figure}
% \paragraph{Treatments}
% RQ1 compares the best performing versions of \marabou{}'s proof checker and \proofcheck{}.
% For RQ2, we consider two of the three optimizations
% implemented in \proofcheck{} : proof tree pruning (X), and 
% proof stabilization (S).  We kept a third optimization that controls the
% degree of parallelization in proof checking fixed at a value of 64 to mitigate
% experimental cost; since the independence of sub-proofs means that
% proof checking is amenable to linear speedup we felt this aspect of experimentation
% was less valuable.
% For RQ3, we use both \neuralsat{} and \crown{} to generate proofs; this
% constitutes a treatment for this research question as it varies the
% verification algorithm.
% For each verifier, we explore a base version of the verifier and an optimization:
% the stabilization optimization for \neuralsat{} and replacing
% the default branch-and-bound decision heuristic with the BaBSR~\cite{bunel2020branch} heuristic
% in \crown{}.

% \paragraph{Metrics}
% In the verification community there are two metrics commonly used to
% assess performance: time to solve the problems and number of problems solved
% from a benchmark.  We report them both here.

% For each \proofcheck{} problem we record:
% the time to verify that the problem is UNSAT, the time to generate a proof,
% the time for \proofcheck{} to finish.
% If the sum of these for a problem is less than a specified timeout,
% 1000 seconds in our evaluation, then we say the problem is ``solved''.
% For verifiers run alone, a problem is solved if the verification completes
% within the timeout.

% For each benchmark, we provide cactus plots which plot the time for a problem on the y-axis, and the number of problems solved on the x-axis; problems are sorted on the x-axis from least to largest.
% As shown in~\autoref{fig:cactus-plots}, these plots allow one to observe both the time difference between baselines and treatments (vertical distance between lines at a point on the x-axis) and the ability of techniques to solve problems (the maximum x-coordinate for a given line).

% We also report the size of proof trees that are generated in \prooflang{}.
% In the absence of optimizations this defines the \textit{number of sub-proofs}
% that need to be checked, but with optimizations the number of sub-proofs may
% be reduced, e.g., when an interior node in the tree can be proven.
% The complexity of  sub-proofs
% may vary significantly, so to provide a more detailed characterization we
% also report \textit{MILP complexity}. ~\autoref{eq:mip} defines the general form
% of each MILP problem, but the problems will vary based on how many of the $a$ variables
% defined in~\autoref{eq:mip}(d) have a fixed value -- either 0 or 1.   When this
% happens the constraint in~\autoref{eq:mip}(e) are simplified.
% Consequently, we measure MILP complexity as the number of neurons that do \textit{not}
% have a fixed value, i.e., the number of unstable neurons.  
% \ignore{This does not account for the contribution of~\autoref{eq:mip}a,b which is directly
% related to network size and input/output dimension.   Is there any way to measure that?}
% % \hd{I see. It seems hard since "a"s and constraints do not have the same unit.}

% \paragraph{Experimental Setup}
% All experiments were run on a Linux machine with an AMD Threadripper 64-core 4.2GHZ CPU, 128GB RAM, and an NVIDIA GeForce RTX 4090 GPU with 24 GB VRAM. 
% We used a timeout of 1000 seconds for the combined time of running the verifier,
% generating the proof, and then checking that proof.

% \subsection{RQ1 : Proof Checking Performance}
% \label{sec:rq1}
%~\autoref{fig:cactus-plots} presents data on the performance
% of \proofcheck{} relative to both an underlying verifier, \neuralsat{}, and prior work on neural network proof checking, \marabou{}'s proof checker.  
% In cactus plots like this, lines that extend further on the x-axis
% are better -- more problems solved -- and lines that are lower are better -- faster solve times.
% Another way to view these is to pick a point on the x-axis where the plots for two techniques are defined and think of the areas under the two curves as the ``total cost'' to solve that number of problems.
% The dashed lines in the plots show the performance of the verifier and the solid lines show the performance of the verifier, proof generation, and the proof checker.  Several configurations of
% \proofcheck{} are shown, but in this RQ we draw the readers attention
% to the plots for the \proofcheck{}(S+X) configurations; the rest are discussed in detail below.

% The cactus plot for the FNN benchmark (top)
% shows that \marabou{} and its checker are able to solve 69 problems or 35\% of the benchmark, whereas \proofcheck{} can solve 186 or 93\%.  
% For the CNN benchmark (bottom) \marabou{} and its checker can solve a single benchmark, whereas \proofcheck{} can solve 177 problems or 89\%.
% In total, \proofcheck{} solved 363 problems or 91\%, whereas \marabou{}  solved 70 problems or 18\% of all instances.

% \begin{figure*}[t]
% \begin{subfigure}{0.4\linewidth}
%     \centering
%     % 
%     \begin{minipage}[t]{0.75\textwidth}
%         \centering  
%         \includegraphics[width=\linewidth]{figure/SUB_PROOFS_NONE.pdf}
%     \end{minipage}
%     %
%     \begin{minipage}[t]{0.235\textwidth}
%         \centering  
%         \includegraphics[width=\linewidth]{figure/SUB_PROOFS_SX.pdf}
%     \end{minipage}
%     \caption{Number of sub-proofs per problem with (right) and without (left) \proofcheck{} optimizations.}
%     \label{fig:sub-proofs-plots}
% \end{subfigure}
% \hfill
% \begin{subfigure}{0.59\linewidth}
%     \centering 
%     %
%     \begin{minipage}[t]{0.5\textwidth}
%         \centering  
%         \includegraphics[width=\linewidth]{figure/MILP_COMPLEXITY_NONE.pdf}
%     \end{minipage}%
%     \begin{minipage}[t]{0.5\textwidth}
%         \centering  
%         \includegraphics[width=\linewidth]{figure/MILP_COMPLEXITY_SX.pdf}
%     \end{minipage}

%     \caption{Number of constraints of a given complexity per problem with (right) and without (left) \proofcheck{} optimizations.}
%     \label{fig:constrs-proofs-plots}
% \end{subfigure}
% \caption{Data on proof size and complexity.   Y-axes are log-scale due to the range of values.}
% \end{figure*}

% % \matt{Some of the line number references are no longer resolving below.}
% The shape of these cactus plots indicates a high-degree of variability in the cost of proof
% checking relative to verification.
% From~\autoref{fig:algorithm} it is clear that both the number of leaves in the tree
% structure,~\autoref{line:get_leaf}, and the complexity of the model to be checked,~\autoref{line:proof_check_objective1}, are factors that contribute to the cost of proof checking.
% To explore those factors we plot their variation across the benchmarks when running \proofcheck{}.

%~\autoref{fig:sub-proofs-plots} (left) plots a histogram of the number of sub-proofs solved per verification 
% problem, i.e., the number of nodes of the proof tree.
% When interpreting these plots, understand that the y-axis log scale means that vertical
% distances have a different meaning as you move upward in the plot.
% While the vast majority of the verification problems have proof trees of fewer then 2000 leaves, but 17 of them have larger trees up to a maximum of more than 10000 leaves.
% Note also that even among the smaller sized proof trees, there are some problems that cannot be solved.
% This is due to complexity of solving the MILP constraints at the leaves of those proof trees.

%~\autoref{fig:constrs-proofs-plots} (top) plots a histogram of the number of occurrences of MILP problems of
% a given complexity across the benchmarks.  Here again we see a spread in data, but unlike with the number of sub-proofs the CNN benchmarks seem to have consistently larger constraints and there is a clear bias among the unsolved problems towards larger constraint size.
% To optimize proof checking, we must address both of these sources of complexity.

% \begin{tcolorbox}[left=1pt,right=1pt,top=1pt,bottom=1pt]
% \textbf{RQ1 Findings}: Proof checking performance varies with both the size of the proof tree and the complexity of the MILP problems at the nodes of the tree.  \proofcheck{} can solve 91\% of the problems across the benchmarks and improves on prior work which can solve less than 18\%.
% % \tvn{are these numbers correct?  the 2nd paragraph of RQ1 says prior work can do 24\% and \proofcheck{} can do 92\%}
% \end{tcolorbox}

% \subsection{RQ2 : Proof Checking Optimizations}
% \label{sec:rq2}
% The performance cactus plots~\autoref{fig:cactus-plots} present an ablation
% study of the 
% pruning (X) and stabilization (S) optimizations of \proofcheck{}.
% The trend across both benchmarks is consistent with pruning (yellow) and stabilization (blue)
%  improving the number of problems solved by 5\% and 36\%, respectively, over the unoptimized
% \proofcheck{} (green).
% The combination of optimizations (red) improves the number of solved problems by 46\%, which is more than the sum of their individual improvements demonstrating that the methods create opportunities for one another for further optimization.
% \ignore{
% - neither X nor S: 168 (F) + 88 (C) = 256
% - X: 175 (F) + 93 (C) = 268
% - S: 178 (F) + 170 (C) = 348
% }

% The~\autoref{fig:sub-proofs-plots} (right) and~\autoref{fig:constrs-proofs-plots} (right) explore the impact of the S and X optimizations on the number of sub-proofs and MILP complexity.  Across the benchmarks optimizations reduce 
% the number of sub-proofs is to less than 1000 and
% MILP complexity to less than 2000.   
% The reduction in sub-proofs directly contributes to the increase
% in performance of \proofcheck{}, but the reduction in
% MILP complexity is more subtle.   
% Integer programming, and thus MILP, is known to be
% NP-Hard in general~\cite{garey1979computers}.
% The stabilization optimization addresses this complexity by
% calculating sets of variables that are forced to take on specific
% values based on other constraints in the MILP problem.  For each
% such variable, the constraints associated with it is effectively
% eliminated.  We can observe this in comparing the left and
% right of~\autoref{fig:constrs-proofs-plots} where we see both
% constraints of higher complexity eliminated and the peak of
% the constraint distribution shifted downward from 400 to 100
% constraints.  

% \ignore{
% Sub-problem size
% - without S+X:
%     + mean: 388
%     + std: 1062
% - with S+X
%     + mean: 142
%     + std: 152

% MILP complexity
% - without S+X: 
%     + mean: 329
%     + std: 274
% - with S+X
%     + mean: 493
%     + std 449

% We performed an analysis of the relationship between size of constraints and number of sub-proofs and determined that these factors are not strongly correlated.
% For example, there is a 1 layer CNN model with 27k parameters whose verification
% generates 680 sub-proofs where the complexity of the constraints in that proof are at most 109. 
% On the other end of the spectrum, verification of a 2 layer CNN model with 180k parameters only requires 81 sub-proofs, but those proofs consist of constraints with complexity of at least 1721.
% }

% \begin{tcolorbox}[left=1pt,right=1pt,top=1pt,bottom=1pt]
% \textbf{RQ2 Findings}: The \proofcheck{} optimizations each independently increase the number of proofs that can be checked and in combination they allow
% an additional 46\% of the proofs in the benchmarks to be checked.
% \end{tcolorbox}

% \subsection{RQ3 : Proof Checking and Verifier Optimizations}
% \label{sec:rq3}
%~\autoref{fig:algvariation} shows cactus-plots for two configurations of \neuralsat{} and \crown{} generated proofs across the benchmarks.   The performance of the verifiers, dashed lines, differ across configurations and they are able to 
% verify between 337 and 400 problems in the benchmark.
% \ignore{Number of Verified/Proved problems
%     + abcrown(babsr):   337/335 = 99.4%
%     + abcrown:          368/366 = 99.4%
%     + neuralsat(SX):    387/363 = 93.7%
%     + neuralsat(S)(SX): 400/384 = 96%
% }
% For both of the verifiers and configurations,
% \proofcheck{} is able to check between 93.7\% and 99.4\% of the proofs that are generated.
% This demonstrates that the \prooflang{} is able to encode proofs
% generated by differing neural network verification algorithms, and
% that \proofcheck{} can check them.

% %~\autoref{tab:sizestats}.
% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.8\linewidth]{figure/ablation.pdf}
%     \caption{\proofcheck{} performance with different verification algorithms.}
%     \label{fig:algvariation}
% \end{figure}

% \begin{table}[t]
%     \caption{Proof statistics for best verifier configurations.}
%     \label{tab:sizestats}
%     \centering
%     \begin{tabular}{c|cc|cc}
%         \toprule
%          \multirow{2}{*}{\textbf{Verifier}} & \multicolumn{2}{c}{\textbf{Num. Sub-Proofs}} & \multicolumn{2}{|c}{\textbf{MILP Complexity}}\\
%          & Mean & Median & Mean & Median \\ 
%          \midrule
%          \neuralsat{}(S) & 95 & 36 & 601 & 545 \\ 
%          \midrule
%          \crown{} & 230 & 180 & 414 & 179\\
%          \bottomrule
%     \end{tabular}
% \end{table}

% We performed an analysis of both the number of sub-proofs and MILP complexity for the proofs generated by the two best performing verifier
% configurations.  These values follow a skewed
% distribution, so we report the mean and median values in~\autoref{tab:sizestats}.   One can observe variation in the
% structure of the proofs generated by these verifiers.
% \neuralsat{} generates smaller proof trees, but where the
% MILP problems are more complex.
% In contrast, \crown{} generates significantly larger proof trees,
% but with less complex MILP problems.
% This variation suggests potential avenues for future work, especially,
% when proof checking is important.

% For example, \neuralsat{} might include an option to generate larger proof trees, but with smaller MILP problems.  Such proofs would then
% be amenable to higher-degrees of parallel solving and mitigate the 
% performance bottleneck presented by MILP solver implementations.
% One might even consider strategies that use fast verification 
% options during development and then when all properties are proven, shift to slower verification options that are more amenable to proof checking.

% \ignore{
% 1. Longer verification time means proof tree will be larger since verifier has to explore larger space
% 2. If an instance is verified by \crown{}, it will likely be proved by \proofcheck{}. In other words, most of timeout instances are due to \crown{} cannot verify (1st phase).

% - MILP complexity:
%     + neuralsat(S)(SX)  : mean=601.36, std=475.88, median=545.00, min=3, max=1944
%     + neuralsat(SX)     : mean=492.40, std=448.81, median=342.00, min=2, max=1956
%     + abcrown           : mean=414.35, std=447.02, median=179.00, min=0, max=1957
%     + abcrown(babsr)    : mean=409.00, std=448.89, median=166.00, min=0, max=1952

% They share the same MILP base model since their base models are all generated from SX setting.
% neuralsat(S)(SX) has larger MILP complexity in average means that its proof trees are often shallower than others. In other words, neuralsat(S) explores smaller space than others -- which is true.

% - number of sub proofs:
%     + neuralsat(S)(SX): mean=95.11,   std=117.13, median=36.00,  min=0, max=829
%     + neuralsat(SX)   : mean=142.00,  std=151.72, median=106.00, min=1, max=1132
%     + abcrown         : mean=229.96,  std=199.23, median=180.00, min=0, max=1152
%     + abcrown(babsr)  : mean=228.10,  std=170.88, median=188.00, min=0, max=857

% - Number of leaves:
%     + neuralsat(S)(SX): mean=236.59,   std=447.80,   median=37.50,  min=0, max=3627
%     + neuralsat(SX)   : mean=902.25,   std=4957.22,  median=219.00, min=6, max=91318
%     + abcrown         : mean=3007.42,  std=12742.09, median=561.00, min=0, max=138918
%     + abcrown(babsr)  : mean=11714.62, std=41909.72, median=781.50, min=0, max=509765
% }


% \begin{tcolorbox}[left=1pt,right=1pt,top=1pt,bottom=1pt]
% \textbf{RQ3 Findings}: \prooflang{} is robust to variation in different verification algorithms and \proofcheck{} is applicable to any such proof and effective in checking
% the vast majority of those arising from the benchmarks.
% \end{tcolorbox}


\chapter{Common Engineerings and Optimizations}\label{chap:common-engineering}

In addition to adversarial attacks (\autoref{chap:adversarial-attacks}), DNN verifiers often employ a range of optimizations and engineering techniques to improve performance. This chapter discusses some of the common techniques used in modern DNN verifiers.

\section{Input Splitting}\label{sec:input-splitting}
Modern DNN verifiers~\cite{katz2019marabou,wang2018formal,wang2021beta,duong2025neuralsat} often use a technique called \emph{input splitting} to quickly deal with networks with verification problems involving low-dimensional networks, such as those in the ACAS Xu benchmark~\autoref{sec:acasxu} where the networks have a small number of inputs. Currently many work set the threshold to 50 inputs, i.e., if the network has more than 50 inputs, it is considered large and input splitting is not applied.

The idea is to split the original verification problem into subproblems, each checking whether the DNN produces the desired output from a smaller input region and returns \unsat{} if all subproblems are verified and \sat{} if a counterexample is found in any subproblem. Input splitting avoids BaB search---also called \emph{neuron splitting} and focuses on individual neurons---and is often used as a fast-path optimization to quickly eliminate easy cases.\hd{``fast-path optimization'' in the last sentence is not clear}

\begin{example}
    % Given $k$ available threads, \tool{} splits the original input region to obtain subproblems as described and and runs DPLL(T) on $k$ subproblems in parallel. % and iteratively splits any subproblem which cannot be solved within pre-defined amount of time, e.g., 2 seconds.
% Modern DNN verification tools such as \neuralsat{} uses the number of available CPU threads to determine the number of created subproblems.
Given the problem with input region $\{x_1 \in [-1,1] , x_2 \in [-2,2]\}$, \tool{} splits it into four subregions:
$\{x_1 \in [-1,0] , x_2 \in [-2,0]\}$, 
$\{x_1 \in [-1,0] , x_2 \in [0,2]\}$ , 
$\{x_1 \in [0,1] , x_2 \in [-2,0]\}$, and 
$\{x_1 \in [0,1], x_2 \in [0,2]\}$.  

\tool{} returns \unsat{} if it verifies all 4 subproblems and \sat{} if it found a counterexample in any of the subproblems. 
Note that the formula $-1 \le x_1 \le 1 \land -2 \le x_2 \le 2$ representing the original input region is equivalent to the formula $(-1 \le x_1 \le 0 \lor 0 \le x \le 1) \land (-2 \le x_2 \le 0 \lor 0 \le x_2 \le 2)$ representing the combination of the created subregions.
\end{example}


\section{Bounds Tightening}\label{sec:boundstigthten}

\subsection{Input Bounds Tightening}\label{sec:inputboundstigthten}
\hd{Every time verifier makes a split, it will create more constraints for each branch, e.g., $\hat{x}_i \le 0$ or $\hat{x}_i > 0$.

Recall the DNN from~\autoref{fig:dnn-b} can be represented as the formula $\alpha$
\[
\begin{aligned}
& \hat{x}_3 = -0.5x_1 + 0.5x_2 + 1.0 ~\land\\
& \hat{x}_4 = 0.5x_1 - 0.5x_2 + 1.0 ~\land\\    
& x_3 = \relu{\hat{x}_3} ~\land \\
& x_4 = \relu{\hat{x}_4} ~\land \\
& x_5 = -x_3 + x_4 - 1.0,
\end{aligned}
\]
and input property $\phi_{in}$
\(
-1 \le x_1 \le 1 \land -2 \le x_2 \le 2
\)

Suppose we make a split on $x_3$.
That will give us two subproblems, in which one problem has the constraint of
\(
    -0.5x_1 + 0.5x_2 + 1.0 \le 0
\)
and the other problem has the constraint of
\(
    -0.5x_1 + 0.5x_2 + 1.0 > 0
\).
For the first subproblem, we can create an optimization problem to tighten the bounds.
For example, to tighten the upper bounds of $x_1$, we can create an optimization problem as follows:
\begin{equation}
\begin{aligned}
\text{maximize~} &x_1 \quad \text{s.t.} \\
& -0.5x_1 + 0.5x_2 + 1.0 \le 0 \\
& -1 \le x_1 \le 1 \\
& -2 \le x_2 \le 2
\end{aligned}
\end{equation}

We can apply the same approach to tighten the lower bounds of $x_1$ by formulating the minimization and the upper/lower bounds of $x_2$.
Note that, this approach works particularly well for networks with small inputs, e.g., the ACAS Xu benchmark~\autoref{sec:acasxu} with 5 inputs, and is adopted by many modern DNN verification tools, including \marabou{} and \nnenum{}.
For larger input dimensions networkswe, it will take much time as we need to run $2 \times$ the number of inputs to tighten all the input bounds (for each input, we need to tighten the upper and lower bounds individually).

To reduce the time complexity, we can prioritize the input variables to tighten first, e.g., deciding the variable with the largest bounds first, and only tighten up to a maxinum number of inputs, e.g., 10 inputs.

\subsection{Neuron (Hidden) Bounds Tightening}\label{sec:neuronboundstigthten}

Instead of tightening the input bounds, we can tighten the bounds of the hidden neurons.
There are a couple of advantages of tightening the bounds of the hidden neurons:
\begin{enumerate}
\item In some networks, numbers of hidden neurons are \emph{fewer} than the number of inputs, e.g., the MNISTFC 2x256 network has $28\times 28 = 784$ inputs and only 512 hidden neurons.
\item We don't necessarily tighten all hidden neurons, as some hidden neurons are already stable, i.e., their lower bounds are greater than 0 or their upper bounds are less than 0.
\item More importantly, if a hidden neuron is stabilized after tightening its bounds, e.g., its lower bound becomes greater than 0 or its upper bound becomes less than 0, we no longer need to branch on that particular neuron.
\end{enumerate}

Let's revisit the example above, after splitting on $x_3$, we can tighten the upper bounds of $x_4$ (suppose that $l_{x_4} < 0 < u_{x_4}$, e.g., unstable and not split yet) by solving the following optimization problem:

\begin{equation}
\begin{aligned}
\text{maximize~} &x_4 \quad \text{s.t.} \\
& 0.5x_1 - 0.5x_2 + 1.0 \le 0 \\
& -1 \le x_1 \le 1 \\
& -2 \le x_2 \le 2
\end{aligned}
\end{equation}
If the optimization result yields a maximum value of $x_4$ less than 0, e.g., $u_{x_4} < 0$, we can conclude that $x_4$ is stabilized and no longer need to branch on $x_4$, thus, reducing the number of branches made by the verifier.
There will be many tweaks to make the optimization problem more efficient, e.g., setting a early stopping condition, e.g., if the maximum value of $x_4$ is less than 0, we can stop the optimization. It is because the fact that, if the upper bound of $x_4$ is already less than 0, $x_4$ will be considered as \emph{inactive} no matter what the \emph{optimal} upper bound is.

Note that, in both cases, optimization problems are independent (between inputs/neurons and lower/upper bounds), thus, we can solve them in parallel, e.g., optimizing the both upper and lower bounds of $x_1$ (input) and $x_4$ (neuron) in parallel.
}

% For networks with small inputs, DNN verification tools use a more aggressive abstraction process to achieve more precise computation. Specifically, they use LP solving to compute the tightest bounds for all input variables from the generated linear constraints. This computation is efficient when the number of inputs is small.



%(line~\ref{line:abstraction},~\autoref{alg:deduction})
% After tightening input bounds DNN verification tools apply abstraction to approximate the output bounds, which can be more precise with better input bounds.
% For networks with large number of inputs, we obtain input bounds from the input property $\phi_{in}$.\tvn{Vu: to rewrite}


% \ignore{
% \section{Branching Heuristics}\label{sec:branchingheuristics}
% Decision or branching heuristics decide free variables to make assignments and thus are crucial for the scalability of DPLL by reducing assignment mistakes~\cite{kroening2016decision,beyer2022progress}.

% For networks with small inputs, \tool{} prioritizes variables representing neurons with the \emph{furthest bounds} from the decision value 0 of ReLU, i.e., the 0 in $\max(x,0)$.
% Such neurons have wider bounds and therefore are more difficult to tighten during abstraction compared to other neurons.
% }





\section{Batch Processing} \label{sec:batchprocessing}
% \tvn{Do we still use this?  or we use the Parallel DPLL(T) in~\autoref{sec:parallel-search} instead?}
% For networks with small inputs, \tool{} uses a simple approach to create and solve subproblems in parallel.
% Given a verification problem $N_{orig} = (\alpha, \phi_{in}, \phi_{out})$, where $\alpha$ is the DNN and $\phi_{in} \Rightarrow \phi_{out}$ is the desired property, \tool{} creates subproblems $N_i = (\alpha, \phi_{{in}_i}, \phi_{out})$, where $\phi_{{in}_i}$ is the $i$-th subregion of the input region specified by $\phi_{in}$.
% Intuitively, each subproblem checks if the DNN produces the output $\phi_{out}$  from a smaller input region $\phi_{{in}_i}$.
% The combination of these subproperties $\bigwedge \phi_{{in}_i} \Rightarrow \phi_{out}$ is logically equivalent to the original property $\phi_{in} \Rightarrow \phi_{out}$.


% Given $k$ available threads, \tool{} splits the original input region to obtain subproblems as described and and runs DPLL(T) on $k$ subproblems in parallel. % and iteratively splits any subproblem which cannot be solved within pre-defined amount of time, e.g., 2 seconds.
% \tool{} returns \texttt{unsat} if it verifies all subproblems and \texttt{sat} if it found a counterexample in any subproblem. %In the current implementation, \tool{} uses the number of available threads to determine the number of created subproblems.
% For example, we split the input region $\{x_1 \in [-1,1] , x_2 \in [-2,2]\}$ into four subregions
% $\{x_1 \in [-1,0] , x_2 \in [-2,0]\}$,
% $\{x_1 \in [-1,0] , x_2 \in [0,2]\}$ ,
% $\{x_1 \in [0,1] , x_2 \in [-2,0]\}$, and
% $\{x_1 \in [0,1], x_2 \in [0,2]\}$.
% Note that the formula $-1 \le x_1 \le 1 \land -2 \le x_2 \le 2$ representing the original input region is equivalent to the formula $(-1 \le x_1 \le 0 \lor 0 \le x \le 1) \land (-2 \le x_2 \le 0 \lor 0 \le x_2 \le 2)$ representing the combination of the created subregions.

\hd{TODO: add batch processing}

\section{GPU Processing}\label{sec:gpu}

% \tvn{Hai, talk about how modern tools like crown and neuralsat leverage GPU.  Give details.  Provide small CUDO code and examples as needed.}
\hd{TODO: add GPU processing}

%\hd{Updated.}


%We note that this input splitting technique is different than other input splitting techniques whe

%% can be split into the subproblems  $-1 \le x_1 \le 1 \land -2 \le x_2 \le 2  \Rightarrow x_5 \le 0$

%% \tvn{hm .. if you have multiple inputs, how do you create regions from those?  e.g., if $\phi = 5\le i_1 \le 10 \land 10 \le i_2 \le 20$, then what is $\phi_k$?}
%% \hd{Split each input at a time, e.g., split $i_1$ from $5\le i_1 \le 10$ to $(5\le i_1 \le 8) \lor (8\le i_1 \le 10)$. Now original problem is $\phi = [(5\le i_1 \le 8) \lor (8\le i_1 \le 10)] \land (10 \le i_2 \le 20)$, or we could rewrite that formula in DNF form like $\phi = [(5\le i_1 \le 8) \land (10 \le i_2 \le 20)] \lor [(8\le i_1 \le 10) \land (10 \le i_2 \le 20)]$}\tvn{so if for i1 you make k1 splits,  i2 you make k2 splits,  .., then the number of sub probs is k1*k2*...kn?}\hd{yes, this thing is very trivial, I did it when I had no idea to optimize during that time}
%% After that, \tool{} creates multiple CDCL verification instances, and each of them will solve a subproblem independently\tvn{how do you determine the number of subregions? is it automatically based on the number of avail threads?} \hd{I did split based on number of threads for now.}




%In the input splitting used in~\cite{wang2018formal,wang2021beta}, they only compute the abstraction over each subregion once to get estimated output.
%If the subregion causes UNSAT, it will be eliminate immediately.
%Otherwise, they split that current subregion into multiple instances, and continue at the aforementioned abstraction step.
%In the other hand, in \tool{}, each CDCL instance takes input of a subregion and run for verifying it with iterations as in~\autoref{fig:alg}.

\part{Modern DNN Verification Tools}\label{part:modern-tools}
\chapter{The \neuralsat{} Algorithm}\label{chap:neuralsat}

\neuralsat{}~\cite{duong2025neuralsat,duong2024harnessing} is a relatively late competitor in the DNN verification space, but it has quickly become a strong contender, consistently placed among the top tools at DNN verification competitions~\autoref{chap:vnncomps}.

At its core, \neuralsat{} is BaB, but follows a DPLL(T) framework~\cite{davis1962machine} and includes unique optimizations and heuristics to improve the search performance.
Thus, \neuralsat{} is essentially an SMT solver with respect to a theory, in this case, the theory of DNNs.

\section{Overview}\label{sec:neuralsat:overview}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\linewidth]{figure/arch.pdf}
    \caption{\label{fig:overview} The \neuralsat{} DPLL(T) Algorithm.} 
\end{figure}


\autoref{fig:overview} gives an overview of \neuralsat{}, which consists of standard DPLL components (light shades) and the theory solver (dark shade).
\neuralsat{} first constructs a propositional formula over Boolean variables that represent the activation status of neurons (\emph{Boolean Abstraction}). Clauses in the formula assert that each neuron, e.g., neuron $i$, is active or inactive, e.g., $v_i \vee \overline{v_i}$.
This representation enables using standard DPLL to search for truth values satisfying these clauses and a DNN-specific theory solver to check the feasibility of truth assignments with respect to the constraints encoding the DNN and the property of interest.

\neuralsat{} now enters an iterative process to find a truth assignment---\emph{activation pattern} (\autoref{sec:activation-patterns})---satisfying the activation clauses.
First, \neuralsat{} assigns a truth value to an unassigned variable (\emph{Decide}), detects unit clauses caused by this assignment, and infers additional assignments (\emph{Boolean Constraint Propagation}).
Next, \neuralsat{} invokes the theory solver or T-solver (\emph{Deduction}), which uses LP solving and abstraction to check the satisfiability of the constraints of the current assignment with the property of interest. %The T-solver can also infer additional truth assignments.


If the T-solver confirms satisfiability, \neuralsat{} continues with new assignments (\emph{Decide}). Otherwise, \neuralsat{} detects a conflict   (\emph{Analyze Conflict}) and learns clauses to remember it and backtrack to a previous decision  (\emph{Backtrack}).
If \neuralsat{} detects local optima, it would restart (\emph{Restart}) the search by clearing all decisions that have been made, but save the conflict clauses learned so far to avoid reaching the same state in the next runs.
Restarting especially benefits challenging DNN problems by enabling better clause learning and exploring different decision orderings.

This iterative process repeats until \neuralsat{} can no longer backtrack, and returns \unsat{}, indicating the DNN has the property, or it finds a total assignment for all boolean variables, and returns \sat{}. % (and the user can query \neuralsat{} for a counterexample).

\autoref{sec:neuralsat-alg} provides more details on the \neuralsat{} algorithm, describing the main components of \neuralsat{} and how they work together to verify DNNs.


\section{Illustration}
\begin{example}\label{ex:neuralsat}
We use \neuralsat{} to prove that for inputs $x_1 \in [-1, 1], x_2 \in [-2,2]$ the DNN in~\autoref{fig:dnn} produces the output $x_5 \le 0$.
\neuralsat{} takes as input the formula $\alpha$ representing the DNN:

\begin{equation*}%\label{eq:ex}
\begin{aligned}
  x_3 &=  \relu{-0.5x_1 + 0.5x_2 + 1} ~\land\\
  x_4 &= \relu{x_1 + x_2 - 1} ~\land\\
  x_5 &= -x_3 + x_4 - 1.0
\end{aligned}
\end{equation*}
and the formula $\phi$ representing the property:

\begin{equation*}\label{eq:valid_prop}
    \phi : -1\le x_1 \le 1 \land -2 \le x_2 \le 2 \quad\Rightarrow\quad x_5 \le 0.
\end{equation*}

To prove $\alpha \Rightarrow \phi$, \neuralsat{} needs to show  that \emph{no} values of $x_1,x_2$ satisfying the input properties would result in $x_5 > 0$. In other words, \neuralsat{} needs to return \texttt{unsat} for: 
\begin{equation}\label{eq:negprop}
  \alpha\; \land\; -1 \le x_1 \le 1     \;\land\; -2 \le x_2 \le 2   \;\land\; x_5 > 0.
\end{equation} 

\textbf{Notation:} In the following, we write $x \mapsto v$ to denote that the variable $x$ is assigned with a truth value $v \in \{T,F\}$. This assignment can be either decided by \texttt{Decide} or inferred by \texttt{BCP}. We also write $x@dl$ and  $\overline{x}@dl$ to indicate the respective assignments $x \mapsto T$ and $x \mapsto F$  at decision level $dl$.

\paragraph{Boolean Abstraction} First, \neuralsat{} creates two Boolean variables $v_3$ and $v_4$ to represent the
%(pre-ReLU)
activation status of the hidden neurons $x_3$ and $x_4$, respectively. For example, $v_3=T$ means $x_3$ is \texttt{active} and thus gives the constraint $-0.5x_1 + 0.5x_2 + 1 > 0$. Similarly, $v_3=F$ means $x_3$ is \texttt{inactive} and therefore gives $-0.5x_1 + 0.5x_2 + 1\le 0$. Next, \neuralsat{} forms two clauses  $\{v_3 \lor \overline{v_3} \;;\; v_4 \lor \overline{v_4}\}$ ensuring that these variables are either \texttt{active} or \texttt{inactive}.


%Now, \neuralsat{} searches for truth assignments for activation variables to satisfy the clauses. %(and later check that they also satisfy the constraints of DNN implied by these variables and the properties to be proved).
%We summarize the five iterations \neuralsat{} uses to determine that no such assignment exists (i.e., \texttt{unsat}).

%We show how \neuralsat{} proves that network in~\autoref{fig:dnn} has property in ~\autoref{eq:valid_prop}, i.e., for any inputs $x_1 \in [-1, 1], x_2 \in [-2,2]$, the network produces the output $x_5 \le 0$. 

% \textbf{SAT formulation} \neuralsat{} first encodes the verification task into an SMT checking problem as described in \S\ref{sec:nnverif} by representing the network in~\autoref{fig:dnn}b as the formula:

% and negating of the property in Eq~\ref{eq:valid_prop}:
% \begin{equation}\label{eq:negprop}
%         -1 \le x_1 \le 1     \;\land\; -2 \le x_2 \le 2   
%         \;\land\; x_5 > 0.
% \end{equation} 

%\hd{I might use different weight for DNN to trigger some technique in the tool.}\tvn{yes, that's fine, make it as easy to illustrate as possible, but should also be challenging enough to require at least 2-3 iterations.  Also good to demonstrate 2 cases:  sat and unsat. For example, focus on say unsat,  and then after illustrating that,  make a new subsection and change something so that it would be sat and briefly mentions how \neuralsat{} would work to return sat}\tvn{\tool is complex, so instead of using the Dynaplex example, which is a bit too easy,  maybe look at the illustrative example for the GenTree's paper---it has more details.  Or even look at the Reluplex's illustrative example in the Survey paper}.

%We use an example\tvn{Hai: create an example, may be use the DNN from PA4 (or subset of that DNN)} to demonstrate how \neuralsat{} works. ~\autoref{fig:ex} shows a small DNN ....  


% \begin{figure}
%   \centering
%   \includegraphics[width=0.7\linewidth]{figure/example-b.pdf}
%   \caption{Simple FNN with ReLU activation.} \label{fig:ex}
% \end{figure}

%\hd{Step 0: About the network - copy somewhere, need to rewrite}
%\textbf{Running example}

%We use an example of simple fully-connected feed-forward neural network with %ReLU activation shown in~\autoref{fig:dnn} to demonstrate how \neuralsat{} works. 
%This network has already been trained and we have the learned weights and bias shown in the figure. 
%The network consists of three layers: an input layer, a hidden layer, and an output layer with two neurons each. 
%The weights on the edges represent the learned coefficients of the weight matrix used by the affine transformations done at each layer. The learned bias for each neuron is shown above or below it. 


% \neuralsat{} aims to find an assignment satisfying the conjunction of the formulae in ~\autoref{eq:ex} and~\ref{eq:negprop}. Such an assignment represents a counterexample violating the property, i.e., within the given ranges but does not satisfy the output requirement.
% %If such an input does not exist, \neuralsat{} returns \texttt{unsat}, indicating the property is valid. Otherwise it returns \texttt{sat} and the input, which represents a counterexample violating the property.

% Next, from the formula in ~\autoref{eq:ex}, \neuralsat{} creates two Boolean variables $v_3$ and $v_4$ to represent the status of the hidden pre-ReLU neurons $x_3'$ and $x_4'$. For example, $v_3=T$ means the status of $x_3$ is \texttt{on}, i.e., $-x_1-0.5x_2-1>0$ and $v_3=F$ means $x_4=\texttt{off}$, i.e.,  $-x_1-0.5x_2-1>0$. \neuralsat{} also forms two initial clauses indicating the status variables must be either \texttt{on} or \texttt{off}: $v_3 \lor \overline{v_3} \;;\; v_4 \lor \overline{v_4}$.



% \begin{equation}\label{eq:newvars}
%     \begin{aligned}
%         v_3 \vee \overline{v_3} \\
%         v_4 \vee \overline{v_4} 
%     \end{aligned}
% \end{equation}




% \begin{table*}
%   \caption{\neuralsat{}'s run producing \texttt{unsat}. The notation $x@dl$ and $\overline{x}@dl$ mean the assignments $x \mapsto T$ and $x \mapsto F$ at decision level $dl$, respectively.}\label{tab:valid}
%   \centering
%   \footnotesize
%     \begin{tabular}{c|c|cc|c|cc}
%     \toprule
%     Iter & \textbf{BCP} & \multicolumn{2}{c|}{\textbf{DEDUCTION}}& \textbf{DECIDE} & \multicolumn{2}{c}{\textbf{ANALYZE-CONFLICT}} \\
%       &&Constraints&Bounds&&Backtrack&Learned Clauses\\
%       \midrule
%       Init &-& $I = -1 \le x_1 \le 1; -2 \le x_2 \le 2$ & $-1 \le x_1 \le 1; -2 \le x_2\le 2$ & - &-&$C = \{v_3 \lor \overline{v_3};\; v_4 \lor \overline{v_4}\}$\\
      
%       1 &-&$I$ & $ x_5 \le 1 $& $\overline{v_4}@1$&-&-\\
      
%       2 &-&$I; x_4=\texttt{off}$&$ x_5 \le -1$& - & 0 &  $C = C \cup \{v_4\}$\\
      
%       3 &$v_4@0$&$I; x_4=\texttt{on} $&$ x_3 \ge 0.5; x_5 \le 0.5$ & $v_3@0$&-&-\\
      
%       4 &-&$I; x_3=\texttt{on}; x_4=\texttt{on}$&-&- & \bf{-1} & $C = C\cup \{\overline{v_4}\}$\\
      
%       % 5 &$v_4@0$&$I; x_3=\texttt{on}; x_4=\texttt{on}$&-&- & \bf{-1}& $C = C \cup \overline{v_3}\lor \overline{v_4}$\\
      
%        \bottomrule
%     \end{tabular}
% \end{table*}

%The goal is to find an activation pattern---a truth assignment for these variables---that satisfies the conjunction of the clauses in~\autoref{eq:negprop}. Such an assignment represents a counterexample violating the property, i.e., within the given ranges but does not satisfy the output requirement. If no such assignment exists, \neuralsat{} returns \texttt{unsat}, indicating the property is valid.

\paragraph{DPLL(T) Iterations} \neuralsat{} searches for a satisfying \emph{activation pattern}---truth assignment for the Boolean variables to satisfy the clauses and the constraints they represent with respect to the formula in~\autoref{eq:negprop}.
For this example, \neuralsat{} uses four iterations, summarized in~\autoref{tab:valid}, to determine that no such assignment exists and the problem is thus \unsat{}.


\begin{table*}
    \centering
    \caption{\neuralsat{}'s run producing \unsat{}.}\label{tab:valid}
    \footnotesize
      \begin{tabular}{ccccccc}
      \toprule
      Iter & \textbf{BCP} & \multicolumn{2}{c}{\textbf{DEDUCTION}}& \textbf{DECIDE} & \multicolumn{2}{c}{\textbf{ANALYZE-CONFLICT}} \\
        &&Constraints&Bounds&&Bt&Learned Clauses\\
        \midrule
        Init &-& $I = -1 \le x_1 \le 1; $& $-1 \le x_1 \le 1;$  & - &-&$C = \{v_3 \lor \overline{v_3};\; v_4 \lor \overline{v_4}\}$\\
        && $-2 \le x_2 \le 2$ & $-2 \le x_2\le 2$& & & \\
        1 &-&$I$ & $ x_5 \le 1 $& $\overline{v_4}@1$&-&-\\
        
        2 &-&$I; x_4=\texttt{off}$&$ x_5 \le -1$& - & 0 &  $C = C \cup \{v_4\}$\\
        
        3 &$v_4@0$&$I; x_4=\texttt{on} $&$ x_3 \ge 0.5; x_5 \le 0.5$ & $v_3@0$&-&-\\
        
        4 &-&$I; x_3=\texttt{on}; x_4=\texttt{on}$&-&- & \bf{-1} & $C = C\cup \{\overline{v_4}\}$\\
        
        % 5 &$v_4@0$&$I; x_3=\texttt{on}; x_4=\texttt{on}$&-&- & \bf{-1}& $C = C \cup \overline{v_3}\lor \overline{v_4}$\\
        
         \bottomrule
      \end{tabular}
  \end{table*}

  
%\emph{Initially}, the set of constraints  consists of the given bounds over the inputs, and the set of the clauses contains the two clauses in ~\autoref{eq:newvars}.

In \emph{iteration 1}, as shown in~\autoref{fig:overview}, \neuralsat{} starts with \texttt{BCP}, which has no effects because the current clauses and (empty) assignment produce no unit clauses.
In \texttt{Deduction}, \neuralsat{} uses an LP solver to determine that the current set of constraints, which contains just the initial input bounds, is feasible\footnote{We use the terms feasible, from the LP community, and satisfiable, from the SAT community, interchangeably.}. \neuralsat{} then uses abstraction to approximate an output upper bound $x_5 \le 1$ and thus deduces that satisfying the output $x_5 >0$ might be feasible. \neuralsat{} continues with \texttt{Decide}, which uses a heuristic to select the unassigned variable $v_4$ and sets $v_4=F$---essentially a \emph{guess} that neuron $x_4$ is inactive. \neuralsat{} increments the decision level ($dl$) to 1 and associates $dl=1$ to the assignment, i.e., $\overline{v_4}@1$.


In \emph{iteration 2}, \texttt{BCP} again has no effect because it does not detect any unit clauses. In \texttt{Deduction}, \neuralsat{} determines that current set of constraints, which contains $x_1 + x_2 - 1 \le 0$ due to the assignment $v_4\mapsto F$ (i.e., $x_4=\texttt{off}$), is feasible. \neuralsat{} then approximates a new output upper bound $x_5\le -1$, which means satisfying the output $x_5 > 0$ constraint is \emph{infeasible}.

\neuralsat{} now enters \texttt{AnalyzeConflict} and determines that $v_4$ causes the conflict ($v_4$ is the only variable assigned so far).  From the assignment $\overline{v_4}@1$, \neuralsat{} learns a ``backjumping'' clause $v_4$, i.e., $v_4$ must be $T$. \neuralsat{} now backtracks to $dl$ $0$ and erases all assignments decided \emph{after} this level. Thus, $v_4$ is now unassigned and the constraint  $x_1 + x_2 - 1 \le 0$ is also removed.

In \emph{iteration 3}, \texttt{BCP} determines that the learned clause is also a unit clause $v_4$ and infers $v_4@0$. In \texttt{Deduction}, we now have the new constraint $x_1 + x_2 - 1 > 0$ due to $v_4 \mapsto T$ (i.e., $x_4=\texttt{on}$).  With the new constraint, \neuralsat{} 
%\hd{tightens input bounds and get $0 \le x_2 \le 2$, then} 
approximates the output upper bound $x_5 \le  0.5$, which means $x_5>0$ might be satisfiable.
Also, \neuralsat{} computes new bounds $0.5 \le x_3 \le 2.5$ and $0 < x_4 \le 2.0$, and deduces that $x_3$ must be positive because its lower bound is 0.5. 
Thus, \neuralsat{} has a new assignment $v_3@0$ ($dl$ stays unchanged due to the implication). 
This new assignment inference from the T-solver is known as \emph{theory propagation} in DPLL(T).

In \emph{iteration 4}, \texttt{BCP} has no effects because we have no new unit clauses.  In \texttt{Deduction}, \neuralsat{} determines that the current set of constraints, which contains the new constraint $-0.5x_1+0.5x_2+1 > 0$ (due to $v_3 \mapsto T$), is \emph{infeasible}. Thus, \neuralsat{} enters \texttt{AnalyzeConflict} and determines that $v_4$, which was set at $dl=0$ (by \texttt{BCP} in iteration 3), causes the conflict. 
\neuralsat{} then learns a clause $\overline{v_4}$ (the conflict occurs due to the assignment $\{v_3 \mapsto T; v_4 \mapsto T\}$, but $v_3$ was implied and thus making $v_4$ the conflict).
However, because $v_4$ was assigned at decision level 0, \neuralsat{} can no longer backtrack and thus sets $dl=-1$ and returns \unsat{}, i.e , the property is valid.


% Note that because we backtrack to $dl=0$, we do not erase the assignment $v_3=T$ because it was decided at $dl=0$ (by BCP in iteration 3).

% In \emph{iteration 5}, because of the new clause $\overline{v_3} \lor v4$ and $v_3$ is already set to $T$, BCD infers $v_4=T$ at dl=0.  In DEDUCTION, \neuralsat{} determines that set of constraints, which contains $-0.5x_1+x_2+1> 0$ for $x_4'=\texttt{on}$ (because $v_4=T$), is infeasible. In ANALYZE-CONFLICT, \neuralsat{} determines $v_4$ causes the conflict  and learns the new clause $\overline{v3} \lor \overline{v4}$ (because the current assignment $v_3=1;v_4=1$ cause the conflict).
% \neuralsat{} then sets $dl=-1$ (because $v_4=T$ was decided at level 0) and realizes that it can no longer backtrack, and thus returns \texttt{unsat}.  Note that we can also see that the learned clauses $\{v_3, \overline{v_3} \lor v_4, \overline{v_3} \lor \overline{v_4}\}$ are not satisfiable.

%\tvn{do we use restart for this example?}\hd{we do not, it would be very long as in FSE paper.}

%Note that this example is too simple to illustrate the use of \emph{restart}, which is described in~\autoref{sec:restart-tree} and~\autoref{sec:restart} and crucial for more complicated and nontrivial problems.
\end{example}






%% \textbf{Discussion}
%% Testing. Does not affect soundness and helps with completeness.
%% Since the procedure is sampling-based, it is applicable to neural networks with any type of activation function.
%% Does not affect performance of DPLL(T) and helps quickly knock out easy instances as shown in experimentation.
%% Used by some verification tools. \tvn{SAT/SMT solvers also do that?} \hd{Not SAT/SMT solver, other verifiers, like ERAN, abcrown, also do that}


%% The falsification algorithm is \textbf{sound} but \textbf{not complete}. 
%% When a falsifying input has been found by our algorithm, it terminates by declaring the network as \textbf{unsafe} and the reported counterexample indeed violates the safety property of the network. 
%% However, when it terminates before finding any falsifying input, one cannot guarantee the absence of any falsifying input and consequently, the safety of the network with respect to the property.

%% % \subsection{Other DPLL components}

%% % Describe other DPLL components (BCP, Decide using VSIDS, etc).  If they are complicated enough,  give it its own section.  

%% \subsection{Properties of \tool{}}

%% \textbf{Sound} \tool{} is sound because the main DPLL algorithm is sound, also the abstraction domain are over-approximated techniques, then they are sound. 

%% \textbf{Complete} Deduce/Theory solver calls LP solver over the reals?

%% \textbf{Complexity} The worst-case complexity of \tool{} is exponential in the number of neurons. More specifically, the algorithm works by assigning activation status for each neuron (either on or off) and thus in the worst-case \tool{} will try all $2^n$ possible combinations of assignments, where $n$ is the number of neurons.  %Moreover, for each combination, \tool{} also performs linear programming solving to check for assignment feasibility.

%% \hd{
%%     This section is duplicated elsewhere
    
%%     \subsection{Difference between of \tool{} and BaB-based verifiers}
    
%%     For example, the network has 5 neurons corresponding to 5 variables, e.g., $\{v_1, v_2, v_3, v_4, v_5\}$. 
%%     Also, \tool{} already assigned $v_1@0, v_2@0, v_3@0$, and suppose that it has generated a conflict clause $c = \overline{v_2} \lor v_4 \lor v_5$.
%%     If \tool{} continue to split an unsigned neurons (e.g., $v_4$ or $v_5$), e.g., \tool{} chooses $v_4$.
%%     If $v_4@1$, there will be 2 cases for $v_5$, e.g., $v_5@2$ and $\overline{v_5}@2$.
%%     If $\overline{v_4}@1$, there will be only one case for $v_5$, that is, $v_5@2$, because of the generated conflict clause $c$.
%%     In total, there will be \textbf{at most} 3 splits to check with help of the learnt conflict clause $c$.
    
%%     In the other hand, if the BaB-based algorithm reached the same state above, e.g, there remains 2 unstable neurons $v_4, v_5$, and they need to check \textbf{at most} 4 splits.


%%     In short, we might be able to decrease some iterations with the help of the conflict clause learning technique.
%% }




\section{\tool{}'s Optimizations}\label{sec:optimizations}

\tool{}implements several optimizations to improve the performance of the search. First are the common optimizations used by other DNN verifiers, such as input splittings (\autoref{chap:common-engineering}) and adversarial attacks (\autoref{chap:adversarial-attacks}). In addition, \neuralsat{} implements several unique optimizations~\cite{duong2024harnessing} to improve the performance of the search. These are neuron stability, restart tree, and restart.


\subsection{Neuron Stability}\label{sec:stabilization}
A neuron is \emph{stable} if its activation status does not change regardless of the input values. In contrast, a neuron is \emph{unstable} if its activation status can change depending on the input values. For example, in the DNN in~\autoref{fig:dnn}, \tvn{any neuron stable? or they are all unstable?}


The key idea in using neuron stability is that if we can determine that a neuron is stable,  we can assign the exact truth value for the corresponding Boolean variable instead of having to guess. This has a similar effect as \mycode{BCP}---reducing mistaken assignments by \Decide---but it operates at the theory level instead of the propositional Boolean level.

%First, the T-solver creates a linear constraint system from the input assignment $\sigma$ and $\alpha \land \phi_{in} \land \overline{\phi_{out}}$, i.e., the formula in ~\autoref{eq:nnv2} representing the original problem  (line~\ref{line:lpsolver}).
%First, the T-solver creates a set of linear constraints representing ReLU activation for hidden neurons whose activation status have been decided.
%Next, those constraints are used in \textsc{Stabilize} for inferring status of neurons that are unassigned, \textsc{Deduce} then applies the polytope abstraction to check satisfiability.
%If the abstraction confirms the infeasibility, \textsc{Deduce} returns \texttt{False} so that \textsc{AnalyzeConflict} can analyze the assignment and and learn the conflict clause.
%Otherwise, the current assignment might be feasible and \textsc{Decide} continues to split more hidden neurons.


%\texttt{Stabilize} (\autoref{fig:alg} line~\ref{line:stabilize}) first creates linear constraints consisting of the DNN $\alpha$, the input \tvn{fillin} and output \tvn{fillin} conditions, and the current assignment $\sigma$. Next, it uses these constraints to generate a Mixed Integer Linear Programming (MILP) problem (~\autoref{eq:mip}), whose objective is compute a tighter lower and upper bounds for unstable neurons based on the current search state (i.e., the current assignment $\sigma$).

%the considered property into a set of constraints for
%The main goal of this process is to


%the boolean values activation status instead of
%that we can remove ReLU activation for hidden neurons whose activation status have been decided, each propositional variable in current assignment concretizes (removes) its corresponding constraints in MILP problem (~\autoref{eq:mip}) that helps solver reduce numbers of constraints and be able to tighten bounds further.



% \hd{Should mention about StabilizeCondition: \tool{} invokes Stabilize() after a number of iterations without improvement in Deduce step (abstraction), e.g, 10 iterations.}

%\tvn{candidate to remove}
%The complexity of this problem can increase exponentially with the number of ReLU neurons, so it would take long time to run even on a small network.
%In the previous work, \mipverify{}~\cite{tjeng2019evaluating} encoded the adversarial attack and verification of ReLU-based networks MIP problem, directly solved by existing MILP solvers (e.g., Gurobi).
%In this work, we do not use MILP for solving instances directly, instead we leverage the progressive bound tightening for determining tighter bounds for hidden neurons which is crucial for problem tractability: tight bounds strengthen the problem formulation and thus improve solve times~\cite{vielma2015mixed}.
%Furthermore, if we can prove that a neuron is stable, we can avoid splitting in the DPLL(T)-based search process.

%Theoretically, for ReLU-based networks, each neuron can either be \textit{active} (its input is positive) or \textit{inactive} (its input is negative so the output is 0), which can be encoded by discrete 0-1 variables.
%Those networks can be generally formulated into a MILP problem which has binary variables $a_j^{(i)}$ for an $j^{th}$ ReLU at layer $i$:

Stabilization involves the solution of a mixed integer linear program (MILP) system~\cite{tjeng2019evaluating}:
\begin{equation}
    \begin{aligned}
        &\mbox{(a)}\quad z^{(i)} = W^{(i)} \hat{z}^{(i-i)} + b^{(i)}; \\
        &\mbox{(b)}\quad y = z^{(L)};  x = \hat{z}^{(0)}; \\
        &\mbox{(c)}\quad \hat{z}_j^{(i)} \ge {z}_j^{(i)}; \hat{z}_j^{(i)} \ge 0; \\
        &\mbox{(d)}\quad a_j^{(i)} \in \{ 0, 1\} ;\\
        &\mbox{(e)}\quad \hat{z}_j^{(i)} \le {a}_j^{(i)} {u}_j^{(i)}; \hat{z}_j^{(i)} \le {z}_j^{(i)} - {l}_j^{(i)}(1 - {a}_j^{(i)}); \\
    \end{aligned}
    \label{eq:mip1}
\end{equation}
where $x$ is input, $y$ is output, and $z^{(i)}$, $\hat{z}^{(i)}$, $W^{(i)}$, and $b^{(i)}$ are the pre-activation, post-activation, weight, and bias vectors for layer $i$.
The equations encode the semantics of a DNN as follows:
(a) defines the affine transformation computing the pre-activation value for a neuron in terms of outputs in the preceding layer;
(b) defines the inputs and outputs in terms of the adjacent hidden layers;
(c) asserts that post-activation values are non-negative and no less than pre-activation values;
(d) defines that the neuron activation status indicator variables that are either 0 or 1; and
(e) defines constraints on the upper, $u_j^{(i)}$, and lower, $l_j^{(i)}$, bounds of the pre-activation value of the $j$th neuron in the $i$th layer.
Deactivating a neuron, $a_j^{(i)} = 0$, simplifies the first of the (e) constraints to $\hat{z}_j^{(i)} \le 0$, and activating a neuron simplifies the second to $\hat{z}_j^{(i)} \le z_j^{(i)}$, which is consistent with the semantics of $\hat{z}_j^{(i)} = max(z_j^{(i)},0)$.

%Even if \mycode{Stabilize} fails to stabilize, \tool{} still can solve problem by other components, e.g., parallel DPLL(T) search.



\SetKwFunction{GetUnassignedVariable}{GetUnassignedVariable}
\SetKwFunction{Sort}{Sort}

\begin{algorithm}
    \small

    \Input{DNN $\alpha$, property $\phi_{in} \Rightarrow \phi_{out}$, current assignment $\sigma$, number of neurons for stabilization $k$}
    \Output{Tighten bounds for variables \textbf{not} in $\sigma$ (unassigned variables)}
    \BlankLine

    % \tcp{create an MILP solver based on ~\autoref{eq:mip}}
    $\model \leftarrow \MIP(\alpha, \phi_{in}, \phi_{out}, \sigma)$ \tcp{create model (~\autoref{eq:mip1}) with  current assignment}

    $[v_1, ..., v_m] \leftarrow \GetUnassignedVariable(\sigma)$ \tcp{get all $m$ current unassigned variables} \label{line:find}


    $[v_1', ..., v_m'] \leftarrow \Sort([v_1, ..., v_m])$ \tcp{prioritize tightening order} \label{line:sort}
    $[v_1', ..., v_k'] \leftarrow \Select([v_1', ..., v_m'], k)$ \tcp{select top-$k$ unassigned variables, $k \le m$} \label{line:topk}

    \tcp{stabilize $k$ neurons in parallel}
    \Parfor{$v_i$ \textbf{in} $[v_1', ..., v_k']$}{
        \If(\tcp*[h]{lower is closer to 0 than upper, optimize lower first}){$(v_i.lower + v_i.upper) \ge 0$}{
            % \tcp{lower is closer to 0 than upper, optimize lower first}
            $\Maximize(\model, v_i.lower)$ \tcp{tighten lower bound of $v_i$} \label{line:maximize1}
            \If(\tcp*[h]{still unstable}){$v_i.lower < 0$}{
                $\Minimize(\model, v_i.upper)$ \tcp{tighten upper bound of $v_i$} \label{line:minimize1}
            }
        }
        \Else(\tcp*[h]{upper is closer to 0 than lower, optimize upper first}){
            % \tcp{upper is closer to 0 than lower, optimize upper first}
            $\Minimize(\model, v_i.upper)$ \tcp{tighten upper bound of $v_i$} \label{line:minimize2}
            \If(\tcp*[h]{still unstable}){$v_i.upper > 0$}{
                $\Maximize(\model, v_i.lower)$ \tcp{tighten lower bound of $v_i$} \label{line:maximize2}
            }
        }
    }
    \vspace*{-0.2in}
    \caption{\texttt{Stabilize}}
    \label{fig:stabilize}
\end{algorithm}



\autoref{fig:stabilize} describes Stabilize solves this equation system.
First,  a MILP problem is created from the current assignment, the DNN, and the property of interest using formulation in ~\autoref{eq:mip1}.
Note that the neuron lower (${l}_j^{(i)}$) and upper bounds (${u}_j^{(i)}$) can be quickly computed by polytope abstraction.

Next, it collects a list of all unassigned variables which are candidates being stabilized (line~\ref{line:find}).
In general, there are too many unassigned neurons, so
\mycode{Stabilize} restricts consideration to $k$ candidates.
Because each neuron has a different impact on abstraction precision we prioritize the candidates.
In \mycode{Stabilize}, neurons are prioritized based on their interval boundaries (line~\ref{line:sort}) with a preference for neurons with either lower or upper bounds that are closer to zero.
The intuition is that neurons with bounds close to zero are more likely to become stable after tightening.

We then select the top-$k$ (line~\ref{line:topk}) candidates and seek to further tighten their interval bounds.
The order of optimizing bounds of select neurons is decided by its boundaries, e.g., if the lower bound is closer to zero than the upper bound then the lower bound would be optimized first.
These optimization processes, i.e., \mycode{Maximize} (line~\ref{line:maximize1} or line~\ref{line:maximize2}) and \mycode{Minimize} (line~\ref{line:minimize1} or line~\ref{line:minimize2}), are performed by an external LP solver (e.g., Gurobi~\cite{gurobi}).

%Note that the work in~\cite{tjeng2019evaluating} uses the MILP system in ~\autoref{eq:mip} to encode the entire verification problem and thus is limited to the encodings of small networks that can be handled by an LP solver.
%This MILP system is used by~\cite{tjeng2019evaluating} to encode the entire verification problem. It is passed to an LP solver to optimize the output of the network with respect to the the property of interest.
%This approach only works small networks whose constraints can be handled by LP solving.
%In contrast, \tool{} creates this system based on the current assignment, which has significantly fewer constraints.
%Moreover, we only use the computed bounds of hidden neurons from this system, and thus even if it cannot be solved, \tool{} will still continue.



\begin{example}
  \tvn{Need a concrete example here.  Use the DNN in~\autoref{fig:dnn} and create the MILP system in ~\autoref{eq:mip1}.}
\end{example}

\subsubsection{Parallel Search}\label{sec:parallel-search}
% Things need to write about
% \begin{itemize}
%     \item [+] how to parallelize DPLL: remove backtrack, compute both branches
%     \item [+] how to use learned clauses: run several times until problem is solved or reaches timeout, save conflict clauses before restarting and use them as initial clauses for next runs
%     \item [!] non-chronological backtracking isn't supported yet, need more engineering to handle this sort of backtracks
% \end{itemize}


%\tvn{this section is short. Add some more, may be some small examples (recall in the POPL paper we have various examples describing various DPLL components).  Does the tree in Fig1. applicable here?  If so you can refer to it. }
%\hd{it appears that's purely engineering to me, shouldn't be focused too much}\tvn{just write what engineerings were used here to help people understand how it works.  Also describe how this removes the need for Backtracking}
% We adopt the idea of Distributed tree search (DTS) algorithm which is a class of algorithms for searching values in an efficient and distributed manner~\cite{ferguson1988distributed}.
% \matt{I woud cite DTS.}
% Their purpose is to iterate through a tree by working along multiple branches in parallel and merging the results of each branch into one common solution, in order to minimize time spent searching for a value in a tree-like data structure.
% DPLL(T) is tree-search problem in each internal nodes is actually an activation pattern containing conditions values along the path from root to such node.
% \matt{replace path condition with activation pattern throughout the paper}
% The arrival of many-core machines leads to new possibilities for SAT solving.
% \matt{What techniques do the parallel SAT people use, i.e., \cite{le2017painless}, we should relate our solution to theirs.}
% Parallel SAT solving rely on two concepts: parallelization strategy and learnt clause exchanges.
% Two main parallelization methods have been developed: Portfolio~\cite{hamadi2010manysat} and Divide-and-Conquer~\cite{le2017painless}.
% The main idea of Portfolio is to run sequential solvers working in parallel on the entire formula, in a competitive way, aiming at increasing the probability of finding a solution using the diversification.
% The Divide-and-Conquer (DnC) approach is based on splitting the search space in disjoint subspaces that are solved independently in parallel by different workers.
% If a subspace is proven sat then the initial formula is sat.
% The formula is unsat if all the subspaces are unsat.
% The challenging points of the divide-and-conquer mechanism are:
% dividing the search space, balancing jobs between workers, and exchanging learnt clauses.

% We follow the DnC scheme
The DPLL(T) process in \tool{} is designed as a tree-search problem where each internal node encodes an \textit{activation pattern} defined by the variable assignments from the root.
To parallelize DPLL(T), we adopt a beam search-like strategy which combines distributed search from Distributed Tree Search (DTS) algorithm~\cite{ferguson1988distributed} and Divide and Conquer (DNC)~\cite{le2017painless} paradigms for splitting the search space into disjoint subspaces that can be solved independently.
At every step of the search algorithm, we select up to $n$ nodes  of the DPLL(T) search tree to create a beam of width $n$.
This splits (like DNC) the search into $n$ subproblems that are independently processed.  Each subproblem extends the tree by a depth of 1.

Our approach simplifies the more general DNC scheme since the $n$ bodies of the \textbf{parfor} on line~\ref{line:parfor} of~\autoref{fig:alg} are roughly load balanced.
While this is a limited form of parallelism, it sidesteps one of the major roadblocks to DPLL parallelism -- the need to efficiently synchronize across load-imbalanced subproblems~\cite{le2017painless,le2019modular}.

In addition to raw speedup due to multiprocessing, parallelism accelerates the sharing of information across search subspaces, in particular learned clause information for DPLL. In \tool{}, we only generate independent subproblems which eliminates the need to coordinate their solution. When all subproblems are complete, their conflicts are accumulated,~\autoref{fig:alg} line~\ref{line:analyze_conflict},  to inform the next round of search.
As we show in \S\ref{sec:eval}, the engineering of this form of parallelism in DPLL(T) leads to substantial performance improvement.

\subsection{Restart}

\SetKwFunction{threshold}{threshold}
\SetKwFunction{maxvisited}{max\_visited}
\SetKwFunction{maxremaining}{max\_remaining}
\SetKwData{implicationgraph}{igraph}


% \begin{algorithm}
%     \small

%     \Input{TBD}
%     \Output{TBD}
%     \BlankLine

%     $\threshold \leftarrow 3$ \tcp{predefined maximum number of restarts}
%     $\maxvisited \leftarrow 200000$ \tcp{predefined maximum number of visited nodes}
%     $\maxremaining \leftarrow 30000$ \tcp{predefined maximum number of remaining nodes}

    % \tcp{create an MILP solver based on ~\autoref{eq:mip}}
    % $\model \leftarrow \MIP(\alpha, \phi_{in}, \phi_{out}, \sigma)$ \tcp{create model (~\autoref{eq:mip}) with  current assignment}

    % $[v_1, ..., v_m] \leftarrow \GetUnassignedVariable(\sigma)$ \tcp{get all $m$ current unassigned variables} \label{line:find}


    % $[v_1', ..., v_m'] \leftarrow \Sort([v_1, ..., v_m])$ \tcp{prioritize tightening order} \label{line:sort}
    % $[v_1', ..., v_k'] \leftarrow \Select([v_1', ..., v_m'], k)$ \tcp{select top-$k$ unassigned variables, $k \le m$} \label{line:topk}

    % \tcp{stabilize $k$ neurons in parallel}
    % \For{$v_i$ \textbf{in} $[v_1', ..., v_k']$}{
    %     \If(){$(v_i.lower + v_i.upper) \ge 0$}{
    %         \tcp{lower is closer to 0 than upper, optimize lower first}
    %         $\Maximize(\model, v_i.lower)$ \tcp{tighten lower bound of $v_i$}
    %         \If(){$v_i.lower < 0$}{
    %             \tcp{still unstable}
    %             $\Minimize(\model, v_i.upper)$ \tcp{tighten upper bound of $v_i$}
    %         }
    %     }
    %     \Else{
    %         \tcp{upper is closer to 0 than lower, optimize upper first}
    %         $\Minimize(\model, v_i.upper)$ \tcp{tighten upper bound of $v_i$}
    %         \If(){$v_i.upper > 0$}{
    %             \tcp{still unstable}
    %             $\Maximize(\model, v_i.lower)$ \tcp{tighten lower bound of $v_i$}
    %         }
    %     }
    % }
%     \caption{\texttt{Reset}}
%     \label{fig:restart}
% \end{algorithm}

As with any stochastic algorithm, \tool{} would perform poorly if it gets into a subspace of the search that does not quickly lead to a solution, e.g., due to choosing a bad sequence of neurons to split~\cite{ferrari2022complete,wang2021beta,de2021improved}.
%In the development of modern SAT solver (e.g.PicoSAT~\cite{biere2008picosat}), researchers has realized most practical problems, even very large or complex, can be easily solved if they follow
This problem, which has been recognized in early SAT solving, motivates the introduction of restarting the search~\cite{gomes1998boosting} to avoid being stuck in such a \emph{local optima}. %This kind of heavy-tail behavior was also the motivation in the original publication on restarts \cite{}.


%In our context where easy SAT instances are usually falsified by external adversarial attack (e.g., PGD~\cite{madry2017towards}), or easy UNSAT instances are often verified within few iterations (e.g., a single iteration), we adopt restart schedule to avoid local optima during search process for ``hard'' problems (at certain points, the abstraction would not be improved or rarely improved).
%Moreover, previous related work showed that the order of making decisions had a great impact to their performance, hence, we hope that after restarting and decision heuristic is changed, \tool{} can follow other search directions toward the goal.

%\tvn{I am not so sure about listing all these numbers. Do we have to write about them here?}\hd{I think so, we can neglect those number too, those are heuristically selected and we didn't change them, different numbers might have different performances.}
\tool{} uses a simple restart heuristic that triggers a restart when either the number of processed assignments (nodes) exceeds a pre-defined number or the number of remaining assignments that need be checked exceeds a pre-defined threshold. % (e.g, 5000). (e.g, 20000)
% It also has a fast restart on the \textit{first} run when it detects a number of consecutive iterations (e.g., 10) without any improvement in abstraction steps.
%The period of restart is repeated until exceed a predefined maximum number of restarts (e.g., 3).
%These thresholds are chosen heuristically based on our experience. %and subject to change and performance of \tool{} might vary depending on those numbers.
After a restart, \tool{} avoids using the same decision order of previous runs (i.e., it would use a different sequence of neuron splittings). It also resets all internal information except the learned conflict clauses, which are kept and reused as these are \textit{facts} about the given constraint system.
This allows a restarted search to quickly prune parts of the space of assignments.
Although restarting may seem like an engineering aspect, it plays a crucial role in stochastic algorithms, and helps \neuralsat{} reduce verification time for challenging problemsk.

%In addition, to avoid revisiting the same search space over and over again, the decision  is changed at the beginning of every new run and conflict clauses learned so far are saved and never deleted.

% \hd{Why are restarts beneficial?}




\section{\tool{} vs. BaB}\label{sec:restart-tree}


\begin{figure}[t]
    \begin{minipage}[b]{\textwidth}
    \centering
        \begin{minipage}[t]{0.495\textwidth}
            \centering
            \includegraphics[width=\linewidth]{figure/cdcl-tree-clause.png}
            % \includegraphics[width=\linewidth]{figure/cdcl-tree-clause.pdf}
            \caption*{(a) \tool{}}
        \end{minipage}
        % \hspace{0.5cm}
        \hfill
        \begin{minipage}[t]{0.44\textwidth}
            \centering
            \includegraphics[width=\linewidth]{figure/none-cdcl-tree.pdf}
            \caption*{(b) Others}
        \end{minipage}
        % \hfill
        \vspace{-0.1in}
        \caption{Search tree explored by \tool{} (a) and other verifiers (b) during a verification run.
        \tvn{Hai, instead of other verifiers can we say this search tree is for a native/general BaB approach?}
        The notation $\{...\}$ indicates learned clauses; red is  infeasibility; white is feasibility; yellow is BCP application; and blue is current consideration.
        The search tree of \tool{} is smaller than the tree of the other techniques because \tool{} was able to prune various branches, e.g., through BCPs (e.g., ${v_3}$ and $\overline{v_5}$) and non-chronological backtracks (e.g., $\overline{v_3}$).}
        % \hd{missing a paragraph writing about this figure.}\tvn{yes, may be in the overview or intro if appropriate}\hd{still thinking of incorporating learned clauses.}
        \label{fig:tree}
    \end{minipage}
\end{figure}

\tvn{TODO: talk about how \tool{} is BaB but has things such as CDCL to help prune the search space.}

%modern DPLL implementations restart the DPLL procedure whenever the search is not making enough progress according to some measure. The rationale behind this idea is that upon each restart, the additional knowledge of the search space compiled into the newly learned lemmas will lead the heuristics for Decide to behave differently, and possibly cause the procedure to explore the search space in a more compact way. The combination of learning and restarts has been shown to be powerful not only in practice, but also in theory. Essentially, any Basic DPLL derivation to FailState is equivalent to a tree-like refutation by resolution. But for some classes of problems tree-like proofs are always exponentially larger than the smallest general, that is, DAG-like, resolution ones [Bonet et al. 2000]. The good news is that DPLL with learning and restarts becomes again equivalent to general resolution with respect to such notions of proof complexity [Beame et al. 2003].




\tvn{rewrite: technically we don't split if the guess was right}
Note that this process of selecting and assigning (guessing) values to variables representing neurons is the \emph{branching} phase in BaB. It is also commonly called \emph{neuron splitting} because  it splits the search tree into subtrees corresponding into the assigned values (e.g., see~\autoref{sec:restart-tree}).





As mentioned in~\autoref{sec:complexity}, ReLU-based DNN verification is NP-complete, and for difficult problem instances DNN verification tools often have to exhaustively search a very large space, making scalability a main concern for modern DNN verification.

%One major difference that sets \tool{} apart from other DNN approaches is how it tackles and prunes such large search space.

\autoref{fig:tree} shows the difference between \tool{} and another DNN verification tool (e.g., using the popular Branch-and-Bound (BaB) approach) in how they navigate the search space.  We assume both tools employ similar abstraction and neuron splitting.
\autoref{fig:tree}b shows that the other tool performs splitting to explore different parts of the tree (e.g., splitting $v_1$ and explore the branches with $v_1=T$ and $v_1=F$ and so on). Note that the other tool needs to consider the tree shown regardless if it runs sequentially or in parallel.

% \tvn{Hai, could you change the LaTeX neg to overline?}\hd{yes}
In contrast, \tool{} has a smaller search space shown in~\autoref{fig:tree}a.
\tool{} follows the path $v_1$, $v_2$ and then $\overline{v_2}$ (just like the tool on the right).
However, because of the learned clause $v_2\lor v_3$, \tool{} performs a BCP step that sets $v_3$ (and therefore prunes the branch with $\overline{v_3}$ that needs to be considered in the other tree).
Then \tool{} splits $v_4$, and like the other tool, determines infeasibility for both branches. Now \tool{}'s conflict analysis determines from learned clauses that it needs to backtrack to $v_3$ (yellow node) instead of $v_1$.  Without learned clauses and non-chronological backtracking, \tool{} would backtrack to decision $v_1$ and continues with the $\overline{v_1}$ branch, just like the other tool in~\autoref{fig:tree}b.

Thus, \tool{} was able to generate non-chronological backtracks and use BCP to prune various parts of the search tree.  In contrast, the other tool would have to move through the exponential search space to eventually reach the same result as \tool{}.




\chapter{The \reluplex{} Algorithm}\label{chap:reluplex}

\reluplex{}~\cite{katz2017reluplex} is a classical BaB (\autoref{chap:bab}) approach for verifying neural networks. The technique extends the simplex method~\cite{nelder1965simplex} to support the ReLU activation function (\textbf{Reluplex} = \textbf{Relu} + Sim\textbf{plex}). \reluplex{} has been succeeded by the Marabou~\cite{katz2019marabou} tool, which are more efficient and scalable. However, the core ideas of \reluplex{} are still relevant and therefore we present it here.

\section{Illustration}

\begin{figure}[h]
    \centering
    \begin{minipage}{0.49\linewidth}
        \centering
        \includegraphics[width=0.6\linewidth]{reluplexA.pdf}
        \caption{A DNN example}\label{fig:reluplex}
    \end{minipage}
    \hfill
    \begin{minipage}{0.50\linewidth}
        \centering
        \includegraphics[width=0.9\linewidth]{reluplexB.pdf}
        \caption{Separating nodes to represent RELU}\label{fig:reluplexB}
    \end{minipage}
  \end{figure}

  %TODO: should use our current example, per haps for disproving property.


  \begin{example}\label{ex:reluplex}

  We use the DNN in~\autoref{fig:reluplex} to demonstrate \reluplex{}. Assume we want to check that the DNN has the property
\begin{equation}\label{eq:prop1}
  (0 \le i_0 \le 0.5 \land -2 \le i_1 \le -1) \implies ( n_{10}< 0 \lor n_{10} > 0.5).
\end{equation}
That is, when the inputs $i_0, i_1$ fall within certain ranges, then the result $n_{10}$ has certain values.
As mentioned in~\ref{sec:satisfiability-and-activation-pattern-search}, we turn this into a satisfiability problem by negating the property and checking if the negation is unsatisfiable.
In this case, we want to check if the negation of ~\autoref{eq:prop1} is \unsat{}:
\begin{equation}\label{eq:negprop1}
    ( 0 \le i_0 \le 0.5 \land -2 \le i_1 \le -1) \land 0 \le n_{10} \le 0.5.
  \end{equation}

If~\autoref{eq:negprop1} is \unsat{}, then the DNN satisfies the property in~\autoref{eq:prop1}---there exists no assignment of the inputs $i_0, i_1$ such that the output $n_{10}$ is within the range $[0, 0.5]$. Otherwise, the DNN does not have the property and we can return a counterexample.


\paragraph{Problem Encoding}  A DNN can be encoded as a conjunctions of constraints.  The ReLU node $v$ can be encoded as a pair of variables $v'$ and $v''$, where $v'$ is used to connect the nodes of previous layers to $v$, and $v''$ is used to connect $v$ to the next layer.

For example, in~\autoref{fig:reluplex}, the ReLU node $n00=\max(i0 -1i1,0)$ is encoded using two variables $n00'=i0 -1i1$ and $n00''=\max(n00',0)$.  The DNN in\autoref{fig:reluplexB} shows the network in~\autoref{fig:reluplex} with additional nodes representing ReLU encoding.



The first step to use Repluplex is to encode the constraints representing the DNN and the problem into a format that Reluplex accepts.
The DNN in~\autoref{fig:reluplex} can be encoded as a conjunction of equalities:

\begin{gather*}%\label{eq:reluplex1}
    n00' = i_0 - i_1,\quad n00'' = \max(n00',0),\\
    n01' = i_0 + i_1, \quad n01'' = \max(n01',0),\\
    n_{10} = 0.5n00'' - 0.2n01''
\end{gather*}

\paragraph{Basic Variables} We also introduce three new \emph{basic} (auxilliary or slack) variables to store the relationships of the DNN's constraints:
\begin{gather}
  a_1 = i_0 - v^b_{12} - n00'\label{eq:reluplex2a},\\
  a_2 = i_0 + v^b_{12} - n01'\label{eq:reluplex2b},\\
  a_3 = 0.5n00'' -0.2 n01'' - n_{10}\label{eq:reluplex2c}
\end{gather}

In simplex terminology, a basic variable is a variable that is used to represent the relationship between other variables in the constraints. For example, $a_1$ represents the difference between $i_0$, $v^b_{12}$, and $n00'$. The basic variables are used to maintain the relationships between the variables in the constraints and are updated during the search process.

In contrast, a \emph{non-basic} variable is a variable that is not used to represent the relationship between other variables in the constraints. For example, $i_0$ and $i_1$ are non-basic because they are not used to represent the relationship between other variables in the constraints. Non-basic variables are typically the input variables of the DNN.

\paragraph{Iteration} \reluplex{} first assigns 0 to all \tvn{basic?} variables in the constraints in~\autoref{eq:reluplex2a}--~\autoref{eq:reluplex2c}.  This assignment---essentially an initial guess---would likely cause issues such as variables violating their bounds.  \reluplex{} works by iteratively fixing these invalid values until it finds a feasible assignment (and returns \texttt{sat}) or cannot do so (and returns \texttt{unsat}).

This iterative updating process can be demonstrated through a sequence of configuration updates over the variables.
~\autoref{tab:reluplex1} shows the initial configuration with all values assigned to 0.
Observe that the lower and upper bounds of the inputs $i_0, i_1$ and output $n_{10}$ are specified in the property in ~\autoref{eq:negprop1}, the lower bounds of $v_f$'s representing ReLU are 0, and the other hidden variables are unbounded.

\begin{table}[h]
    \centering
\begin{tabular}{ccccccccccc}
     & $i_0$ & $i_1$ & $n00'$ & $n00''$ & $n01'$ & $n01''$ & $n_{10}$ &$a_1$&$a_2$&$a_3$ \\
    \midrule
    LB & 0 & -2 & $-\infty$&0&$-\infty$& 0 & 0 & 0 & 0 &0\\
    Val& 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
    UP & 0.5 & -1 &$\infty$&$\infty$&$\infty$&$\infty$&0.5& 0 & 0 & 0
\end{tabular}
\caption{Configuration \#1}\label{tab:reluplex1}
\end{table}

\autoref{tab:reluplex1} shows that $i_1$ is out-of-bounds because $0 \notin [-2,-1]$. To fix $i_1$, which is non-basic, Reluplex simply updates it to a valid value, e.g., $i_1 \texttt{+=} -1.0 = -1.0$, which means adding -1.0 to the current value of $i_1$ and thus having $i_1= -1.0$.
Now, because $a_1, a_2$ depend on $i_1$ as shown in~\autoref{eq:reluplex2a} and~\autoref{eq:reluplex2b}, respectively, this update to $i_1$ also changes $a_1,a_2$:
    \begin{align*}
        a_1 ~+=~ 1.0 = 1.0   &~\text{because}~ a_1=i_0 - i_1 - n00', \\
        a_2 ~+=~ -1.0 = -1.0  & ~\text{because}~ a_2=i_0 + i_1 - n01'.\\
    \end{align*}



\autoref{tab:reluplex2} shows the new configuration.
\autoref{tab:reluplex2} also shows $a_1, a_2$ violate their bounds and need to be fixed. Assume Reluplex picks $a_1$. To fix $a_1$, which is a basic variable, Reluplex pivots (swaps) it with one of the variables it depends on as shown in the constraint $ a_1 = i_0 - v^b_{12} - n00'$ in~\autoref{eq:reluplex2a}. Assume Reluplex pivots $a_1$ with $n00'$, we get
\begin{equation}\label{eq:reluplex5}
n00' = i_0 - v^b_{12} - a_1.
\end{equation}


\begin{table}[h]
    \centering
\begin{tabular}{ccccccccccc}
     & $i_0$ & $i_1$ & $n00'$ & $n00''$ & $n01'$ & $n01''$ & $n_{10}$ &$a_1$&$a_2$&$a_3$ \\
    \midrule
    LB & 0 & -2 & $-\infty$&0&$-\infty$& 0 & 0 & 0 & 0 &0\\
    Val& 0 & \textbf{-1} & 0 & 0 & 0 & 0 & 0 & \textbf{1} & \textbf{-1} & 0\\
    UP & 0.5 & -1 &$\infty$&$\infty$&$\infty$&$\infty$&0.5& 0 & 0 & 0\\\
\end{tabular}
\caption{Configuration \#2}\label{tab:reluplex2}
\end{table}


Reluplex now updates the non-basic $a_1$ to 0 ($a_1 \text{+=} -1.0 = 0$). This also changes $n00'$  to 1.0 ($n00'+=1.0 = 1.0)$ because $n00'$ depends on $a_1$ as shown in~\autoref{eq:reluplex5}.

\begin{table}[h]
    \centering
\begin{tabular}{ccccccccccc}
     & $i_0$ & $i_1$ & $n00'$ & $n00''$ & $n01'$ & $n01''$ & $n_{10}$ &$a_1$&$a_2$&$a_3$ \\
    \midrule
    LB & 0 & -2 & $-\infty$&0&$-\infty$& 0 & 0 & 0 & 0 &0\\
    Val& 0 & -1 & \textbf{1} & 0 & 0 & 0 & 0 & \textbf{0} & -1 & 0\\
    UP & 0.5 & -1 &$\infty$&$\infty$&$\infty$&$\infty$&0.5& 0 & 0 & 0\\\
\end{tabular}
\caption{Configuration \#3}\label{tab:reluplex3}
\end{table}

~\autoref{tab:reluplex3} shows the new configuration. ~\autoref{tab:reluplex3} also shows the basic variable $a_2$ is out-of-bound.  To fix it, Reluplex pivots $a_2$ with a variable it depends on as shown in the constraint $a_2 = i_0 + v^b_{12} - n01'$ in Eq~\ref{eq:reluplex2b}.  Assume Reluplex pivots $a_2$ with $n01'$, we get
\begin{equation}\label{eq:reluplex6}
  n01' = i_0 + v^b_{12} - a_2
\end{equation}
Now $a_2$ becomes non-basic and is updated to 0 through $a_2+= 1.0 = 0$. As $n01'$ depends on $a_1$ as shown in ~\autoref{eq:reluplex6}, we make the change $n01' ~\texttt{-=}~1.0 = -1.0$.


\begin{table}[h]
    \centering
\begin{tabular}{ccccccccccc}
     & $i_0$ & $i_1$ & $n00'$ & $n00''$ & $n01'$ & $n01''$ & $n_{10}$ &$a_1$&$a_2$&$a_3$ \\
    \midrule
    LB & 0 & -2 & $-\infty$&0&$-\infty$& 0 & 0 & 0 & 0 &0\\
    Val& 0 & -1 & 1 & 0 & \textbf{-1} & 0 & 0 & 0 & \textbf{0} & 0\\
    UP & 0.5 & -1 &$\infty$&$\infty$&$\infty$&$\infty$&0.5& 0 & 0 & 0\\\
\end{tabular}
\caption{Configuration \#4}\label{tab:reluplex4}
\end{table}

~\autoref{tab:reluplex4} shows the new configuration.
At this point, we no longer have out-of-bound variables, but have inconsistent values for the pair of RELU variables $n00', n00''$. This is because $n00'' = \max(n00',0)$ but  we have $n00'=1$ thus $\max(1,0)=1$, which is not $n00''=0$.  Thus, Reluplex needs to fix either $n00''$ or $n00'$.

Assume Reluplex picks $n00''$. Because $n00''$ is non-basic, we simply update it, i.e.,  $n00'' = \text{+} 1 = 1$.  As $a_3$ depends on $n01''$, i.e., $ a_3 = 0.5n00'' -0.2 n01'' - n_{10}$, Reluplex also makes the change $a_3+= 0.5\times 1.0=0.5$.



\begin{table}[h]
    \centering
\begin{tabular}{ccccccccccc}
     & $i_0$ & $i_1$ & $n00'$ & $n00''$ & $n01'$ & $n01''$ & $n_{10}$ &$a_1$&$a_2$&$a_3$ \\
    \midrule
    LB & 0 & -2 & $-\infty$&0&$-\infty$& 0 & 0 & 0 & 0 &0\\
    Val& 0 & -1 & 1 & \textbf{1} & -1 & 0 & 0 & 0 & 0 & \textbf{0.5}\\
    UP & 0.5 & -1 &$\infty$&$\infty$&$\infty$&$\infty$&0.5& 0 & 0 & 0\\\
\end{tabular}
\caption{Configuration \#5}\label{tab:reluplex5}
\end{table}

~\autoref{tab:reluplex5} shows the new configuration.
In the new configuration, $a_3$ is out-of-bound. To fix this basic variable, we pivot $a_3$ with one of the variables $n00'', n01'', n_{10}$ because of the constraint $a_3 = 0.5n00'' -0.2 n01'' - n_{10}$ in ~\autoref{eq:reluplex2c}. Assume we pivot $a_3$ with $n_{10}$, we get
\begin{equation}\label{eq:reluplex7}
  n_{10} = 0.5n00'' -0.2 n01'' - a_3
\end{equation}

Now, $a_3$ becomes non-basic and we update it to 0 through $a_3+=-0.5=0$.  As $n_{10}$ depends on $a_3$ as shown in Eq~\ref{eq:reluplex7}, we make the change $n_{10} += 0.5=0.5$.

\begin{table}[h]
    \centering
\begin{tabular}{ccccccccccc}
     & $i_0$ & $i_1$ & $n00'$ & $n00''$ & $n01'$ & $n01''$ & $n_{10}$ &$a_1$&$a_2$&$a_3$ \\
    \midrule
    LB & 0 & -2 & $-\infty$&0&$-\infty$& 0 & 0 & 0 & 0 &0\\
    Val& 0 & -1 & 1 & \textbf{1} & -1 & 0 & \textbf{0.5} & 0 & 0 & \textbf{0}\\
    UP & 0.5 & -1 &$\infty$&$\infty$&$\infty$&$\infty$&0.5& 0 & 0 & 0\\\
\end{tabular}
\caption{Configuration \#6}\label{tab:reluplex6}
\end{table}

~\autoref{tab:reluplex6} shows the new configuration.
At this point, Reluplex no longer has any out-of-bound or inconsinstent values, and thus stops and returns \sat{} with the values in the \textbf{Val} row in ~\autoref{tab:reluplex6} as the satisfying assignment for the formula in Eq~\ref{eq:negprop1}.

Thus, in this example, we conclude that property in~\autoref{eq:prop1} is \emph{not valid} for the DNN in~\autoref{fig:reluplex} because for the inputs $i_0=0,v_{-12}=-1$, the DNN gives the output $n_{10}=0.5$, which violates the property in~\autoref{eq:prop1}.
\end{example}

\section{Excercises}
\begin{problem}
Consider the DNN in~\autoref{fig:reluplex} and the property in~\autoref{eq:prop1}.  Use \reluplex{} to verify the property.  If you find a counterexample, provide it.  You will need to provide all the steps in the \reluplex{} algorithm, e.g., DNN encoding, basic variable encoding, and the \reluplex{} search through a series of configurations as shown in~\autoref{ex:reluplex}.

\end{problem}


\chapter{GPU and Multicore Parallelism}


\part{Survey of DNN Verification Tools}

\chapter{Popular Techniques and Tools}




\part{Advanced Topics\label{part:advanced-topics}}





\chapter{DNN Verification Benchmarks}\label{chap:benchmarks}
Here we survey the latest benchmarks in DNN verification and how SOTA tools perform on them.  These results are taken from the Verification Neural Network Competitions (VNN-COMP)~\cite{brix2024fifth} and the recent work by Duong et al.~\cite{duong2024harnessing}.




\section{VNN-COMP Benchmarks}

%Artifacts for all benchmarks are available in the repository\footnote{\url{https://github.com/ChristopherBrix/vnncomp2024_benchmarks/tree/main/benchmarks}}.

\tvn{check this table with VNN-COMP'24 reports. The Report seems to have a lot more benchmarks for regular tracks. Also many numbers don't quite match. We should probably use the benchmarks from VNN-COMP'24 report. I also ? on place for you to fill in}

\begin{table}
    \caption{Benchmark instances. U: \texttt{unsat}, S: \texttt{sat}, ?: \texttt{unknown}.}\label{tab:benchmarks}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{c|ccccc|cc}
        \toprule
        \multirow{2}{*}{\textbf{Benchmarks}} &\multicolumn{2}{c}{\textbf{Networks}} &  \multicolumn{3}{c|}{\textbf{Per Network}} &\multicolumn{2}{c}{\textbf{Tasks}} \\
        & Type & Networks & Neurons & Parameters & Input Dim & Properties & Instances (U/S/?) \\
        \midrule
      cGan &  Conv. + Vision Trans. & & & 500K--68M & 5 &  &  \\
      NN4Sys & ReLU + Sigmoid       & & & 33k--37M & 1--308 & & \\
      LinearizeNN & FC. + Conv. + & && 203k & 4 && \\
      &Vision Trans. + Res. + ReLU &&&&&&\\
      \midrule
      Collins RUL CNN & Conv. + ReLU, Dropout  &&& 60k--262k  & 400--800 &&\\
      cifar100 &FC + Conv. + Res., & &&2.5M--3.8M & 3072 & &\\
                                             &ReLU + BatchNorm &&&&&&\\
      tinyimagenet &FC + Conv. + Res., &&& 3.6M & 9408 & &\\
      & ReLU + BatchNorm &&&&&&\\
      Metaroom & Conv. + FC, ReLU &&& 466k--7.4M & 5376 & &\\

      \midrule

      TLL Verify Bench & Two-Level Lattice NN (FC. + ReLU)  &&& 17k--67M & 2 &&\\
      Acas XU & FC. + ReLU &45&300& 13k & 5 &10&139/47/0\\
      %ACAS Xu & FNN & 45 & 300 & 13305 & 5 & 10 & 139/47/0 \\
      Dist Shift & FC. + ReLU + Sigmoid &&& 342k -- 855k & 792 &&\\
      safeNLP & FC. + ReLU &&& 4k & 30 &&\\
      CORA & FC. + ReLU &&& 575k, 1.1M & 784, 3072 &&\\


        % MNISTFC & FNN & 3 &  0.5--1.5K & 269--532K & & 30 & 56/23/11\\

        % %CIFAR2020 & FNN+CNN & 3 &  17--62K & 2.1--2.5M && 203 & 149/43/11 \\
        % \midrule

        % RESNET\_A/B & CNN+ResNet & 2 & 11K & 354K & & 144 & 49/23/72 \\
        % \midrule

        % CIFAR\_GDVB & FNN+CNN & 42 & 9--49K & 0.08--58M && 39 & 60/0/0 \\
        % \midrule
        % \midrule
        % VGGNet16 & CNN + ReLU + MaxPool& ? & ? & 138M & 150K & ? & ? \\
        \bottomrule
        \end{tabular}
    }
\end{table}



\subsection{ACAS Xu}\label{sec:acasxu}
\paragraph{Networks} The ACASXu benchmark consists of 10 properties defined over 45 neural networks used to issue turn advisories to aircraft to avoid collisions. The neural networks have 300 neurons arranged in 6 layers, with ReLU activation functions. There are 5 inputs corresponding to the aircraft states, and 5 network outputs, where the minimum output is used as the turn advisory the system ultimately produces.

\paragraph{Specifications} VNN-COMP uses the original 10 properties~\cite{katz2017reluplex}, where properties 1--4 are checked on all 45 networks as was done in later work by the original authors~\cite{katz2019marabou}. Properties 5--10 are checked on a single network. The total number of benchmarks is therefore 186.\tvn{does not match table}


\subsection{Cifar2020}

\paragraph*{Motivation} This benchmark combines two convolutional CIFAR10 networks from last year's VNN-COMP 2020 with a new, larger network with the goal to evaluate the progress made by the whole field of Neural Network verification.

\paragraph*{Networks} The two ReLU networks \texttt{cifar\_10\_2\_255} and \texttt{cifar\_10\_8\_255} with two convolutional and two fully-connected layers were trained for $\ell_\infty$ perturbations of $\epsilon = \frac{2}{255}$ and $\frac{8}{255}$, respectively, using COLT \cite{balunovic:20}  and the larger \texttt{ConvBig} with four convolutional and three fully-connected networks, was trained using adversarial training \cite{madry:17} and $\epsilon = \frac{2}{255}$.

\paragraph*{Specifications} We draw the first 100 images from the CIFAR10 test set and for every network reject incorrectly classified ones. For the remaining images, the specifications describe a correct classification under an $\ell_\infty$-norm perturbation of at most $\frac{2}{255}$ and $\frac{8}{255}$ for \texttt{cifar\_10\_2\_255} and \texttt{ConvBig} and \texttt{cifar\_10\_8\_255}, respectively and allow a per sample timeout of 5 minutes.


\subsection{VGGNET16}
\paragraph*{Proposed by} Stanley Bak, Stony Brook University

\paragraph*{Motivation} This benchmark tries to scale up the size of networks being analyzed by using the well-studied VGGNET-16 architecture~\cite{simonyan2014very} that runs on ImageNet. Input-output properties are proposed on pixel-level perturbations that can lead to image misclassification. 

\paragraph*{Networks} All properties are run on the same network, which includes 138 million parameters. The network features convolution layers, ReLU activation functions, as well as max pooling layers.

\paragraph*{Specifications} Properties analyzed ranged from single-pixel perturbations to perturbations on all 150528 pixles (L-infinity perturbations). A subset of the images was used to create the specifications, one from each category, which was randomly chosen to attack. Pixels to perturb were also randomly selected according to a random seed.

\paragraph*{Link} \url{https://github.com/stanleybak/vggnet16_benchmark2022/}





% \begin{table}[h]
%     \centering
%     \caption{Overview of all scored benchmarks.}\label{tab:my_label}
%     \resizebox{\textwidth}{!}{
%     \renewcommand{\arraystretch}{1.4}
%     \begin{tabular}{ccccccc}
%     \toprule
%     Category &
%     Benchmark &
%     Application &
%     Network Types &
%     \# Params &
%     Effective Input Dim &
%     Track
%     \\
%     \midrule
%     \multirow{8}{*}{Complex}
%     %& Carvana UNet  & Image Segmentation & Complex UNet              & 275k - 373k & 4.3k \\
%     & cGAN & \makecell{Image Generation \\ \& Image Prediction} & Conv. + Vision Transformer & 500k - 68M & 5 & regular \\
%     & NN4Sys & \makecell{Dataset Indexing \\ \&  Cardinality Prediction}   & ReLU + Sigmoid & 33k - 37M & 1-308 & regular \\
%     %& ml4acopf & Power System & Complex (ReLU + Trigonometric + Sigmoid) & 4k-680k & 22 - 402 & extended \\
%     %& ViT & Vision & Conv. + Residual + Softmax + BatchNorm & 68k - 76k & 3072 & extended \\
%     %& Collins Aerospace & - & FC + Conv. + Residual, LeakyReLU + MaxPool + Square & 1.8M & 1.2M & extended \\
%     %& LSNC & Lyapunov stability of NN controllers & FC + Residual, ReLU + Sin + Cos & 210, 406 & 8 & extended \\
%     %& CCTSDB & - & FC + Conv. + Residual, ReLU +  MaxPool + Clip & 100k & 2 & extended \\
%     %\cmidrule(lr){1-7}
%     %\multirow{7}{*}{\makecell{CNN \\ \& ResNet}}
%     % & Cifar Bias Field      & Image Classification & Conv. + ReLU  & 45k   & 16 \\

%     % & Large ResNets         & Image Classification & ResNet (Conv. + ReLU)  & 55k - 286k   & 3.1k - 12k \\
%     % & Oval21 & Image Classification & Conv. + ReLU  & 3.1k - 6.2k   & 3.1k \\
%     % & SRI ResNet A/B & Image Classification  & ResNet (Conv. + ReLU)  & 11k   & 3.1k \\
%     %& VGGNet16 & Image Classification & Conv. + ReLU + MaxPool    & 138M & 150k & extended \\
%     & Traffic Signs Recognition & Image Classification & Conv. + Sign + MakPool + BatchNorm & 905k - 1.7M & 2.7k - 12k & extended \\

%     % & Yolo & - & FC + Conv. + Residual, ReLU + Sigmoid & 22k - 37M & 1 - 308 & extended \\
%     % %
%     % \cmidrule(lr){1-7} %
%     % \multirow{5.5}{*}{\makecell{FC}}
%     % %& MNIST FC & Image Classification & FC. + ReLU    & 512 - 1.5k & 784 \\
%     % %& Reach Prob Density    & Probability density estimation & FC. + ReLU    & 64 - 192 & 3 - 14 \\
%     % %& RL Benchmarks  & Reinforcement Learning & FC. + ReLU    & 128 - 512  & 4 - 8 \\
%     \bottomrule
%     \end{tabular}
%     }
% \end{table}


\subsection{cGAN}
\paragraph*{Proposed by} Feiyang Cai, Ali Arjomandbigdeli, Stanley Bak (Stony Brook Univ.). Link: \url{https://github.com/feiyang-cai/cgan_benchmark2023}

This benchmark targets robustness verification for generative modelsâ€”an area often overlooked compared to discriminative networks.
It uses conditional GANs trained to generate images of vehicles at specific distances. The generator takes a 1D distance input and a 4D noise vector; the discriminator outputs a real/fake score and a predicted distance.
Models vary in architecture (CNNs, vision transformers) and image size (32Ã—32, 64Ã—64).
The verification task checks whether the predicted distance from the generated image matches the input condition, under small input perturbations.


\paragraph*{Motivation}
While existing neural network verification benchmarks focus on discriminative models, the exploration of practical and widely used generative networks remains neglected in terms of robustness assessment.
This benchmark introduces a set of image generation networks specifically designed for verifying the robustness of the generative networks.
\paragraph*{Networks}
The generative networks are trained using conditional generative adversarial networks (cGAN), whose objective is to generate camera images that contain a vehicle obstacle located at a specific distance in front of the ego vehicle, where the distance is controlled by the input distance condition.
The network to be verified is the concatenation of a generator and a discriminator.  The generator takes two inputs: 1) a distance condition (1D scalar) and 2) a noise vector controlling the environment (4D vector). The output of the generator is the generated image. The discriminator takes the generated image as input and outputs two values: 1) a real/fake score (1D scalar) and 2) a predicted distance (1D scalar).
Several different models with varying architectures (CNN and vision transformer) and image sizes (32x32, 64x64) are provided for different difficulty levels.
\paragraph*{Specifications}
The verification task is to check whether the generated image aligns with the input distance condition, or in other words, verify whether the input distance condition matches the predicted distance of the generated image.
In each specification, the inputs (condition distance and latent variables) are constrained in small ranges, and the output is the predicted distance with the same center as the condition distance but with slightly larger range.

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \pagebreak
% \subsection{NN4Sys}
% \paragraph*{Proposed by} the $\alpha,\!\beta$-CROWN team with collaborations with Cheng Tan, Haoyu He and Shuyi Lin at Northeastern University.
% \paragraph*{Application}
% The benchmark contains networks for database learned index, video streaming learned adaptive bitrate, and learned cardinality
% estimation which map inputs from various dimensions to 1-dimension outputs.

% \begin{itemize}

% \item \textit{Background}: learned index, learned cardinality, and learned
%     adaptive bitrate are all instances in neural networks for computer systems
%         (NN4Sys), which are neural network based methods performing system
%         operations. These classes of methods show great potential but have one
%         drawback---the outputs of an NN4Sys model (a neural network) can be
%         arbitrary, which may lead to unexpected issues in systems.

% \item \textit{What to verify}: our benchmark provides multiple pairs of (1) trained NN4Sys model
% and (2) corresponding specifications. We design these pairs with different parameters such
% that they cover a variety of user needs and have varied difficulties for verifiers. 
% We describe benchmark details in our NN4SysBench report:
%         \url{http://naizhengtan.github.io/doc/papers/nn4sys23lin.pdf}.

% \item \textit{Translating NN4Sys applications to a VNN benchmark}: 
% the original NN4Sys applications have some sophisticated structures that are hard to verify.
% We tailored the neural networks and their specifications to be suitable for VNN-COMP.
% For example, learned index~\cite{kraska18case} contains multiple NNs in a tree structure that together serve one purpose.
% However, this cascading structure is inconvenient/unsupported to verify
% because there is a ``switch" operation---choosing one NN in the second stage
% based on the prediction of the first stage's NN.
% To convert learned indexes to a standard form, we train a monolithic (larger) NN.

% \item \textit{A note on broader impact}: using NNs for systems is a broad topic, but many existing works
% lack strict safety guarantees. We believe that NN Verification can help system developers gain confidence
% to apply NNs to critical systems. We hope our benchmark can be an early step toward this vision.

% \end{itemize}

% \paragraph*{Networks}
% This benchmark has twelve networks with different parameters: two for learned
% indexes, four for learned cardinality estimation and six for learned adaptive bitrate.
% The learned index uses fully-connected feed-forward neural networks. The other
% two---the learned cardinality and the learned adaptive bitrate---has a
% relatively sophisticated internal structure. Please see our NN4SysBench report
% (URL listed above) for details


% \paragraph*{Specifications}
% For learned indexes,
% the specification aims to check if the prediction error is bounded.
% The specification is a collection of pairs of input and output intervals such that
% any input in the input interval should be mapped to the corresponding output interval.
% For learned cardinality estimation and learned adaptive bitrate,
% the specifications check the prediction error bounds (similar to the learned indexes)
% and monotonicity of the networks.
% By monotonicity specifications, we mean that for two inputs, the network should produce a larger
% output for the larger input, which is required by cardinality estimation or adaptive bitrate.


% \paragraph{Link:} \url{https://github.com/Khoury-srg/VNNComp23_NN4Sys}



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%% sec: LinearizeNN %%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{LinearizeNN}
% \paragraph*{Proposed by}  Ali Arjomandbigdeli, Stanley Bak (Stony Brook University).
% \paragraph*{Motivation}
% Assuming having a neural network controller approximation with a piecewise linear model in the form of a set of linear models with added noise to account for local linearization error. The objective of this benchmark is to investigate the neural network output falls within the range we obtain from our linear model output plus some uncertainty.

% The idea of this benchmark came from one of our recent paper~\cite{ArjomandBigdeli2024} in which we approximated the NN controller with a piecewise linear model, and we wanted to check if the neural network output falls within the range we obtained from our linear model output plus some uncertainty.
% \paragraph*{Networks} The neural network controller we used in this benchmark is an image-based controller for an Autonomous Aircraft Taxiing System whose goal is to control an aircraft's taxiing at a steady speed on a taxiway. This network was introduced  in the paper "Verification of Image-based Neural Network Controllers Using Generative Models"~\cite{katz2021veri}. The neural network integrates a concatenation of the cGAN (conditional GAN) and controller, resulting in a unified neural network controller with low-dimensional state inputs. In this problem, the inputs to the neural network consist of two state variables and two latent variables. The aircraft's state is determined by its crosstrack position (p) and heading angle error ($\theta$) with respect to the taxiway center line. Two latent variables with a range of -0.8 to 0.8 are introduced to account for environmental changes.

% Because in this case the output spec depends on both the input and output and considering the VNN-LIB limitation, we added a skip-connection layer to the neural network to have the input values present in the output space. We also added one linear layer after that to create a linear equation for each local model.
% \paragraph*{Specifications} As mentioned earlier, the aim of this benchmark is to examine whether the neural network output stays within the range defined by the linear model's output, including a margin for uncertainty.Given input $x \in X$ and output $Y = f_{NN}(x)$, the query is of the form: $A_{mat}\times X + b + U_{lb} \leq Y \leq A_{mat}\times X + b + U_{ub}$ for each linear model in its abstraction region.
% \paragraph*{Link} \url{https://github.com/aliabigdeli/LinearizeNN_benchmark2024}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
% \pagebreak
% % \subsection{Cifar Bias Field}

% % \paragraph{Proposed by} The VeriNet team.

% % \paragraph*{Motivation} This benchmark considers verification of a Cifar 10 network against bias field perturbations. The bias field perturbations are encoded by creating augmented networks with only 16 input parameters; thus, the problem has a significantly lower input dimensionality than many other image-based benchmarks.

% % \paragraph*{Networks} For each image to be verified, a separate bias field transform network is created~\cite{Henriksen+21} which consists of the FC transform layer followed by the Cifar CNN. The Cifar CNN consists of 8 convolutional layers followed by ReLUs. Each bias field transform network has 363k parameters and 45k nodes.  

% % \paragraph*{Specifications} The specification considers bias field perturbations of the input. The task is reduced to a standard $\ell_\infty$ specification by encoding bias field the bias field transformation into fully connected layers which are prepended to the network under consideration. The bias field perturbations used $\epsilon = 0.06$ (as described in~\cite{Henriksen+21}) and a timeout of 5 minutes. 


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%% sec: ml4acopf %%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{ml4acopf}
% \paragraph*{Proposed by} Haoruo Zhao, Michael Klamkin, Mathieu Tanneau, Wenbo Chen, and Pascal Van Hentenryck (Georgia Institute of Technology), and Hassan Hijazi, Juston Moore, and Haydn Jones (Los Alamos National Laboratory).

% \paragraph*{Motivation}
% Machine learning models are utilized to predict solutions for an optimization model known as AC Optimal Power Flow (ACOPF) in the power system. Since the solutions are continuous, a regression model is employed. The objective is to evaluate the quality of these machine learning model predictions, specifically by determining whether they satisfy the constraints of the optimization model. Given the challenges in meeting some constraints, the goal is to verify whether the worst-case violations of these constraints are within an acceptable tolerance level.

% \paragraph*{Networks}
% The neural network designed comprises two components. The first component predicts the solutions of the optimization model, while the second evaluates the violation of each constraint that needs checking. The first component consists solely of general matrix multiplication (GEMM) and rectified linear unit (ReLU) operators. However, the second component has a more complex structure, as it involves evaluating the violation of AC constraints using nonlinear functions, including sigmoid, quadratic, and trigonometric functions such as sine and cosine. This complex evaluation component is incorporated into the network due to a limitation of the VNNLIB format, which does not support trigonometric functions. Therefore, these constraints violation evaluation are included in the neural network.

% \paragraph*{Specifications}
% In this benchmark, four different properties are checked, each corresponding to a type of constraint violation:
% \begin{enumerate}
%     \item Power balance constraints: the net power at each bus node is equal to the sum of the power flows in the branches connected to that node.
%     \item Thermal limit constraints: power flow on a transmission line is within its maximum and minimum limits.
%     \item Generation bounds: a generator's active and reactive power output is within its maximum and minimum limits.
%     \item Voltage magnitude bounds: a voltage's magnitude output is within its maximum and minimum limits.
% \end{enumerate}

% The input to the model is the active and reactive load. The chosen input point for perturbation is a load profile for which a corresponding feasible solution to the ACOPF problem is known to exist. For the feasibility check, the input load undergoes perturbation. Although this perturbation does not exactly match physical laws, the objective is to ascertain whether a machine learning-predicted solution with the perturbation can produce a solution that does not significantly violate the constraints.

% The scale of the perturbation and the violation threshold are altered by testing whether an adversarial example can be easily found using projected gradient descent with the given perturbation. The benchmark, provided with a fixed random seed, is robust against the simple projected gradient descent that is implemented.

% \paragraph*{Link} \url{https://github.com/AI4OPT/ml4acopf_benchmark}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%% sec: ViT %%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{ViT}
% \paragraph*{Proposed by} the $\alpha,\!\beta$-CROWN team.
% \paragraph*{Motivation}
% Transformers~\cite{vaswani2017attention} based on the self-attention mechanism have much more complicated architectures and contain more kinds of nonlinerities, compared to simple feedforward networks with relatively simple activation functions. 
% It makes verifying Transformers challenging. We aim to encourage the development of verification techniques for Transformer-based models, and we also aim to benchmark neural network verifiers on relatively complicated neural network architectures and more general nonlinearities. Therefore, we propose a new benchmark with Vision Transformers (ViTs)~\cite{dosovitskiy2020image}. This benchmark is developed based on our work on neural network verification for models with general nonlinearities~\cite{shi2024genbab}.

% \paragraph*{Networks}
% The benchmark contains two ViTs, as shown in \Cref{tab:vits}.
% Considering the difficulty of verifying ViTs, we modify the ViTs and make the models relatively shallow and narrow, with significantly reduced number of layers and attention heads.
% Following \cite{shi2019robustness}, we also replace the layer normalization with batch normalization.
% The models are mainly trained with PGD training~\cite{madry2017towards}, and we also add a weighted IBP~\cite{gowal2018effectiveness,shi2021fast} loss for one of the models as a regularization.

% \begin{table}[ht]
% \centering
% \caption{Networks in the ViT benchmark.}
% \label{tab:vits}
% \begin{tabular}{ccc}
% \toprule 
% Model & \texttt{PGD\_2\_3\_16} & \texttt{IBP\_3\_3\_8} \\
% \midrule
% Layers & 2 & 3\\
% Attention heads & 3 & 3\\
% Patch size & 16 & 8\\
% Weight of IBP loss & 0 & 0.01\\
% Training $\epsilon$ & $\frac{2}{255}$ & $\frac{1}{255}$\\
% Clean accuracy & 59.78\% & 62.21\%\\
% \bottomrule
% \end{tabular}
% \end{table}

% \paragraph*{Specifications} 
% The specifications are generated from the robustness verification problem with $\ell_\infty$ perturbation. 
% We use the CIFAR-10 dataset with perturbation size $\epsilon=\frac{1}{255}$ at test time.
% We have filtered the CIFAR-10 test set to exclude instances where either adversarial examples can be found (by PGD attack~\cite{madry2017towards} with 100 steps and 1000 restarts) or the vanilla CROWN-like method~\cite{zhang2018efficient,shi2019robustness} can already easily verify. 
% We randomly keep 100 instances for each model, with a timeout threshold of 100 seconds. 
% Note that since instances with adversarial examples have mostly been excluded during the filtering process, this version of the benchmark may not be able to reflect soundness issues in verifiers, and we refer readers to \cite{zhou2024testing} for discussions on testing soundness with models including ViT.

% \paragraph*{Link} \url{https://github.com/shizhouxing/ViT_vnncomp2023}


% \subsection{LSNC}

% \paragraph*{Proposed by} the $\alpha,\!\beta$-CROWN team.
% \paragraph*{Motivation}
% We develop a benchmark for the problem of verifying the Lyapunov stability of NN controllers in nonlinear dynamical systems within a region-of-intrest and a region-of-attraction. This is important for providing stability guarantees that are essential for safety-critical applications with NN controllers. It is also a useful application of neural network verification as recently demonstrated in \cite{yang2024lyapunov,shi2024certified}, and we refer readers to those works for more details on the problem.
% \paragraph*{Networks and Specifications}
% Models are adopted from \cite{yang2024lyapunov}. 
% We adopt two models for the 2D quadrotor dynamical system with state feedback and output feedback, respectively. Each model consists of a controller which is a shallow ReLU network, a Lyapunov function which is a quadratic function, and nonlinear operators modelling the dynamics of a 2D quadrotor. The model for output feedback further consists of a shallow LeakyReLU network as the observer. The verification objective of the Lyapunov stability has been encoded in the ONNX graphs and VNNLIB specifications. Specifications for the benchmark are randomly generated and consist of random sub-regions within the original region-of-interest. The size of the random sub-regions is controlled by a factor $\epsilon~(0<\epsilon\leq 1)$ which is applied to each input dimension, and it has been adjusted for a suitable difficulty given the timeout. For the state feedback model, we set $\epsilon=0.5$ and the timeout is 100s; for the output feedback model, we set $\epsilon=0.3$ and timeout is 200s. For each of the two models, we randomly generate 20 instances. 
% \paragraph*{Link} \url{https://github.com/shizhouxing/LSNC_VNNCOMP2024}

% \subsection{Collins-RUL-CNN}
% \paragraph*{Proposed by} Collins Aerospace, Applied Research \& Technology (\href{https://www.collinsaerospace.com/what-we-do/capabilities/technology-and-innovation/applied-research-and-technology}{website}).

% \paragraph*{Motivation} Machine Learning (ML) is a disruptive technology for the aviation industry. This particularly concerns safety-critical aircraft functions, where high-assurance design and verification methods have to be used in order to obtain approval from certification authorities for the new ML-based products. Assessment of correctness and robustness of trained models, such as neural networks, is a crucial step for demonstrating the absence of unintended functionalities~\cite{ForMuLA, kirov2023formal}. The key motivation for providing this benchmark is to strengthen the interaction between the VNN community and the aerospace industry by providing a realistic use case for neural networks in future avionics systems~\cite{kirov2023benchmark}.

% \paragraph*{Application} Remaining Useful Life (RUL) is a widely used metric in Prognostics and Health Management (PHM) that manifests the remaining lifetime of a component (e.g., mechanical bearing, hydraulic pump, aircraft engine). RUL is used for Condition-Based Maintenance (CBM) to support aircraft maintenance and flight preparation. It contributes to such tasks as augmented manual inspection of components and scheduling of maintenance cycles for components, such as repair or replacement, thus moving from preventive maintenance to \emph{predictive} maintenance (do maintenance only when needed, based on componentâ€™s current condition and estimated future condition). This could allow to eliminate or extend service operations and inspection periods, optimize component servicing (e.g., lubricant replacement), generate inspection and maintenance schedules, and obtain significant cost savings. Finally, RUL function can also be used in airborne (in-flight) applications to dynamically inform pilots on the health state of aircraft components during flight. Multivariate time series data is often used as RUL function input, for example, measurements from a set of sensors monitoring the component state, taken at several subsequent time steps (within a time window). Additional inputs may include information about the current flight phase, mission, and environment. Such highly multi-dimensional input space motivates the use of Deep Learning (DL) solutions with their capabilities of performing automatic feature extraction from raw data.

% \paragraph*{Networks} The benchmark includes 3 convolutional neural networks (CNNs) of different complexity: different numbers of filters and different sizes of the input space. All networks contain only convolutional and fully connected layers with ReLU activations. All CNNs perform the regression function. They have been trained on the same dataset (time series data for mechanical component degradation during flight).

% \paragraph*{Specifications} We propose 3 properties for the NN-based RUL estimation function. First, two properties (robustness and monotonicity) are local, i.e., defined around a given point. We provide a script with an adjustable random seed that can generate these properties around input points randomly picked from a test dataset. For robustness properties, the input perturbation (delta) is varied between 5\% and 40\%, while the number of perturbed inputs varies between 2 and 16. For monotonicity properties, monotonic shifts between 5\% and 20\% from a given point are considered. Properties of the last type ("if-then") require the output (RUL) to be in an expected value range given certain input ranges. Several if-then properties of different complexity are provided (depending on range widths).

% \paragraph*{Link} \url{https://github.com/loonwerks/vnncomp2022}

% \paragraph*{Paper} Available in~\cite{kirov2023benchmark} or on request.




% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%% sec: Traffic Signs Recognition %%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Traffic Signs Recognition}
% \paragraph*{Proposed by} M\u{a}d\u{a}lina Era\c{s}cu and Andreea Postovan (West University of Timisoara, Romania)
% \paragraph*{Motivation} Traffic signs play a crucial role in ensuring road safety and managing traffic flow in both city and highway driving. The recognition of these signs, a vital component of autonomous driving vision systems, faces challenges such as susceptibility to adversarial examples~\cite{szegedy2013intriguing} and occlusions~\cite{zhang2020lightweight}, stemming from diverse traffic scene conditions.

% \paragraph*{Networks} Binary neural networks (BNNs) show promise in computationally limited and energy-constrained environments within the realm of autonomous driving~\cite{hubara2016binarized}. BNNs, where weights and/or activations are binarized to $\pm 1$, offer reduced model size and simplified convolution operations for image recognition compared to traditional neural networks (NNs).

% We trained and tested various BNN architectures using the German Traffic Sign Recognition Benchmark (GTSRB) dataset~\cite{GTSRB}. This multi-class dataset, containing images of German road signs across 43 classes, poses challenges for both humans and models due to factors like perspective change, shade, color degradation, and lighting conditions. The dataset was also tested using the Belgian Traffic Signs \cite{BelgianTrafficSignDatabase} and Chinese Traffic Signs \cite{ChineseTrafficSignDatabase} datasets. The Belgium Traffic Signs dataset, with 62 classes, had 23 overlapping classes with GTSRB. The Chinese Traffic Signs dataset, with 58 classes, shared 15 classes with GTSRB. Pre-processing steps involved relabeling classes in the Belgium and Chinese datasets to match those in GTSRB and eliminating non-overlapping classes (see \cite{postovan2023architecturing} for details).

% We provide three models with the structure in Figures \ref{fig:Acc-Efficient-Arch-GTSRB-Belgium}, \ref{fig:Acc-Efficient-Arch-Chinese}, and \ref{fig:XNOR(QConv)-arch}. They contain QConv, Batch Normalization (BN), Max Pooling (ML), Fully Connected/Dense (D) layers.  Note that the QConv layer binarizes the corresponding convolutional layer. All models were trained for 30 epochs. The model from Figure \ref{fig:Acc-Efficient-Arch-GTSRB-Belgium} was trained with images having the dimension 64px x 64 px, the one from Figure \ref{fig:Acc-Efficient-Arch-Chinese} with 48px x 48 px and the one from Figure \ref{fig:XNOR(QConv)-arch} with 30px x 30 px. The two models involving Batch Normalization layers introduce real valued parameters besides the binary ones, while the third one contains only binary parameters (see Table \ref{tab:stats}) for statistics.

% \begin{figure}[h]
%   \centering
%     \includegraphics[width=0.7\textwidth]{figure/AccEfficientGTSRBBelgium.png}
%     \caption{Accuracy Efficient Architecture for GTSRB and Belgium dataset}
%     \label{fig:Acc-Efficient-Arch-GTSRB-Belgium}
% \end{figure}

% \begin{figure}[h]
%   \centering
%     \includegraphics[width=0.7\textwidth]{figure/AccEfficientArchChinese.png}
%     \caption{Accuracy Efficient Architecture for Chinese dataset}
%     \label{fig:Acc-Efficient-Arch-Chinese}
% \end{figure}

% \begin{figure}[h]
%   \centering
%     \includegraphics[width=0.3\textwidth]{figure/XNORQConv.png}
%     \caption{XNOR(QConv) architecture}
%     \label{fig:XNOR(QConv)-arch}
% \end{figure}

% % Please add the following required packages to your document preamble:
% % \usepackage{multirow}
% \begin{table}[h]
% \caption{Training and Testing Statistics}
% \label{tab:stats}
% \centering
% \scriptsize
% \begin{tabular}{|c|c|ccc|ccc|}
% \hline
% \multirow{2}{*}{\textbf{Input size}} & \multirow{2}{*}{\textbf{Model name}} & \multicolumn{3}{c|}{\textbf{Accuracy}}                                      & \multicolumn{3}{c|}{\textbf{\#Params}}                                      \\ \cline{3-8} 
%                             &                             & \multicolumn{1}{c|}{\textbf{German}} & \multicolumn{1}{c|}{\textbf{China}} & \textbf{Belgium} & \multicolumn{1}{c|}{\textbf{Binary}}  & \multicolumn{1}{c|}{\textbf{Real}} & \textbf{Total}   \\ \hline
% 64px $\times$ 64px          & Figure \ref{fig:Acc-Efficient-Arch-GTSRB-Belgium}                  & \multicolumn{1}{c|}{96.45}  & \multicolumn{1}{c|}{81.50} & 88.17   & \multicolumn{1}{c|}{1772896} & \multicolumn{1}{c|}{2368} & 1775264 \\ \hline
% 48px $\times$ 48px          & Figure \ref{fig:Acc-Efficient-Arch-Chinese}                  & \multicolumn{1}{c|}{95.28}  & \multicolumn{1}{c|}{83.90} & 87.78   & \multicolumn{1}{c|}{904288}  & \multicolumn{1}{c|}{832}  & 905120  \\ \hline
% 30px $\times$ 30px          & Figure \ref{fig:XNOR(QConv)-arch}                  & \multicolumn{1}{c|}{81.54}  & \multicolumn{1}{c|}{N/A}   & N/A     & \multicolumn{1}{c|}{1005584} & \multicolumn{1}{c|}{0}    & 1005584 \\ \hline
% \end{tabular}
% \end{table}
% \paragraph*{Specifications} To evaluate the \emph{adversarial robustness} of the networks above, we assessed perturbations within the infinity norm around zero, with the radius denoted as $\epsilon = \{1, 3, 5, 10, 15\}$. This involved randomly selecting three distinct images from the GTSRB dataset's test set for each model and generating \textsc{VNNLIB} files for each epsilon in the set. In total, we created 45 \textsc{VNNLIB} files. Due to a 6-hour total timeout constraint for solving all instances, each instance had a maximum timeout of 480 seconds. To review the generated \textsc{VNNLIB} specification files submitted to VNNCOMP 2023, as well as to generate new ones, please refer to \url{https://github.com/apostovan21/vnncomp2023}.

% \paragraph*{Link} \url{https://github.com/apostovan21/vnncomp2023}



% \subsection{CIFAR100}

% \paragraph*{Proposed by} the $\alpha,\!\beta$-CROWN team.
% \paragraph*{Motivation} This benchmark is reused from VNN-COMP 2022 with a reduced complexity (only two out of the four models with medium sizes are retained). 
% See details in Section 4.5 of the report of VNN-COMP 2022~\cite{muller2022vnncomp}.

% \paragraph*{Networks} We provide two ResNet models on CIFAR-100 with different model widths and depths (input dimension $32 \times 32 \times 3$, 100 classes):
% \begin{itemize}
%     \item \texttt{CIFAR100-ResNet-medium}: 8 residual blocks, 17 convolutional layers + 2 linear layers
%     \item \texttt{CIFAR100-ResNet-large}: 8 residual blocks, 19 convolutional layers + 2 linear layers (almost identical to standard ResNet-18 architecture)
% \end{itemize}

% \paragraph*{Specifications} 
% We randomly select 100 images from the CIFAR-100 test set with a verification timeout of 100 seconds for each of the two models. 
% We filtered out the samples which can be verified by vanilla CROWN (which is used during training) to make the benchmark more challenging. The filtering process is done offline on a machine with a GPU due to the large sizes of these models. 
% A small proportion of instances (around 18\%) with adversarial examples have been retained for potentially identifying unsound results. 

% \paragraph*{Link} \url{https://github.com/huanzhang12/vnncomp2024_cifar100_benchmark}


% \subsection{TinyImagenet}

% \paragraph*{Proposed by} the $\alpha,\!\beta$-CROWN team.
% \paragraph*{Motivation} This benchmark is reused from VNN-COMP 2022. See details in Section 4.5 of the report of VNN-COMP 2022~\cite{muller2022vnncomp}.

% \paragraph*{Networks} We provide a ResNet for TinyImageNet (input dimension $64 \times 64 \times 3$, 200 classes):
% \begin{itemize}
%     \item \texttt{TinyImageNet-ResNet-medium}: 8 residual blocks, 17 convolutional layers + 2 linear layers
% \end{itemize}

% \paragraph*{Specifications} We randomly select 200 images from the TinyImageNet test set with a verification timeout of 100 seconds for each of the two models. A filtering procedure has been adopted similar to the CIFAR100 benchmark.

% \paragraph*{Link} \url{https://github.com/huanzhang12/vnncomp2024_tinyimagenet_benchmark}



% \subsection{TLL Verify Bench}
% \paragraph*{Proposed by} James Ferlez (University of California, Irvine)

% \paragraph*{Motivation} This benchmark consists of Two-Level Lattice (TLL) NNs, which have been shown to be amenable to fast verification algorithms (e.g. \cite{FerlezKS22}). Thus, this benchmark was proposed as a means of comparing TLL-specific verification algorithms with general-purpose NN verification algorithms (i.e. algorithms that can verify arbitrary deep, fully-connected ReLU NNs).

% \paragraph*{Networks}  The networks in this benchmark are a subset of the ones used in \cite[Experiment 3]{FerlezKS22}. Each of these TLL NNs has $n=2$ inputs and $m=1$ output. The architecture of a TLL NN is further specified by two parameters: $N$, the number of local linear functions, and $M$, the number of selector sets. This benchmark contains TLLs of sizes $N = M = 8, 16, 24, 32, 40, 48, 56, 64$, with $30$ randomly generated examples of each (the generation procedure is described in \cite[Section 6.1.1]{FerlezKS22}). At runtime, the specified verification timeout determines how many of these networks are included in the benchmark so as to achieve an overall 6-hour run time; this selection process is deterministic. Finally, a TLL NN has a natural representation using multiple computation paths \cite[Figure 1]{FerlezKS22}, but many tools are only compatible with fully-connected networks. Hence, the ONNX models in this benchmark implement TLL NNs by ``stacking'' these computation paths to make a fully connected NN (leading to sparse weight matrices: i.e. with many zero weights and biases). The \texttt{TLLnet} class (\url{https://github.com/jferlez/TLLnet}) contains the code necessary to generate these implementations via the \texttt{exportONNX} method.

% %\vfill
% %\pagebreak
% \paragraph*{Specifications}  All specifications have as input constraints the hypercube $[-2,2]^2$. Since all networks have only a single output, the output properties consist of a randomly generated real number and a randomly generated inequality direction. Random output samples from the network are used to roughly ensure that the real number property has an equal likelihood of being within the output range of the NN and being outside of it (either above or below all NN outputs on the input constraint set). The inequality direction is generated independently and with each direction having an equal probability. This scheme biases the benchmark towards verification problems for which counterexamples exist. 

% \paragraph*{Link} \url{https://github.com/jferlez/TLLVerifyBench}
% \paragraph*{Commit}
% 199d2c26d0ec456e62906366b694a875a21ff7ef





% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{safeNLP}

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.9\columnwidth]{./figure/NLP-Flow.png}
%     \caption{\small\emph{Generic approach to generating the NLP verification pipelines~\cite{casadio2023antonio,casadio2024nlp} deployed to obtain the safeNLP benchmark.}}
%    \label{fig:antonio}
% \end{figure}

% \paragraph*{Proposed by} Marco Casadio, Ekaterina Komendantskaya, Luca Arnaboldi, Tanvi Dinkar.

% \paragraph*{Motivation}
% While considerable research has been dedicated to the verification of DNN-based systems in domains such as computer vision, there has been a notable lack of focus on the verification of natural language processing (NLP) systems. This is particularly critical given the rise of conversational agents across various domains, where inaccurate or misleading responses can cause real-world harm. For example, recent EU legislation~\cite{EUlaw} requires chatbots to disclose their non-human nature when queried, and developers of the chatbots should provide firm, and if possible, formal, guarantees that such disclosure will be given in an accurate manner. Medical assistants give another example where formal guarantees about the conversational agent responses are needed in order to safeguard against chatbots  generating harmful medical advice~\cite{bickmore2018patient}. While some initial work has been done in this area of NLP verification~\cite{jia2019certified,huang2019achieving,welbl2020towards,zhang2021certified,wang2023robustness,ko2019popqorn,du2021cert,shi2020robustness,bonaert2021fast}, no agreement on commonly  accepted benchmarks has been reached in this domain. To address this gap, we introduce safeNLP, the first such benchmark. 

% \paragraph*{Application}
% In~\cite{casadio2024nlp}, we have undertaken a large-scale study of the existing literature on  NLP verification, and distilled common patterns among the existing approaches. Usually, given a dataset consisting of sentences divided into classes, Large Language Models (LLMs) are used to embed these sentences into real-vector spaces, after which smaller neural networks are trained to classify the embedded vectors (relative to the originally given classes). For verification, one can generate meaning-preserving sentence perturbations, again embed them into vector spaces, and verify that subspaces that contain the (embeddings of) the perturbed sentences are classified correctly. Also, in line with classical verification pipelines~\cite{CasadioKDKKAR22}, one can use these input subspaces to train the neural network to be robust on them.  The problem was that each of the existing approaches~\cite{jia2019certified,huang2019achieving,welbl2020towards,zhang2021certified,wang2023robustness,ko2019popqorn,du2021cert,shi2020robustness,bonaert2021fast} used parts of this pipeline in different ways, which made it difficult to compare or audit the results. In~\cite{casadio2023antonio,casadio2024nlp}, we made a generic implementation of this pipeline, 
% %(released as a Python package ANTONIO), 
% where each of the components of the pipeline is implemented in a modular and transparent way. For example, we can choose  and vary embedding functions, training modes, algorithms for sentence perturbations and algorithms for robust training, independently and modularly; as shown in Figure~\ref{fig:antonio}. This implementation was used to generate the presented VNNCOMP benchmark.

% \begin{itemize}
%     \item \emph{Datasets:} Although there was no clear consensus in~\cite{jia2019certified,huang2019achieving,welbl2020towards,zhang2021certified,wang2023robustness,ko2019popqorn,du2021cert,shi2020robustness,bonaert2021fast}, the most frequently used dataset in prior works was the IMDB dataset containing film reviews. Its disadvantage is unclear relation to safety critical domains that usually motivate verification efforts. On the other hand, none of the previously used datasets concerned safety-critical applications of NLP. We decided to address this problem, and therefore applied our generic NLP verification pipeline on two safety-critical datasets:  R-U-A-Robot~\cite{gros2021ruarobot}, which focuses on the chatbot disclosure problem, and Medical~\cite{abercrombie2022risk}, which addresses the issue of harmful advice provided by medical chatbots. Both datasets are pre-processed into two classes, positive and negative, to simplify the verification task. For further details on the pre-processing steps and datasets, see~\cite{casadio2024nlp} and the \href{https://github.com/ANTONIONLP/safeNLP}{benchmark GitHub repository}.
%     \item \emph{Input Space:} In both datasets, sentences are transformed into fixed-size vector representations, i.e. embeddings, which serve as the inputs to the neural networks. For this VNNCOMP benchmark, we used Sentence-BERT~\cite{reimers-gurevych-2019-sentence}. 
%     %This part is handled by ANTONIO, which employs .
%     \item \emph{What to Verify:} For each dataset, we generated meaning-preseving sentence perturbations at character and word level as in Moradi et al.~\cite{moradi2021evaluating} and at sentence level with Vicuna~\cite{vicuna2023}. For each positive sentence in the dataset, the smallest hypercube containing the embeddings of all of its obtained perturbations formed one input subspace for verification. Such subspaces were obtained for all positive sentences from the given data set, and were subject to VNCCOMP verification challenge. 
%     %ANTONIOâ€™s modular approach allows us to independently chose both the perturbation algorithms and the subspaces form.
%     %The goal is to verify that every point within these subspaces is classified as positive by the network.
%     \item \emph{A note on broader impact:} Verified models can serve as filters for larger NLP systems: e.g. to screen inputs to ensure they meet safety criteria before being passed on to more complex models.
% \end{itemize}

% \paragraph*{Networks} The safeNLP benchmark includes two neural networks, each corresponding to a different dataset (R-U-A-Robot and Medical). Both networks share the same architecture, consisting of two fully-connected layers. The hidden layer has 128 units with a ReLU activation function, while the output layer has 2 units representing the two classification classes (positive/negative). To enhance the robustness of the networks to the specified safety requirements, they are trained using a custom PGD (Projected Gradient Descent)~\cite{madry2018towards} adversarial training technique. In particular, the PGD attack explores the above-mentioned subspaces of the input space (cf. also Figure~\ref{fig:antonio}). 
% %ANTONIO plays a crucial role in this process, allowing us to
% %flexibly select the training mode and robustness algorithm. Specifically, we 
% %customise the PGD algorithm to work effectively with the subspaces used in our specifications.

% \paragraph*{Specifications} The benchmark uses hyper-rectangles in the 30-dimensional embedding space as the subspaces of choice, offering a computationally efficient way to define more precise and adaptable regions compared to the traditional $\epsilon$-cubes. 
% %These hyper-rectangles are defined by a series of lower and upper bounds. 
% The specifications require verifying that, for a given network and hyper-rectangle, every point within the hyper-rectangle is classified as the positive class by the network. To meet time constraints, we randomly select 1,080 such specifications, each linked to one of the two networks and a corresponding hyper-rectangle, with a timeout of 20 seconds per specification.

% \paragraph*{Link} \url{https://github.com/ANTONIONLP/safeNLP}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%% sec: dist_shift %%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Real-world distribution shifts}
% \paragraph*{Proposed by} the Marabou team.
% \paragraph*{Motivation}
% While robustness against handcrafted perturbations (e.g., norm-bounded) for perception networks are more commonly investigated, robustness against real-world distribution shifts~\cite{wu2022toward} are less studied but of practical interests. This benchmark set contains queries for verifying the latter type of robustness.  
% \paragraph*{Networks} The network is a concatenation of a generative model and a MNIST classifier. The generative model is trained to take in an unperturbed image and an embedding of a particular type of distribution shifts in latent space, and produce a perturbed image. The distribution shift captured in this case is the "shear" perturbation. 
% \paragraph*{Specifications} The verification task is to certify that a classifier correctly classifies all images in a perturbation set, which is a set of images generated by the generative model given a fixed image and a ball centering the mean perturbations on this image (in the latent space). This mean perturbation is computed by a prior network.
% \paragraph*{Link} \url{https://github.com/wu-haoze/dist-shift-vnn-comp}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%% sec: cora %%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{CORA Benchmark}
% \paragraph*{Proposed by} the CORA team.
% \paragraph*{Motivation}
% The verification of neural networks can be quite slow, i.e., the verification of a single instance can take multiple days -- which is often hard to justify, particularly in safety-critical scenarios. To encourage the fast verification of neural networks, our benchmark focuses on the verification time by setting a small timeout and testing three different (adversarial) training techniques that aim to ease the verifiability.


% \paragraph*{Networks} The benchmark consists of one ReLU-neural network architecture (7x250 + ReLU), which was trained on three datasets, (MNIST, SVHN, and CIFAR10), using three different (adversarial) training methods, i.e., standard (point), interval-bound propagation, and set-based. Both interval-bound propagation and set-based training are training methods that improve the robustness of the trained neural network and aim to ease later verification. The neural networks are taken from the first evaluation run of~\cite{koller_et_al_2024}; please refer to~\cite{koller_et_al_2024} for the training details.
% \paragraph*{Specifications} All networks are trained on classification tasks. The goal is to verify that no image within a given input set is incorrectly classified.
% \paragraph*{Link} \url{https://github.com/kollerlukas/cora-vnncomp2024-benchmark}

% \section{Results}


% \paragraph{Results}~\autoref{tab:score} shows the results. We report the Rank (\textbf{\#}) and  \textbf{\%} is the percentage of solved problems over all problem instances of the corresponding benchmark.   The last two columns break down the number of problems each verifier was able to verify and falsify. For example, for ACAS Xu, all tools other than \crowndefault{} were able to verify all 186 problems (139 + 47), and \crowndefault{} was only able to solve 113 problems (78 + 35), which is 60.8\% of the total problems. 

% \newcommand{\nsTwentyFour}{\texttt{NeuralSAT}$_\text{VNN-COMP'24}$}
% \newcommand{\ns}{\texttt{NeuralSAT}}

% \begin{table}
%   \small
%   \centering
%   \caption{Results over VNN-COMP'24 Benchmarks}\label{tab:score}
%        \renewcommand{\arraystretch}{0.6}
%   \begin{tabular}{c|ccr|rr}
%     \toprule
%     \textbf{Benchmark} & \textbf{\#} & \textbf{Tool} & \textbf{\%} & \textbf{Verify} & \textbf{Falsify}  \\

% \midrule
% \multirow{4}{*}{\rotatebox[origin=c]{0}{ACAS Xu}}
% & 1 & \crown{} & 100.0\% & \textbf{139} & \textbf{47} \\
% & 1 & \ns{} & 100.0\% & \textbf{139} & \textbf{47} \\
% & 1 & \nsTwentyFour{} & 100.0\% & \textbf{139} & \textbf{47} \\
% & 4 & \crowndefault{} & 60.8\% & 78 & 35 \\
% \midrule
% \multirow{4}{*}{\rotatebox[origin=c]{0}{Cgan}} 
% & 1 & \crown{} & 100.0\% & \textbf{8} & \textbf{13} \\
% & 1 & \ns{} & 100.0\% & \textbf{8} & \textbf{13} \\
% & 1 & \nsTwentyFour{} & 100.0\% & \textbf{8} & \textbf{13} \\
% & 4 & \crowndefault{} & 33.3\% & 0 & 7 \\
% \midrule
% \multirow{4}{*}{\rotatebox[origin=c]{0}{Cifar100}} 
% & 1 & \crown{} & 77.5\% & \textbf{123} & \textbf{32} \\
% & 2 & \ns{} & 76.5\% & 122 & 31 \\
% & 3 & \crowndefault{} & 71.0\% & 110 & \textbf{32} \\
% & 4 & \nsTwentyFour{} & 64.5\% & 98 & 31 \\
% \midrule
% \multirow{4}{*}{\rotatebox[origin=c]{0}{Collins Rul CNN}} 
% & 1 & \crown{} & 100.0\% & \textbf{30} & \textbf{32} \\
% & 1 & \crowndefault{} & 100.0\% & \textbf{30} & \textbf{32} \\
% & 1 & \ns{} & 100.0\% & \textbf{30} & \textbf{32} \\
% & 1 & \nsTwentyFour{} & 100.0\% & \textbf{30} & \textbf{32} \\
% \midrule
% \multirow{4}{*}{\rotatebox[origin=c]{0}{Cora}} 
% & 1 & \crown{} & 43.9\% & \textbf{24} & \textbf{134} \\
% & 1 & \crowndefault{} & 43.9\% & \textbf{24} & \textbf{134} \\
% & 1 & \ns{} & 43.9\% & \textbf{24} & \textbf{134} \\
% & 1 & \nsTwentyFour{} & 43.9\% & \textbf{24} & \textbf{134} \\
% \midrule
% \multirow{4}{*}{\rotatebox[origin=c]{0}{Dist Shift}} 
% & 1 & \crown{} & 100.0\% & \textbf{64} & \textbf{8} \\
% & 1 & \ns{} & 100.0\% & \textbf{64} & \textbf{8} \\
% & 3 & \nsTwentyFour{} & 98.6\% & 63 & \textbf{8} \\
% & 4 & \crowndefault{} & 94.4\% & 60 & \textbf{8} \\
% \midrule
% \multirow{4}{*}{\rotatebox[origin=c]{0}{Linearize NN}} 
% & 1 & \crown{} & 100.0\% & \textbf{59} & \textbf{1} \\
% & 1 & \ns{} & 100.0\% & \textbf{59} & \textbf{1} \\
% & 1 & \nsTwentyFour{} & 100.0\% & \textbf{59} & \textbf{1} \\
% & 4 & \crowndefault{} & 68.3\% & 40 & \textbf{1} \\
% \midrule
% \multirow{4}{*}{\rotatebox[origin=c]{0}{Meta Room}} 
% & 1 & \crown{} & 98.0\% & \textbf{91} & \textbf{7} \\
% & 1 & \ns{} & 98.0\% & \textbf{91} & \textbf{7} \\
% & 1 & \nsTwentyFour{} & 98.0\% & \textbf{91} & \textbf{7} \\
% & 4 & \crowndefault{} & 0.0\% & 0 & 0 \\
% \midrule
% \multirow{4}{*}{\rotatebox[origin=c]{0}{Nn4sys}} 
% & 1 & \crown{} & 100.0\% & \textbf{194} & 0 \\
% & 1 & \ns{} & 100.0\% & \textbf{194} & 0 \\
% & 1 & \nsTwentyFour{} & 100.0\% & \textbf{194} & 0 \\
% & 4 & \crowndefault{} & 4.1\% & 8 & 0 \\
% \midrule
% \multirow{4}{*}{\rotatebox[origin=c]{0}{Safe NLP}} 
% & 1 & \crown{} & 98.1\% & \textbf{411} & \textbf{648} \\
% & 1 & \ns{} & 98.1\% & \textbf{411} & \textbf{648} \\
% & 3 & \crowndefault{} & 96.9\% & 401 & 646 \\
% & 4 & \nsTwentyFour{} & 94.3\% & 378 & 640 \\
% \midrule
% \multirow{4}{*}{\rotatebox[origin=c]{0}{Tiny ImageNet}} 
% & 1 & \crown{} & 91.5\% & \textbf{140} & \textbf{43} \\
% & 2 & \ns{} & 91.0\% & 139 & \textbf{43} \\
% & 3 & \crowndefault{} & 89.5\% & 136 & \textbf{43} \\
% & 4 & \nsTwentyFour{} & 72.5\% & 102 & \textbf{43} \\
% \midrule
% \multirow{4}{*}{\rotatebox[origin=c]{0}{TLL Verify Bench}} 
% & 1 & \crown{} & 100.0\% & \textbf{15} & \textbf{17} \\
% & 1 & \ns{} & 100.0\% & \textbf{15} & \textbf{17} \\
% & 1 & \nsTwentyFour{} & 100.0\% & \textbf{15} & \textbf{17} \\
% & 4 & \crowndefault{} & 65.6\% & 5 & 16 \\
% \midrule
% \multirow{4}{*}{\rotatebox[origin=c]{0}{\textbf{Overall}}} 
% & 1 & \crown{} & 88.8\% & \textbf{1298} & \textbf{982} \\
% & 2 & \ns{} & 88.7\% & 1296 & 981 \\
% & 3 & \nsTwentyFour{} & 84.7\% & 1201 & 973 \\
% & 4 & \crowndefault{} & 71.9\% & 892 & 954 \\
% \bottomrule
%   \end{tabular}
% \end{table}


\chapter{VNN-COMPs}\label{chap:vnncomps}

\chapter{Benchmarks Generation}\label{chap:benchmarks-generation}



\chapter{Conclusion}

\part{Appendices\label{part:appendices}}
%\renewcommand{\appendixname}{Assignment}
\appendix
\chapter{Schedule and Assignments}
\begin{itemize}
    \item Week 1 (Aug 27): Introduction (videos of neural networks, basic terminologies and concepts).
    \item Week 2 (Sept 3):
    \begin{itemize}
    \item HW due: Post a short introduction about yourself on Canvas
    \item Topics: Background on Logic~\autoref{chap:logics} and Linear Programming~\autoref{chap:lp}
    \item Quiz: no quiz this week
    \end{itemize}
    \item Week 3 (Sept 10):
    \begin{itemize}
        \item HW due: MILP problem~\autoref{ex:milp-online}
        \item Topics: DNN and Properties and their formal representation (~\autoref{chap:nn-basics} and~\autoref{chap:properties})
        \item Quiz:~\autoref{problem:milp-hand}
    \end{itemize}
    \item Week 4 (Sept 17):
    \begin{itemize}
        \item HW due: Neural Networks and Properties~\autoref{problem:z3-properties}
        \item Topics: DNN Verification (\autoref{sec:verification}) 
        \item Quiz:~\autoref{problem:drone}
    \end{itemize}
    \item Week 5 (Sept 24): No class this week (prof not available). No quiz or HW due. 

    \item Programming Assignment 1 (PA1)
    \begin{itemize}
        \item Symbolic Execution of Neural Networks~\autoref{sec:pa1} 
        \item Due date \alert{Monday October 6, 2025 11:59pm}
    \end{itemize}
    \item Week 6 (Oct 1):
    \begin{itemize}
        \item HW due:~\autoref{ex:negation-trick},~\autoref{problem:z3-dnn}, and~\autoref{problem:pattern-enumeration}. %, and ~\autoref{problem:nnv-pattern}
        \item Topics: Activation Pattern Search (\autoref{sec:activation-patterns}) and Symbolic Execution (\autoref{sec:se-smt})
        \item Quiz:~\autoref{problem:mydnntwo}
    \end{itemize}
    \item Week 7 (Oct 8):
    \begin{itemize}
        \item No HW because of PA1 due date
        \item Topics: MILP Enncoding of DNNs (\autoref{sec:using-milp})
        \item Quiz: (Re)Do~\autoref{ex:milp-dnn} by hand
    \end{itemize}
    \item Programming Assignment 2 (PA2)
    \begin{itemize}
        \item Abstraction~\autoref{sec:pa2}
        \item Due date \alert{Wednesday October 29, 2025 11:59pm}
    \end{itemize}
    \item Week 8 (Oct 15):
    \begin{itemize}
      \item HW: Do~\autoref{prob:milp-dnn}
       \item Topics: Abstraction (\autoref{chap:abstractions}), Interval and Zonotope (\autoref{sec:interval-abstraction},~\autoref{sec:zonotope-abstraction})
       \item Quiz:~\autoref{prob:stable-neuron}
    \end{itemize}
  \item Week 9 (Oct 22):
        \begin{itemize}
          \item Topics: Abstraction (\autoref{chap:abstractions}), Interval and Zonotope (\autoref{sec:interval-abstraction},~\autoref{sec:zonotope-abstraction})                
          \item HW: Do~\autoref{prob:int-abs}
          \item Quiz:~\autoref{prob:correct-abs}      
        \end{itemize}
    \item Week 10 (Oct 29):
    \begin{itemize}        
        \item No HW because of PA2 due date
        \item Topics: Zonotope~\autoref{sec:zonotope-abstraction} and BaB Algorithm~\autoref{chap:bab}
        \item Quiz: attendance
    \end{itemize}
    \item Week 11 (Nov 5):
    \begin{itemize}                
        \item HW: Do~\autoref{prob:bab-detailed},~\autoref{prob:bab-counterexample}, and ~\autoref{prob:bab-interval}
        \item Topics: Adversarial Attacks~\autoref{chap:adversarial-attacks} and Proof Certificates~\autoref{chap:proof-gen-check}
        \item Quiz:~\autoref{prob:bab-understanding}
    \end{itemize}
    \item Programming Assignment 3 (PA3)
    \begin{itemize}
        \item Branch and Bound~\autoref{sec:pa3}
        \item Due date \alert{Tuesday Nov 25, 2025 11:59pm}
    \end{itemize}    
    \item Week 12 (Nov 12):
    \begin{itemize}        
        \item HW: Do~\autoref{prob:compute-gradients},~\autoref{prob:pgd-iterations}
    \end{itemize}
    
    
\end{itemize}    

\chapter{Programming Assignments}\label{chap:pa}

\input{pa/pa1.tex}
\input{pa/pa2.tex}
\input{pa/pa3.tex}

\renewcommand{\appendixname}{Background}
\appendix

\chapter{Comparing neural networks with software}\label{app:nn-vs-software}

\begin{table}
    \caption{Similarities}\label{tab:nn-software-similarities}
    \scriptsize
    \centering
\begin{tabular}{l|l}
    \toprule
    Aspect & Description\\
    \midrule
    Representation &	Represented using if-then-else statements\\
    Input-Output Mapping &	Take Inputs and produce outputs\\
    Determinism	& Can produce deterministic outputs\\
    Execution Path	& Paths from input to output\\
    Specifications & Can have specifications involving preconditions over inputs and postconditions over outputs\\
    Logical Constraints	& Can be represented as logical constraints\\
    Bugs and Errors & Can have bugs that violate specifications\\
    \bottomrule
\end{tabular}    
\end{table}

\begin{table}
    \caption{Differences}\label{tab:nn-software-differences}
    \scriptsize
    \centering
\begin{tabular}{l|l|l}
    \toprule
    Aspect	& Traditional Software	& Neural Networks \\
    \midrule
    % Control Flow	Complex flow with loops, recursion, and branching.	Feedforward execution; no explicit loops or recursion during inference.
    % State Representation	Uses variables, objects, and explicit state transitions.	Encodes state in weights and neuron activations.
    % Granularity	Operates at a higher abstraction level with fewer conditional branches.	Operates on thousands or millions of neurons, creating many implicit conditional branches.
    % Object-Oriented Features	Incorporates OOP principles like encapsulation, inheritance, and polymorphism.	Lacks explicit OOP features but can be modular (e.g., layers, sub-networks).
    % Execution Path	Determined by explicit logic and relatively few branches.	Implicit execution paths defined by piecewise-linear regions from activations.
    % Termination	Explicitly handles termination in loops and recursion.	Fixed-length inference process with no explicit termination conditions.
    % Semantics	Implements precise, deterministic logic for well-defined tasks.	Approximates functions based on training, often non-deterministic during learning.
    % Verification	Formal verification methods are established for correctness.	Verification is challenging due to non-linearity and high dimensionality.
    % Debugging	Tools like debuggers allow step-by-step inspection of logic.	Focuses on diagnosing data issues, architecture problems, or training convergence.
    Explainability & Can be explained through code inspection & Lacks explicit explainability mechanisms\\
    Designing &	Written by human & Created by machine through learning from training data\\
    Size & Small to medium-sized codebases & Large number of neurons and layers\\
    Error Causing & arise from bugs in logic or implementation & arise from insufficient training data, overfitting, etc\\
    Error Incurring & Can cause crashes, incorrect outputs, or unexpected behavior & Can cause incorrect predictions or unexpected behavior\\
    Error Handling & try-catch blocks for exception handling &	Lacks explicit error-handling mechanisms\\
    % Learning	Does not â€œlearnâ€; behavior must be explicitly defined.	Learns to approximate functions through training.
    % Non-Linearity	Handles non-linearity explicitly through conditional logic or complex mathematical operations.	Uses activation functions like ReLU, Sigmoid, or Tanh to introduce non-linearity.
    % Parallelism	Often single-threaded or relies on explicit multi-threading for parallelism.	Intrinsic large-scale parallelism due to the structure of layers and neurons.
    % Adversarial Vulnerability	Less vulnerable to adversarial inputs, but bugs can lead to unexpected behavior.	Susceptible to small, imperceptible perturbations in input (adversarial examples).
    % Generalization	Executes pre-defined logic; does not generalize beyond explicit instructions.	Generalizes from training data, allowing predictions on unseen inputs.    
    % Dynamic Resource Management	Explicitly handles memory, files, and resources during execution.	Resources are statically allocated during training and inference; no dynamic management.
    % Concurrency	Explicitly handles concurrent operations using threads or async programming.	No explicit concurrency; parallelism occurs naturally due to network architecture.
    \bottomrule
\end{tabular}    
\end{table}

\chapter{Logics}\label{chap:logics}

The field of neural network verification (NNV) relies heavily on two fundamental areas: 
\emph{logic} (to formalize and reason about properties as logical formulae) and \emph{optimization} (to formulate and reason about numerical constraints).
This chapter and the next (\autoref{chap:lp}) provides the necessary background on both topics in detail, starting with propositional logic and satisfiability, 
and then moving to linear and mixed-integer programming.


\section{Propositional Logic and Satisfiability}\label{sec:propositional-logic}

Propositional, or Boolean, logic is the branch of logic that studies formulae built from Boolean variables, where each variable can take only the values \texttt{True} or \texttt{False}. These formulae are combined using logical connectives such as \texttt{and}, \texttt{or}, and \texttt{not}, and their evaluation always reduces to a single truth value.

\subsection{Syntax}

A \emph{propositional variable} is a symbol (e.g., $x, y, z$). Logical formulae are built \emph{inductively} from these variables using logical connectives as follows:

\begin{itemize}
  \item Variables: Any propositional variable $p$ is a formula.
  \item Constants: $\top$ and $\bot$ are formulae.
  \item Negation: If $\phi$ is a formula, then so is $\lnot \phi$.
  \item Binary connectives: If $\phi, \psi$ are formulae, then so are
    $(\phi \land \psi)$, $(\phi \lor \psi)$, and $(\phi \to \psi)$.
\end{itemize}

\begin{example}

\[
(x \lor y) \land (\lnot x \lor z)
\]
is a formula involving three variables $x,y,z$.
\end{example}

\paragraph{Special connectives} In addition to the standard connectives, we define some special connectives that are often useful:

\begin{itemize}
    \item \emph{Implication}: $\phi \to \psi \equiv \lnot \phi \lor \psi$
    \item \emph{Biconditional} (or \emph{equivalence}): $\phi \leftrightarrow \psi \equiv (\phi \to \psi) \land (\psi \to \phi)$
\end{itemize}


\paragraph{Convert to Conjunctive Normal Form (CNF)} A formula is in CNF if it is a conjunction of disjunctions of literals,
where a literal is either a variable $p$ or its negation $\lnot p$. 

Any formula can be transformed into CNF. The process generally involves the following steps:
\begin{enumerate}
\item Eliminate biconditionals and implications.
\item Move negations inward using De Morgan's laws.
\item Distribute disjunctions over conjunctions.
\end{enumerate}

\begin{problem}
Transform the formula 
\[
(x \to y) \land (y \to z)
\]
into CNF.
\end{problem}


\begin{commentbox}
Notice here that we purely define the syntax of propositional logic, which allows us to construct valid formulae. We will discuss the semantics or meanings of formulae next (\autoref{sec:propositional-semantics}).
\end{commentbox}
\subsection{Semantics}\label{sec:propositional-semantics}

A logical formula in propositional logic has a truth value, which can be either \texttt{True} or \texttt{False}. 
For example, the formula $x \lor \neg{x}$ is always \texttt{True}, while the formula $x \land y$ is \texttt{True} if both $x$ and $y$ are \texttt{True}, and \texttt{False} otherwise.
This is the \emph{semantics} of the formula.

An \emph{assignment} $\alpha$ maps each formula to $\texttt{True}$ or $\texttt{False}$.
The truth value of a formula is defined recursively
\begin{align*}
  \alpha(\top) &\quad = \texttt{True}, \\
  \alpha(\bot) &\quad = \texttt{False}, \\
  \alpha(p) &\quad \text{iff } \alpha(p) = \texttt{True}, \\
  \alpha(\lnot \phi) = \texttt{True} &\quad \text{iff } \alpha(\lnot \phi) = \texttt{True}, \\
  \alpha(\phi \land \psi) = \texttt{True} &\quad \text{iff } \alpha(\phi) = \texttt{True} \text{ and } \alpha(\psi) = \texttt{True}, \\
  \alpha(\phi \lor \psi) = \texttt{True} &\quad \text{iff } \alpha(\phi) = \texttt{True} \text{ or } \alpha(\psi) = \texttt{True}, \\
  \alpha(\phi \to \psi) = \texttt{True} &\quad \text{iff } \alpha(\phi) = \texttt{False} \text{ or } \alpha(\psi) = \texttt{True}.
\end{align*}

\begin{problem}  
For the formula 

\[
(x \lor y) \land (\lnot x \lor z), 
\]
evaluate its truth value under all $2^3=8$ possible assignments of $x,y,z$.
\end{problem}

\subsection{Satisfiability and Validity}
\begin{definition}[Satisfiability]\label{def:sat-validity}
     A formula $\phi$

\begin{itemize}
  \item is \emph{satisfiable} if there exists \textbf{some} $\alpha$ such that $\alpha(\phi) = \texttt{True}$.
  \item is \emph{unsatisfiable} if \textbf{no} assignment satisfies it.
  \item is \emph{valid} if \textbf{all} assignments satisfy it.
\end{itemize}
\end{definition}

\begin{example} The formula
    \[x\]
    is satisfiable (e.g., $\alpha(x) = \texttt{True}$).
\[
(x) \land (\lnot x)
\]
is unsatisfiable (no assignment works).
In contrast,
\[
(x \lor \lnot x)
\]
is valid.
\end{example}

\begin{problem}
Show that $(\phi \to \psi)$ is equivalent to $(\lnot \phi \lor \psi)$.  
(Hint: construct a truth table.)
\end{problem}


\subsection{SAT Solving}\label{sec:sat-solving}

A SAT solver takes a propositional formula as input and determines its satisfiability by searching for a satisfying assignment. If one exists, it returns the assignment; otherwise, it reports \unsat{}. % Modern solvers use search algorithms such as
% \emph{DPLL (Davisâ€“Putnamâ€“Logemannâ€“Loveland)} and
% \emph{CDCL (Conflict-Driven Clause Learning)}.

\begin{example}
\begin{align*}
\phi_1 &= (x \lor y) \land (\lnot x \lor z) \quad \Rightarrow \, \sat{}\\
\phi_2 &= (x) \land (\lnot x) \quad \Rightarrow \unsat{}
\end{align*}
\end{example}




\begin{problem}
Use the Z3 solver to check whether
\[
(x \lor y) \land (\lnot x \lor y) \land (x \lor \lnot y)
\] is satisfiable.  
Provide a satisfying assignment if it exists.
\end{problem}




\paragraph{Conjunctive Normal Form (CNF)}
In practice, SAT solvers do not take arbitrary formulae as input. Instead, they require the formula to be in \emph{Conjunctive Normal Form (CNF)}.


\begin{example}
\[
(x \lor y) \land (\lnot x \lor z)
\]
is in CNF. Each clause $(x \lor y)$, $(\lnot x \lor z)$ is a disjunction of literals.
\end{example}



\subsection{Validity Checking}\label{sec:validity-checking}
By~\autoref{def:sat-validity}, a formula $\alpha$ is valid if all assignments satisfy it.
This is equivalent to saying that its negation $\overline{\alpha}$ is unsatisfiable (no assignment satisfies it), i.e., 
\[
\text{valid}(\alpha) \iff \text{unsat}(\overline{\alpha})
\]  
Thus, to check the validity of $\alpha$, we can use a SAT solver to check that $\overline{\alpha}$ is \unsat{}.

%We can use a SAT solver to check if a formula $\alpha$ is valid (no satisfying assignment) by checking that its \emph{negation}, $\overline{\alpha}$, is \emph{not} satisfiabile. 


\section{Satisfiability Modulo Theories (SMT)}

SAT solvers only reason about propositional formulae, which only contain Boolean variables and logical operators such as $\land, \lor$.  However, in verification problems, we often need to reason about arithmetic constraints $2x + 3y \leq 7; x \geq 0; x,y \in \mathbb{Z}$.


This leads to \emph{Satisfiability Modulo Theories (SMT)}:
\begin{itemize}
  \item SMT generalizes SAT by adding background theories (e.g., linear arithmetic, bit-vectors, arrays).
  \item An SMT formula mixes Boolean structure with constraints from these theories.
\end{itemize}

\begin{example}\label{ex:smt2}
Is the formula $2x = 1$ satisfiable? 

The answer depends on the chosen theory. Here, over real numbers ($\mathbb{R}$), it is SAT (e.g., $x=0.5$), but over integers ($\mathbb{Z}$) it is UNSAT.


\end{example}
\subsection{SMT Solvers}

% Like SAT solving, an SMT solver ..

Popular SMT solvers include Z3 (Microsoft Research), CVC5, and dReal.
They combine:
\begin{itemize}
  \item A SAT solver for the Boolean skeleton.
  \item A \emph{theory solver} or T-solver (e.g., linear arithmetic) for the numeric parts.
\end{itemize}

The SAT solver guesses a truth assignment for the Boolean structure. The T-solver checks whether the corresponding arithmetic constraints are feasible. This loop continues until either a satisfying assignment is found or \unsat{} is proven.

\begin{problem}
Decide the satisfiability of:
\[
(x > 3) \land (y < 2) \land (x+y < 1).
\]

First, do the reasoning informally by hand, and then confirm with an SMT solver such as Z3.
\end{problem}


\subsection{Z3 SMT Solver}\label{sec:z3}

Z3~\cite{de2008z3} is a well-known SMT solver developed by Microsoft Research. Here we'll show how to use it for various logical and arithmetic problems.


\paragraph{Installing} You can install Z3 using your package manager, for example

\begin{lstlisting}
    brew install z3        # using homebrew
    pip install z3-solver   # using pip
    apt install z3 python3-z3 # using apt (on Debian-based Linux systems)
    conda install z3solver # using conda
\end{lstlisting}    


Then try its Python interface:

\begin{lstlisting}
    from z3 import *
    x = Int(`x')
    y = Int(`y')
    solve(x > 2, y < 10, x + 2*y == 7)
\end{lstlisting} 



\begin{example}[Propositional Logic]\label{ex:z3-propositional}

We use Z3 to check satisfiability of propositional formulae and generate counterexamples.

\begin{lstlisting}
from z3 import *

x, y = Bools(`x y')
formula = And(Or(x, y), Or(Not(x), y))
s = Solver()
s.add(formula)
print(s.check())   #output: sat
print(s.model())   #a possible model is {x=True, y=True}
\end{lstlisting}
\end{example}

\begin{problem}
Modify the code in~\autoref{ex:z3-propositional} to check 

\[
(x \land \lnot x).
\]
Confirm that the result is \texttt{unsat}.
\end{problem}




\begin{example}[Linear Constraints.]

We now use Z3 as an SMT solver to check linear constraints.

    \begin{lstlisting}
from z3 import *
x, y = Reals(`x y')

# example 1
s = Solver()
s.add(x > 0, y > 0, 2*x + y <= 1)
print(s.check())  # Output: unsat

# example 2
s = Solver()
s.add(x + y <= 4, x >= 0, y >= 0)
print(s.check()) # Output: sat
print(s.model())  # Output: {x=0, y=0}


# example 3
x, y = Ints(`x y')
s = Solver()
s.add(Implies(x > 3, y > 2))
print(s.check()) # Output: sat
print(s.model()) # Output: {x=0, y=0}
\end{lstlisting}
\end{example}

\begin{problem}
Use Z3 to check whether the constraints
\[
x+y=5, \quad x \geq 0, \quad y \geq 0
\]
are satisfiable, and if so, ask Z3 for a model.
\end{problem}

\begin{problem}
Use Z3 to check the formula given in~\autoref{ex:smt2}. Do it for both the reals and integers.
\end{problem}

\begin{problem}
Use Z3 to formulate and check the statement \texttt{``If $x>3$ then $y>2$ AND $x \leq 1$''}.
Is it satisfiable? What model does Z3 return?
\end{problem}



\begin{example}[DNN-style checking]
Consider a one-neuron ReLU: $y = \max(0, x - 1)$.  
We want to check if the property \texttt{``For all $x \leq 0$, we have $y=0$''} holds.


\begin{lstlisting}
x, y = Reals(`x y')
s = Solver()

# y = max(0, x-1)
s.add(y >= x-1, y >= 0)
s.add(Or(y == x-1, y == 0)) # ReLU
s.add(x <= 0, y != 0) # Negation of property

print(s.check()) # Output: unsat, property holds
\end{lstlisting}
\end{example}


\begin{problem}
Modify the above to check property:  
\texttt{``For all $x \geq 2$, we have $y \geq 1$.''}  
What does Z3 return?
\end{problem}


\section{SAT and SMT Solving Algorithms}\label{sec:sat-smt-algorithms}

Here we briefly discuss SAT and SMT solving algorithms, which are used to determine the satisfiability (and therefore validity) of SAT and SMT formulae.

\subsection{Satisfiability (SAT) Problem}\label{sec:sat-problem}
The classical satisfiability (SAT) problem asks if a given propositional formulae (\autoref{sec:propositional-logic}) can be satisfied~\cite{biere2009handbook}.  Given a formula CNF $f$, an SAT solver returns \sat{} if it can find a satisfying assignment that maps truth values to variables of $f$ that makes $f$ evaluate to true, and \unsat{} if it cannot find any satisfying assignments.

The SAT problem is \NP-Complete and research into methods for efficiently solving  problem instances has been ongoing for multiple decades.


\subsection{DPLL}



\begin{figure}
    \centering
  \includegraphics[width=0.6\linewidth]{figure/dpll.pdf}
  \caption{\label{fig:dpll} The classicial DPLL Algorithm.}
\end{figure}


\autoref{fig:dpll} gives an overview of \textbf{DPLL}, a SAT solving technique introduced in 1961 by Davis, Putnam, Logemann, and Loveland~\cite{davis1962machine}. DPLL is an iterative algorithm that takes as input a propositional formula and (i) decides an unassigned variable and assigns it a truth value, (ii) performs Boolean constraint propagation (BCP or also called Unit Propagation),  which detects single literal clauses that either force a literal to be true in a satisfying assignment or give rise to a conflict; (iii) analyzes the conflict to backtrack to a previous decision level \texttt{dl}; and (iv) erases assignments at levels greater than \texttt{dl} to try new  assignments. 

These steps repeat until DPLL finds  a satisfying assignment and returns \texttt{sat}, or decides that it cannot backtrack (\texttt{dl}=-1) and returns \texttt{unsat}.


%DPLL is both sound (its results are correct) and complete (it can find a solution for any input in finite time). %Since its introduction, many heuristics have been introduced to make DPLL more efficient,
%However, because SAT solving is NP-Complete and DPLL has a worst-case exponential time complexity. %However, many heuristics have been developed to help DPLL efficient in practice,  e.g., choosing variables to assign values and decision levels to backtrack to~\cite{TODO}.


\subsection{CDCL} 

Modern DPLL solving improves the original version with Conflict-Driven Clause Learning (\emph{CDCL}~\cite{bayardo1997using,marques1999grasp,569607}).
DPLL with CDCL can \emph{learn new clauses} to avoid past conflicts and backtrack more intelligently (e.g., using non-chronologically backjumping).
%Similar to DPLL, CDCL is sound and complete, but also incurs an exponential complexity.  However, 
Due to its ability to learn new clauses, CDCL can significantly  reduce the search space and allow SAT solvers to scale to large problems.
In the following, whenever we refer to DPLL, we mean DPLL with CDCL.

\subsection{DPLL(T)} 

DPLL(T)~\cite{nieuwenhuis2006solving} extends DPLL for propositional formulae to check SMT formulae involving non-Boolean variables, e.g., real numbers and data structures such as strings, arrays, lists.
DPLL(T) combines DPLL with dedicated \emph{theory solvers} to analyze formulae in those theories\footnote{SMT is Satisfiability Modulo Theories and the T in DPLL(T) stands for Theories.}.  
For example, to check a formula involving linear arithmetic over the reals (LRA), DPLL(T) may use a theory solver that uses linear programming to check the  constraints in the formula.

Modern DPLL(T)-based SMT solvers such as Z3~\cite{de2008z3} and CVC4~\cite{barrett2011cvc4} 
include solvers supporting a wide range of theories including linear arithmetic, nonlinear arithmetic, string, and arrays~\cite{kroening2016decision}.

\chapter{Linear Programming (LP)}\label{chap:lp}

Linear Programming (LP) and its generalization Mixed-Integer Linear Programming (MILP) 
form the optimization backbone of many neural network verification techniques.
This chapter provides an overview of LP and MILP that are related to DNN verification.


\section{Linear Constraints and Objectives}\label{sec:lp}

At a high level, LP is a method for optimizing an objective with respect to certain constraints. For example, we want to maximize profit while keeping production costs within budget. In LP, both the objective and constraints are \emph{linear}.


\paragraph{Linear Constraints}

Linear constraints are inequalities that involve linear combinations of variables.  A linear inequality has the general form
\[
c_1x_1 + c_2x_2 + \cdots + c_nx_n \leq b,
\]

where $c_i, b \in \mathbb{R}$. These constraints limit the feasible values that the variables $x_i$ can take.
The set of points satisfying all constraints is called the \emph{feasible region}.


\begin{example}\label{ex:lp-constraints}
Consider the following linear constraints:
\[
x + y \leq 4, \qquad x \geq 0, \qquad y \geq 0.
\]
The feasible region is a triangle with vertices at $(0,0), (4,0), (0,4)$.

\begin{center}
\begin{tikzpicture}[scale=0.8]
\draw[->] (0,0) -- (5,0) node[right] {$x$};
\draw[->] (0,0) -- (0,5) node[above] {$y$};
\draw[thick, fill=blue!10] (0,0) -- (4,0) -- (0,4) -- cycle;
\node at (2,1) {Feasible region};
\end{tikzpicture}
\end{center}
\end{example}

\paragraph{Linear Objective Functions}
A linear objective function $z$ has the general form
\[
z(x_1, x_2, \ldots, x_n) = c_1x_1 + c_2x_2 + \cdots + c_nx_n,
\]

where $c_i \in \mathbb{R}$ are coefficients, and $x_i \in \mathbb{R}$ are decision variables. 


\paragraph{Optimizing Goals}
Our goal is to optimize (maximize or minimize) $z$ with respect to a set of linear constraints over the decision variables.
\[
\begin{aligned}
& \text{maximize } z \\
& \text{subject to } \\
& \{c_1x_1 + c_2x_2 + \cdots + c_nx_n \leq b, \ldots    \}
\end{aligned}
\]

\begin{example}\label{ex:lp-example1}
Maximize 
\[
1.5x+2y
\] subject to:
\[
\{x+y \leq 4, x \geq 0, y \geq 0\}.
\]

First, we can solve for the intersection points of the constraints:

\[
\begin{aligned}
& x+y = 4 \\
& x = 0 \\
& y = 0
\end{aligned}
\]
Solving these equations gives us the corner points or vertices of the feasible region:
\[
\begin{aligned}
& (0,0) \\
& (4,0) \\
& (0,4)
\end{aligned}
\]

Now, we can evaluate the objective function $z = 1.5x+2y$ at each vertex:

\begin{center}
\begin{tabular}{ccc}
\hline
x & y & z \\
\hline
0 & 0 & 0 \\
4 & 0 & 6 \\
0 & 4 & 8 \\
\hline
\end{tabular}
\end{center}

Thus, the maximum value of $z$ is 8, achieved at the vertex $(0,4)$.


\paragraph{Geometric interpretation} The constraints represent the feasible region as a triangle with vertices at $(0,0)$, $(4,0)$, and $(0,4)$:

\begin{center}
\begin{tikzpicture}[scale=0.7, transform shape]
    \begin{axis}[
        axis lines = middle,
        xlabel = $x$,
        ylabel = $y$,
        xmin=0, xmax=5,
        ymin=0, ymax=5,
        xtick={0,1,2,3,4},
        ytick={0,1,2,3,4},
        grid=both,
        width=8cm,
        height=8cm,
    ]
    % Feasible region
    \addplot [
        domain=0:4, 
        samples=100, 
        fill=blue!20, 
        opacity=0.5
    ] {4 - x} \closedcycle;
    
    % Constraints
    \addplot [thick] {4 - x};
    \addplot [thick] {0};
    \addplot [thick] coordinates {(0,0) (0,4)};
    
    % Vertices
    \filldraw[red] (axis cs:0,0) circle (2pt) node[anchor=north west] {$(0,0)$};
    \filldraw[red] (axis cs:4,0) circle (2pt) node[anchor=north east] {$(4,0)$};
    \filldraw[red] (axis cs:0,4) circle (2pt) node[anchor=south west] {$(0,4)$};
    
    % Objective function line
    \addplot [dashed, thick] {8 - 1.5*x} node[pos=0.85, above] {$1.5x + 2y = 8$};
    
    \end{axis}
\end{tikzpicture}
\end{center}

The objective function $z = 1.5x+2y$ is maximized at vertex $(0,4)$.

\end{example}

\begin{problem}\label{ex:lp-problem2}
    Maximize $z=4x+5y$ subject to $\{x+y \le 20, \; 2x+4y \leq 72\}$.

    \begin{enumerate}    
        \item Identify the corner points.
        \item Evaluate the objective function at each corner point.
    \end{enumerate}
\end{problem}


\section{Mixed-Integer Linear Programming (MILP)}\label{sec:milp-basics}

LP (\autoref{sec:lp}) assumes continuous variables over real numbers.  
A mixed-integer linear program (MILP) extends LP by requiring some variables to be integers (often binary 0 or 1).  This is useful because it allows for modeling discrete decisions and logical constraints, e.g., on/off decisions, yes/no choices, and active/inactive ReLU.

\paragraph{Linear Constraints}
In MILP, a linear constraint can involve both integer and continuous decision variables, and have the general form
\[
c_1x_1 + c_2x_2 + \cdots + c_nx_n + d_1y_1 + d_2y_2 + \cdots + d_my_m \leq b,
\]
where $x_i \in \mathbb{R}$ are continuous variables, $y_j \in \mathbb{Z}$ are integer variables, and $c_i, d_j, b \in \mathbb{R}$.

\paragraph{Objective Function}
A linear objective function $z$ in MILP can be expressed as:
\[
z(x_1, \ldots, x_n, y_1, \ldots, y_m) = c_1x_1 + c_2x_2 + \cdots + c_nx_n + d_1y_1 + d_2y_2 + \cdots + d_my_m,
\]
where $x_i \in \mathbb{R}$ are continuous variables, $y_j \in \mathbb{Z}$ are integer variables, and $c_i, d_j \in \mathbb{R}$.

\paragraph{Optimizing Goals}
In MILP, the goal is to find the optimal values of the decision variables $x$ and $y$ that maximize or minimize the objective function $z$, while satisfying all linear constraints.

\[
\begin{aligned}
& \text{maximize } z(x_1, \ldots, x_n, y_1, \ldots, y_m) \\
& \text{subject to } \\
& \{c_1x_1 + c_2x_2 + \cdots + c_nx_n + d_1y_1 + d_2y_2 + \cdots + d_my_m \leq b\}
\end{aligned}
\]


\begin{example}\label{ex:lp-example3}
A company sells a chair for \$50 and a table for \$120. The production costs of the chair and the table are \$20 and \$70, respectively. It also takes 3 hours to produce a chair and 1 hour to produce a table. 
Moreover, it takes 5 units of wood to produce a chair and 20 units of wood to produce a table.

How many chairs and tables should the company produce to \emph{maximize} profit within a week without exceeding its monthly budget of 200 units of woods, 80 hours of labor, and \$800 in production costs? 

First, the decision variables are defined as follows:
\begin{itemize}
    \item $x$: the number of chairs produced.
    \item $y$: the number of tables produced.
\end{itemize}

The objective function to maximize profit $P$ is given by:
\[
P = 50x + 120y - 20x - 70y = 30x + 50y
\]

with subject to the constraints:
\[
\begin{aligned}
& 5x + 20y \le 200 \implies x + 4y \le 40\\
& 3x + y \le 80 \\
& 20x + 70y \le 800 \implies 2x + 7y \le 80\\
& x \ge 0 \\
& y \ge 0.
\end{aligned}
\]

\paragraph{Solving}

First, we can find the corner points from the constraints
\[
\begin{aligned}
    & x + 4y = 40 \\
    & 3x + y = 80 \\
    & 2x + 7y = 80 \\
    & x = 0 \\
    & y = 0
\end{aligned}
\]

Solving these equations gives us the corner points or vertices of the feasible region:
(0,0);
(0, 10);
$(\frac{80}{3} ,0)$; and 
$(\frac{280}{11},\frac{40}{11})$ (from x + 4 y = 40 ~\&~ 3x + y = 80). 
Note that all of these are feasible with $2x + 7y \le 800$.




Now, we can evaluate the objective function $P$ at each vertex:

\begin{center}
\begin{tabular}{ccc}
\hline
x & y & P = 30x + 50y \\
\hline
0 & 0 & 0 \\
0 & 10 & 500 \\
$\frac{80}{3}$ & 0 & 800 \\
$\frac{280}{11}$ & $\frac{40}{11}$ &945.45 \\
\hline
\end{tabular}
\end{center}

Thus, the maximum value of $P$ is 945.45, achieved at the vertex $(\frac{280}{11},\frac{40}{11})$. 

Of course, since we cannot produce fractional chairs or tables, we need to round these numbers to the nearest integers.
This means the company should produce 24 chairs and 4 tables per week, and get a profit of \$920.00

\end{example}


\subsection{Encoding Binary Variables}\label{sec:milp-binary}
MILP problems often involve disjunction or condition where the answer depends on some condition.  We can encode such condition using binary variables (0-1 integers), e.g., using  $z \in \{0,1\}$ to indicate whether a certain condition is met.  Moreover, we also use a ``trick'' with a large constant $M$, e.g., $\infty$, to encode logical implications.

\begin{example}
To encode ``if $z = \texttt{True}$ then $x \geq 5$'', use:
\[
x \geq 5 - M(1-z), \quad z \in \{0,1\}
\]


This works because 
\begin{itemize}
 \item $z=1 \implies x \ge 5 - M(0) \implies x \geq 5$.
 \item $z=0 \implies x \geq 5 - M \implies x \ge -\infty$ (because $M$ is large this is vacuously true and can be discarded).
\end{itemize}

\end{example}


\begin{problem}
Encode the disjunction $x \geq 5 \lor x \leq 3$ in MILP.

\begin{solution}
    We use two constraints:
    \begin{itemize}
    \item $x \geq 5 - M(1-z)$ (if $z=1$, this enforces $x \geq 5$)
    \item $x \leq 3 + Mz$ (if $z=0$, this enforces $x \leq 3$)
    \end{itemize}
\end{solution}
\end{problem}


\begin{example}[Encoding ReLU in MILP]\label{ex:relu_milp}

To encode the ReLU (\autoref{sec:relu}) activation function $y = \max(0, x)$, use
\begin{equation}\label{eq:relu-milp}
\begin{aligned}
& y \geq x, \\
& y \geq 0, \\
& y \leq x + M(1-z), \\
& y \leq Mz,\\
& z \in \{0,1\}.\\
\end{aligned}
\end{equation}

This works because 

\begin{itemize}
\item $z=1 \implies y=x$.    
\item $z=0 \implies y=0$.  
\end{itemize}


\end{example}
\begin{problem}
Consider again the ReLU example in \autoref{ex:relu_milp} but now $x$ has the bounds $L \leq x \leq U$. Modify the MILP encoding so that $L$ and $U$ are used \emph{directly} instead of a large constant $M$.

\begin{solution}
To modify the MILP encoding for the ReLU function with bounds $L \leq x \leq U$, we add the following constraints:
\[
\begin{aligned}
& y \geq x, \\
& y \geq 0, \\
& y \leq x + (U-x)(1-z), \\
& y \leq Uz, \quad z \in \{0,1\}, \\
& L \leq x \leq U.
\end{aligned}
\]
\end{solution}
\end{problem}


\section{Using Z3 to Solve LP and MILP}

We can use Z3's optimization capabilities to solve both LP and MILP problems. Note that in practice, we often use dedicated solvers such as Gurobi or CPLEX for large problems, but Z3 is effective for demonstration purposes.

\begin{example}
    We can model and solve~\autoref{ex:lp-example1} using Z3 as follows:

    \begin{lstlisting}
from z3 import *

x, y = Reals("x y")
opt = Optimize() # setup the optimization problem
opt.add(x + y <= 4, x >= 0, y >= 0)

# Objective
z = 1.5*x + 2*y
h = opt.maximize(z)

# Solve
if (opt.check() == sat): 
    print("Optimal sol:", opt.model())  # output [x = 0, y = 4]
    print("Max value:", opt.upper(h))   # output 8
    \end{lstlisting}
\end{example}


\begin{problem}
Do~\autoref{ex:lp-problem2} using Z3.
\end{problem}

\begin{problem}
Do~\autoref{ex:lp-example3} using Z3.
\end{problem}



\begin{problem}\label{ex:milp-online}
For this problem, you will find some interesting MILP problem online, formulate it, and solve it using Z3. Specifically, do the following:
\begin{itemize}
\item Find \emph{two} interesting MILP problems online. These can be from textbooks, research papers, or online resources (Youtube, Google, online tutorials).

Note: Interesting here means the problem has a non-trivial structure, resembles real-world applications (like the table and chair example in~\autoref{ex:lp-example3}), or involves complex constraints.
\item For each problem:
\begin{itemize}
    \item Write down the problem and \emph{cite} the sources (e.g., exact URL or Author(s)/Title/Year if from a paper).
    \item Formulate the problem as a MILP (clearly indicate the objective and constraints).
    \item Solve them by hand (you can type this out, but show all the steps, if possible, draw the graph showing the feasible region).
    \item Implement the formulation in Z3 and solve it.
\end{itemize}
\end{itemize}

\end{problem}


\begin{problem}\label{problem:milp-hand}
Minimize $z = x + y$ subject to:
\[
\begin{aligned}
& x + 2y \geq 3, \\
& 3x + y \geq 3, \\
& x, y \geq 0, \\
& x,y \in \mathbb{R}.
\end{aligned}
\]

You can either do this by hand on paper (and take picture) or write Python code with Z3. Either way, show all the steps (e.g., as comments in the Z3 code):
\begin{enumerate}
    \item The constraints and objective function.
    \item The corner or candidate points (this problem is very simple that you do need an algorithm like Simplex to solve. You can simply ``guess'' these points, e.g., the intersection of the given constraints)
    \item The objective value at each corner point.
    \item The optimal solution.
\end{enumerate}
\end{problem}

% \paragraph{Example.}  
% One-neuron ReLU: $y = \max(0,2x-1)$.  
% Verify: â€œFor all $x \in [0,0.4]$, $y=0$.â€  
% - Encode input range, ReLU, and negation ($y>0$).  
% - MILP is infeasible.  
% - Property holds.

% ---

% \section{problems}

% \paragraph{problem 1 (Warm-up).}  
% Maximize $2x+3y$ subject to $x+2y \leq 8, \; 2x+y \leq 8, \; x,y \geq 0$.  
% (a) Sketch feasible region.  
% (b) Identify corner points.  
% (c) Find optimal solution.

% \paragraph{problem 2.}  
% Formulate and solve a diet problem with three foods and two nutrients.  
% Find the cheapest diet satisfying requirements.

% \paragraph{problem 3.}  
% Duality practice:  
% Write the dual of
% \[
% \min 5x_1+2x_2 \quad \text{s.t. } x_1+x_2 \geq 3, \; x_1, x_2 \geq 0.
% \]

% \paragraph{problem 4 (MILP).}  
% Encode in MILP:  
% â€œIf factory A is open ($z_A=1$) then production $\geq 50$,  
% if factory B is open ($z_B=1$) then production $\geq 30$.  
% At most one factory may be open.â€

% \paragraph{problem 5 (Verification).}  
% Network: $h=\max(0,x_1-x_2), \; y=h+x_2$.  
% Verify: For all $x_1,x_2 \in [0,1]$, $y \geq 0$.  
% Model as MILP and solve.



% \section{Linear Constraints and Feasible Regions}

% A \emph{linear constraint} has the form:
% \[
% a_1x_1 + a_2x_2 + \cdots + a_nx_n \leq b.
% \]


% \paragraph{Example.}  
% Constraints:
% \[
% x + y \leq 4, \quad x \geq 0, \quad y \geq 0.
% \]
% The feasible region is a triangle bounded by the axes and the line $x+y=4$.

% \begin{example}
%     Sketch the feasible region defined by:
% \[
% 2x + y \leq 6, \quad x \geq 0, \quad y \geq 0.
% \]
% \end{example}
% \section{Linear Programming Problems}

% An LP is an optimization problem:
% \[
% \max c^T x \quad \text{subject to } Ax \leq b, \; x \geq 0.
% \]

% \paragraph{Example.}  
% Maximize $x+y$ subject to
% \[
% x+y \leq 4, \quad x \geq 0, \quad y \geq 0.
% \]
% Solution: maximum is 4 at $(4,0)$ or $(0,4)$.

% \paragraph{problem 6 (Homework).}  
% Solve the LP:
% \[
% \max 3x+2y \quad \text{subject to } 
% \quad 2x+y \leq 8, \; x+2y \leq 6, \; x,y \geq 0.
% \]

% \subsection{Duality (Optional Enrichment)}

% Every LP has a \emph{dual} problem, and strong duality holds under mild conditions.  
% Understanding duality is useful in verification because it enables certificates of infeasibility.

% ---

% \section{Mixed-Integer Linear Programming (MILP)}

% \subsection{From Logic to MILP}

% SAT handles logic, LP handles linear inequalities.
% MILP combines both: some variables are required to be integers (often binary).

% \paragraph{Example.}
% Constraint:
% \[
% x \in \{0,1\}, \quad y \geq 2x.
% \]
% - If $x=0$, then $y \geq 0$.
% - If $x=1$, then $y \geq 2$.

% This encodes logical branching into optimization.

% \paragraph{problem 7 (In-class).}  
% Formulate â€œif $x=1$, then $y=0$â€ as linear constraints using a binary variable and a big-$M$ method.

% \subsection{Encoding ReLU Constraints}

% A ReLU is $y = \max(0,x)$.  
% We introduce a binary variable $z$ to encode activation:
% \begin{align*}
% y &\geq x, \\
% y &\geq 0, \\
% y &\leq x + M(1-z), \\
% y &\leq Mz.
% \end{align*}
% Here $M$ is a large constant.

% - If $z=0$, $y=0$.
% - If $z=1$, $y=x$.

% \paragraph{problem 8 (Homework).}  
% Write MILP constraints for $y = \max(0, 2x+1)$ with $-10 \leq x \leq 10$.

% \subsection{Example: Verifying a Tiny Network}

% Network: input $x \in [0,1]$, hidden neuron $h = \max(0, 2x-1)$, output $y=h$.

% \paragraph{Property.}
% Verify: for all $x \in [0,0.4]$, $y=0$.

% \paragraph{Encoding.}
% \begin{itemize}
%   \item Input constraint: $0 \leq x \leq 0.4$.
%   \item ReLU encoding for $h = \max(0, 2x-1)$.
%   \item Negation of property: $y > 0$.
% \end{itemize}

% \paragraph{Result.}
% MILP is infeasible $\Rightarrow$ property holds.

% \paragraph{problem 9 (Homework).}  
% Modify the property to â€œfor all $x \in [0.6,1]$, $y > 0$.â€  
% Check if the MILP is feasible.

% ---

% ---

---

\subsection{Using LP as Feasibility Checking}\label{sec:lp-feasibility}

In addition to optimization, LP can be used for \emph{feasibility} (or satisfiability) checking of linear constraints, i.e., 
are there any values for the variables that satisfy all the constraints?
This is achieved by running an LP solver with a constant objective (e.g., ``minimize 0''), in which case it simply tries to find \emph{any} point in the feasible region or shows that none exists (infeasible). This thus makes it usefful for property checking and verification (e.g., showing that no counterexample exists).


The main difference between LP feasibility and SMT satisfiability is the type of constraints they can handle. SMT satisfiability can handle richer logics involving booleans, integers, nonlinear arithmetic, and other theories while LP feasibility is limited to linear equalities/inequalities over real numbers. But for problems that involve only linear real arithmetic, LP feasibility is sufficient and often more efficient. For problems involving more complex logic or theories, SMT solvers are necessary.



% \subsubsection*{Examples (adapted from earlier LP sections)}

\begin{example}

For the constraints in~\autoref{ex:lp-constraints}:    
\begin{align}
x+y \le 4,\quad x\ge 0,\quad y\ge 0
\end{align}

Running an LP solver with objective $\min 0$ will return a point, e.g., (x=0,y=0), within the feasible region.
\end{example}




\chapter{Software vs DNN Verification}\label{app:software-vs-dnn}


\paragraph{General}
Software verification and DNN verification share the common goal of ensuring the correctness and reliability of their respective systems. Both fields aim to identify and eliminate potential errors or vulnerabilities before deployment, ultimately enhancing user trust and system robustness.

\begin{table}
    \caption{Comparison of Software Verification and DNN Verification}
    \footnotesize
\begin{tabular}{|c|c|c|}
    \hline
    \textbf{Aspect} & \textbf{Software Verification} & \textbf{DNN Verification} \\
    \hline
    \textbf{Input} & Source code, specifications & DNN model, input space \\
    \hline
    \textbf{Output} & Verification results, counterexamples & Verification results, adversarial examples \\
    \hline
    \textbf{Techniques} & Model checking, theorem proving & Formal methods, testing \\
    \hline
    \textbf{Challenges} & State explosion, incomplete specifications & High dimensionality, non-convexity \\
    \hline
\end{tabular}
\end{table}

\paragraph{Similarities} 

\begin{table}
\caption{Similarities of Software Verification and DNN Verification}
\footnotesize
\begin{tabular}{|c|c|c|}
    \hline
    \textbf{Aspect} & \textbf{Software Verification} & \textbf{DNN Verification} \\
    \hline
    \textbf{Input} & Source code, specifications & DNN model, input space \\
    \hline
    \textbf{Output} & Verification results, counterexamples & Verification results, adversarial examples \\
    \hline
    \textbf{Techniques} & Model checking, theorem proving & Formal methods, testing \\
    \hline
    \textbf{Challenges} & State explosion, incomplete specifications & High dimensionality, non-convexity \\
    \hline
\end{tabular}
\end{table}

\paragraph{Differences}
Software verification typically deals with discrete systems and logical properties, while DNN verification focuses on continuous input spaces and the behavior of neural networks under various conditions. Additionally, the techniques used in each field differ significantly, with software verification relying on formal methods and testing, whereas DNN verification often employs specialized techniques such as adversarial training and robustness analysis.

\begin{table}
\caption{Differences of Software Verification and DNN Verification}
\begin{tabular}{|c|c|c|}
    \hline
    \textbf{Aspect} & \textbf{Software Verification} & \textbf{DNN Verification} \\
    \hline
    \textbf{Input} & Source code, specifications & DNN model, input space \\
    \hline
    \textbf{Output} & Verification results, counterexamples & Verification results, adversarial examples \\
    \hline
    \textbf{Techniques} & Model checking, theorem proving & Formal methods, testing \\
    \hline
    \textbf{Challenges} & State explosion, incomplete specifications & High dimensionality, non-convexity \\
    \hline
\end{tabular}
\end{table}


\renewcommand{\appendixname}{Advanced Topics}
\appendix

\chapter{\neuralsat{} Algorithm}\label{sec:neuralsat-alg}



\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\SetKw{Break}{break}
\SetKw{Continue}{continue}
\SetKwFunction{Backtrack}{Backtrack}
\SetKwFunction{Decide}{Decide}
\SetKwFunction{BCP}{BCP}
\SetKwFunction{Deduction}{Deduction}
\SetKwFunction{AnalyzeConflict}{AnalyzeConflict}
\SetKwFunction{BooleanAbstraction}{BooleanAbstraction}
\SetKwFunction{AddClause}{AddClause}
\SetKwFunction{isTotal}{isTotal}
\SetKwFunction{randomattack}{RandomAttack}
\SetKwFunction{pgd}{PGDAttack}

\SetKwFunction{DPLLT}{DPLLT}
\SetKwFunction{isValid}{isValid}
\SetKwFunction{LPSolver}{LPSolver}
\SetKwFunction{Solve}{Solve}
\SetKwFunction{FindLayerNodes}{FindLayerNodes}
\SetKwFunction{TightenInputBounds}{TightenInputBounds}
\SetKwFunction{Abstract}{Abstract}
\SetKwFunction{Check}{Check}
\SetKwFunction{Decide}{Decide}
\SetKwFunction{Imply}{Imply}
\SetKwFunction{Lower}{LowerBound}
\SetKwFunction{Upper}{UpperBound}
\SetKwFunction{GetInputBounds}{GetInputBounds}
\SetKwFunction{GetInputs}{GetInputs}
\SetKwFunction{GetNumInputs}{GetNumInputs}
\SetKwFunction{CurrentConflictClause}{CurrentConflictClause}
\SetKwFunction{StopCriterion}{StopCriterion}
\SetKwFunction{LastAssignedLiteral}{LastLiteral}
\SetKwFunction{LiteralToVariable}{LiteralToVariable}
\SetKwFunction{Antecedent}{Antecedent}
\SetKwFunction{BinRes}{BinRes}
\SetKwFunction{BacktrackLevel}{BacktrackLevel}
\SetKwFunction{AddClause}{AddClause}
\SetKwFunction{ActivationStatus}{ActivationStatus}

\SetKwData{implicationgraph}{igraph}
\SetKwData{literal}{lit}
\SetKwData{variable}{var}
\SetKwData{antecedent}{ante}
\SetKwData{conflict}{conflict}
\SetKwData{none}{none}
\SetKwData{layerid}{lid}
\SetKwData{hiddenbounds}{hidden\_bounds}
\SetKwData{layerbounds}{lbounds}
\SetKwData{inputs}{inputs}
\SetKwData{inputbounds}{input\_bounds}
\SetKwData{outputbounds}{output\_bounds}
\SetKwData{infeasible}{INFEASIBLE}
\SetKwData{unreachable}{UNREACHABLE}
\SetKwData{maxinputs}{MAX\_NUM\_INPUT}
\SetKwData{assignment}{$\sigma$}
\SetKwData{network}{$\alpha$}
\SetKwData{dl}{dl}
\SetKwData{lpmodel}{solver}
\SetKwData{clauses}{clauses}
\SetKwData{conflict}{conflict}
\SetKwData{clause}{clause}
\SetKwData{igraph}{igraph}
\SetKwData{cex}{cex}

\SetKwData{true}{true}
\SetKwData{false}{false}
\DontPrintSemicolon
\SetKwFunction{Restart}{Restart}

\SetKwData{issat}{is\_sat}
\SetKwData{conflictclause}{conflict\_clause}
\SetKwData{isconflict}{is\_conflict}

\begin{algorithm}
    \small
    

    \Input{DNN $\alpha$, property $\phi_{in} \Rightarrow \phi_{out}$}
    \Output{\texttt{unsat} if the property is valid and \texttt{sat} otherwise}
    \BlankLine

    $\clauses \leftarrow \BooleanAbstraction(\alpha)$\;\label{line:Booleanabstraction}

    \While{\true}{
        $\sigma \leftarrow \emptyset$ \tcp{initial assignment}\label{line:varsa}
        $\dl \leftarrow 0$ \tcp{initial decision level}
        $\igraph \leftarrow \emptyset$ \tcp{initial implication graph}\label{line:varsb}
        \While{\true}{\label{line:dpllstart}
            $\isconflict \leftarrow \true$ \;

            \If{$\BCP(\clauses, \sigma, \dl, \igraph)$}{\label{line:bcp}
                \If{$\Deduction(\sigma, \dl, \alpha, \phi_{in}, \phi_{out})$}{ \label{line:deduction}
                    $\issat, v_i \leftarrow \Decide(\alpha, \phi_{in}, \phi_{out}, \dl, \sigma)$ \tcp{decision heuristic} \label{line:decide}
                    \lIf(\tcp*[h]{total assignment}){\issat}{
                        \Return{$\sat$} \label{line:returnsat}
                    }
                    $\sigma \leftarrow \sigma \land v_i$\;% \tcp{decide new variable}
                    $\dl \leftarrow \dl + 1$\;% \tcp{increase decision level by 1}
                    $\isconflict \leftarrow \false$ \tcp{mark as no conflict}
                }
            }
            \If{\isconflict}{
                \lIf(\tcp*[h]{conflict at decision level 0}){$\dl \equiv 0$}{
                    \Return{\unsat}  \label{line:unsat}
                }
                $\clause \leftarrow \AnalyzeConflict(\igraph)$\;
                $\dl \leftarrow \Backtrack(\sigma, \clause)$ \;\label{line:backtrack}
                $\clauses \leftarrow \clauses \cup \{\clause\}$ \tcp{learn conflict clauses} \label{line:learn}
            }

            \lIf(\tcp*[h]{restart heuristic}){$\Restart{}$}{\label{line:restart}
                \Break
            }
        }\label{line:dpllend}
    }
    \caption{The  \tool{}  DPLL(T) algorithm.}\label{fig:alg}

\end{algorithm}



\autoref{fig:alg} shows the \tool{} algorithm, which takes as input the formula $\alpha$ representing the ReLU-based DNN $N$ and the formulae $\phi_{in}\Rightarrow \phi_{out}$ representing the property $\phi$ to be proved.
Internally, \tool{} checks the satisfiability of the formula given in~\autoref{eq:nnv2}
\begin{equation*}
  \alpha \land \phi_{in} \land \overline{\phi_{out}}.
\end{equation*}
\tool{} returns \texttt{unsat} if the formula unsatisfiable, indicating  that $\phi$ is a valid property of $N$, and \texttt{sat} if it is satisfiable, indicating the $N$ is not a valid property.

\tool{} uses a  DPLL(T)-based algorithm to check unsatisfiability.
First, the input formula in~\autoref{eq:nnv2} is abstracted to a propositional formula
with variables encoding neuron activation status (\texttt{BooleanAbstraction}).
Next, \tool{} assign values to Boolean variables (\texttt{Decide}) and checks for conflicts the assignment has with the real-valued constraints of the DNN and the property of interest (\texttt{BCP} and \texttt{Deduction}).
If conflicts arise, \tool{} determines the assignment decisions causing the conflicts (\texttt{AnalyzeConflict}), backtracks to erase such decisions (\texttt{Backtrack}), and learns clauses to avoid those decisions in the future.
\tool{} repeats these decisions and checking steps until it finds a total or full assignment for all Boolean variables, in which it returns \texttt{sat}, or until it no longer can backtrack and returns \texttt{unsat}.

%Note that \tool{} also resets its search (if it thinks that it is stuck in a local optima) and tries different decision orderings to enable better clause learning and avoid similar ``bad'' decisions in the previous runs.



\section{Boolean Abstraction}
\texttt{BooleanAbstraction} (\autoref{fig:alg}~\autoref{line:Booleanabstraction}) encodes the DNN verification problem into a Boolean constraint to be solved by DPLL.  This step creates Boolean variables to represent the \emph{activation status} of hidden neurons in the DNN. Observe that when evaluating the DNN on any concrete input, the value of each hidden neuron \emph{before} applying ReLU is either $>0$ (the neuron is \emph{active} and the input is passed through to the output) or $\le 0$ (the neuron is \emph{inactive} because the output is 0).
This allows partial assignments to these variables to represent neuron activation patterns within the DNN.

From the given network, \tool{} first creates Boolean variables representing the activation status of neurons. Next, \tool{} forms a set of initial clauses ensuring that each status variable is either \texttt{T} or \texttt{F}, indicating that each neuron is either active or inactive, respectively. A truth assignment over the variable $v_i$ creates a constraint on the pre-ReLU neuron $x_i$.


\begin{example}
For the DNN in~\autoref{fig:dnn}, \tool{} creates two status variables $v_3,v_4$ for neurons $x_3,x_4$, respectively, and two initial clauses $v_3\lor \overline{v_3}$ and $v_4 \lor \overline{v_4}$. The assignment $\{x_3=T, x_4=F \}$ creates the constraint $0.5x_1-0.5x_2-1>0 \land x_1 + x_2 -2 \le 0$.
\end{example}


% neural network of verification task into set of clauses, then feed them to the solver.
% To do this, we encode each hidden node $h_i$ of the network correspond to one variable $v_i$ of the decidability problem.
% The number of variables for each hidden layer is equal to number of neurons that feed into the ReLU activation (because we want to decide the status of each ReLU node).
% In particular, in case of the linear layer, the number of hidden nodes is the hidden size $H$ of the layer itself.
% Therefore, $H$ hidden nodes are encoded as $\{v_i, v_{i+1}, ..., v_{i+H-1} \}$.
% In case of the 2-D convolution layer with input shape of $(N, C_{in}, H_{in}, W_{in})$, and output shape $(N, C_{out}, H_{out}, W_{out})$, where $N$ is the batch size, number of variables for this layer is:
% \begin{equation*}
%     H = C_{out} \times H_{out} \times W_{out}
% \end{equation*}
% After encoding all the hidden neurons into the corresponding variables, we construct a set of clauses (init\_clauses in Line 1 of Algo~\ref{fig:alg}):
% \begin{equation} \label{eq:clause}
%     (v_0 \lor \overline{v_0}) \land (v_1 \lor \overline{v_1}) \land ... \land (v_i \lor \overline{v_i}) \land (v_{i+1} \lor \overline{v_{i+1}}) \land ...
% \end{equation}
% With this form in Eq~\ref{eq:clause}, the \tool{} needs to decide all the variables to find a satisfiable solution if it exists, then returns SAT, or returns UNSAT if it could not find one.




%thus in the first step we exploit the structure of the network to create a Boolean abstraction for DPLL.

%and backtracks assignment decisions when conflicts arise.
%However, the variables in the SMT formula representing the FNN and property are real-valued, thus we exploit the structure of network to create a Boolean abstraction for DPLL.


%Thus, during preprocessing, \tool{} also creates Boolean variables representing the status values of hidden pre-ReLU neurons and an initial set of clause enforcing that each variable needs to be either $T$ (\texttt{on}) or $F$ (\texttt{off}).

\section{DPLL}\label{sec:dpll}

After \texttt{BooleanAbstraction}, \tool{} iteratively searches for an assignment satisfying the status clauses (\autoref{fig:alg}, lines~\ref{line:dpllstart}--~\ref{line:dpllend}).
% \tvn{something is wrong with the line ?? here} \hd{fixed}
\tool{} combines  DPLL components (e.g., \texttt{Decide}, \texttt{BCP}, \texttt{AnalyzeConflict}, \texttt{Backtrack} and \texttt{Restart}) to assign truth values with a theory solver (\S\ref{sec:deduction}), consisting of abstraction and linear programming solving, to check the feasibility of the constraints implied by the assignment with respect to the network and property of interest.

\tool{} maintains several variables (\autoref{fig:alg}, lines~\ref{line:Booleanabstraction}--~\ref{line:varsb}). These include $\clauses$, a set of \emph{clauses} consisting of the initial activation clauses and learned clauses;   $\sigma$, a \emph{truth assignment} mapping status variables to truth values; $igraph$, an \emph{implication graph} used for analyzing conflicts; and  $dl$, a non-zero \emph{decision level} used for assignment and backtracking.


%needs to analyze both \emph{Boolean constraints} (i.e., clauses involving status variables) and \emph{non-Boolean constraints} involving the nonlinear representation of the activation function and linear constraints encoding the network and status variables,  e.g., $v_3=\texttt{F}$ means $x_3'=\texttt{off}=0.5x_1-0.5x_2-1.0 \le 0$.
%To analyze both kinds of constraints,

%\autoref{fig:overview} gives an overview of \tool{}, which takes as input a DNN $N$ and a property $P$ and returns \texttt{unsat} if $P$ is a valid property of $N$ and \texttt{sat} otherwise. In the case of \texttt{sat}, \tool{} can also return a satisfying assignment representing a counterexample input violating $P$.

\subsection{Decide}\label{sec:decide}

From the current assignment, \texttt{Decide} (\autoref{fig:alg}, line~\ref{line:decide}) uses a heuristic to choose an unassigned variable and assigns it a random truth value at the current decision level.
\tool{} applies the Filtered Smart Branching (FSB) heuristic~\cite{bunel2018unified,de2021improved}. For each unassigned variable, FSB assumes that it has been decided (i.e., the corresponding neuron has been split) and computes a fast approximation of the lower and upperbounds of the network output variables.  FSB then prioritizes unassigned variables with the best differences among the bounds that would help make the input formula unsatisfiable (which helps prove the property of interest).
Note that if the current assignment is full, i.e., all variables have assigned values, \texttt{Decide} returns \texttt{False} (from which \tool{} returns \texttt{sat}).

% In the current implementation of \tool{}, we use two heuristics to decide unassigned variables representing activation status of neurons.
% The first is based on the bounds computed for the neurons and the second is based objective improvement approach proposed in~\cite{bunel2018unified}.



% \subsection{DPLL - CDCL}
% Modern SAT solvers employ the CDCL (Conflict-Driven Clause Learning) algorithm \cite{cdcl}, which combines the classical DPLL \cite{dpll} (Davis-Putnam-Logemann-Loveland) algorithm with clause learning.

% \textbf{DPLL} DPLL has three main components: assigning truth values to variables, inferring additional assignments from current assignments, and analyzing conflicts and backtracking to a previous decision level to try new assignments.
% Viewing the process as a search on a binary tree, each decision is associated with a decision level, which is the depth in the binary decision tree at which it is made, starting from 1.
% The assignments implied by a decision are associated with its decision level at which it occurred.

% The process of BCP is best illustrated with an implication graph.
% An implication graph represents the current partial assignment and the reason for each of the implications.
% The root nodes of an implication graph correspond to decisions, and the internal nodes to implications through BCP.
% A conflict node with incoming edges labeled with $c$ represents the fact that the BCP process has reached a conflict, by assigning 0 (False) to all the literals in the clause $c$ (i.e., $c$ is conflicting).

% \textbf{CDCL} CDCL also has these DPLL components but extends conflict analysis to learn clauses, which help avoid conflicts and backtrack more effectively.

% \textbf{DPLL(T)} DPLL(T) combines DPLL/CDCL with theory solvers to analyze formulae in different theories (e.g., using an LP solver for linear constraints).
% State-of-the-art SMT solvers such as Z3 \cite{z3} and CVC \cite{cvc} employ the DPLL(T) algorithm \cite{dpllt} to check the satisfiability of an SMT formula involving non-Boolean variables, e.g., real numbers or strings.



%\tool{} follows the DPLL(T) architecture and consists of the several main components as follows.

\subsection{Boolean Constraint Propagation (BCP)}\label{sec:bcp}

From the current assignment and clauses, \texttt{BCP} (\autoref{fig:alg}, line~\ref{line:bcp}) detects \emph{unit clauses}\footnote{A unit clause is a clause that has a single unassigned literal.} and infers values for variables in these clauses.
For example, after the decision $a\mapsto F$, \texttt{BCP} determines that the clause $a\vee b$ becomes unit, and infers that $b \mapsto T$.
Moreover, each assignment due to \texttt{BCP} is associated with the current decision level because instead of being ``guessed'' by \texttt{Decide} the chosen value is logically implied by other assignments.
Moreover, because each {BCP} implication might cause other clauses to become unit, \texttt{BCP} is applied repeatedly until it can no longer find unit clauses.
\textsc{BCP} returns \texttt{False} if it obtains contradictory implications (e.g., one BCP application infers $a \mapsto F$ while another infers $a \mapsto T$), and returns \texttt{True} otherwise.

\paragraph{Implication Graph} \texttt{BCP} uses an \emph{implication graph}~\cite{barrett2013decision} to represent the current assignment and the reason for each BCP implication. In this graph, a node represents the assignment and an edge $i \xrightarrow{c} j$ means that \texttt{BCP} infers the assignment represented in node $j$ due to the unit clause $c$ caused by the assignment represented by node $i$.
The implication graph is used by both BCP, which iteratively constructs the graph on each BCP application and uses it to determine conflict, and \texttt{AnalyzeConflict} (\autoref{sec:analyze-conflicts}), which analyzes the conflict in the graph to learn clauses.

\begin{figure}
    \begin{minipage}[c]{0.15\textwidth}
        \centering
        \small
        \begin{equation*}
            \begin{aligned}
                c_1 &= (\overline{v_1} \lor v_2) \\
                c_2 &= (\overline{v_1} \lor v_3 \lor v_5) \\
                c_3 &= (\overline{v_2} \lor v_4) \\
                c_4 &= (\overline{v_3} \lor \overline{v_4})
            \end{aligned}
        \end{equation*}
        \caption*{(a)}
    \end{minipage}
    \begin{minipage}[c]{0.40\textwidth}
        \centering
        \includegraphics[width=1\linewidth]{figure/implication_graph.pdf}
        \caption*{(b)}
    \end{minipage}
    \begin{minipage}[c]{0.33\textwidth}
        \centering
        \footnotesize
        \begin{tabular}{ccccc}
            name & cl & lit & var & ante \\
            \midrule
            $c_4$ &$\overline{v_3} \lor \overline{v_4}$   & $\overline{v_3}$ &$v_3$   &     $c_2$\\
            & $\overline{v_4} \lor \overline{v_1} \lor v_5$  & $\overline{v_4}$   &     $v_4$  &      $c_3$\\
            &$\overline{v_1} \lor v_5 \lor \overline{v_2}$   & $\overline{v_2}$   &     $v_2$  &      $c_1$\\
            $c_5$      & $\overline{v_1} \lor v_5$
        \end{tabular}
        \caption*{(c)}
    \end{minipage}
    \caption{(a) A set of clauses, (b) an implication graph, and (c) learning a new clause.\label{fig:igraph}}
\end{figure}


\begin{example}
    Assume we have the clauses in~\autoref{fig:igraph}(a), the assignments $\overline{v_5}@3$ and $v_1@6$ (represented in the graph in~\autoref{fig:igraph}(b) by nodes  $\overline{v_5}@3$ and $v_1@6$, respectively), and are currently at decision level $dl$ 6.
Because of assignment $v_1@6$, \texttt{BCP} infers $v_2@6$ from the unit clause $c_1$ and captures that implication with edge $v_1@6 \xrightarrow{c_1} v_2@6$.
Next, because of assignment $v_2@6$, \texttt{BCP} infers $v_4@6$ from the unit clause $c_3$ as shown by edge $v_2@6 \xrightarrow{c_3} v_4@6$.

Similarly, \texttt{BCP} creates edges $v_1@6 \xrightarrow{c_2} v_3@6$ and $\overline{v_5}@ \xrightarrow{c_2} v_3@6$ to capture  the inference $v_3@6$ from the unit clause $c_2$ due to assignments $\overline{v_5}@3$ and $v_1@6$.
Now, \texttt{BCP} detects a conflict because clause $c_4=\overline{v_3} \lor \overline{v_4}$ cannot be satisfied with the assignments $v_4@6$ and $v_3@6$ (i.e., both $v_3$ and $v_4$ are $T$)  and creates two edges to the (red) node $\kappa$: $v_4@6 \xrightarrow{c_4} \kappa$ and $v_3@6 \xrightarrow{c_4} \kappa$ to capture this conflict.

Note that in this example \texttt{BCP} has the implication order $v_2,v_4,v_3$ (and then reaches a conflict). In the current implementation, \tool{} makes an arbitrary decision and thus could have a different order, e.g., $v_3, v_4,v_2$.
\end{example}

%While many SAT solvers use such arbitrary BCP implications, some use heuristics to make decisions to help reach a conflict faster~\cite{pipatsrisawat2007lightweight}.


%The implication graph is sensitive to the order in which the implications are propagated in BCP, which means that the graph is not unique for a given partial assignment. In most SAT solvers, this order is rather arbitrary (in particular, BCP progresses along a list of clauses that contain a given literal, and the order of clauses in this list can be sensitive to the order of clauses in the input CNF formula). In some other SAT solvers, this order is not arbitrary; rather, it is biased towards reaching a conflict faster. \tvn{what about in \tool{}, is the order arbitrary?}

% To illustrate the technique, we use some notations as in \cite{barrett2013decision}.
% If a variable $v_i$ is assigned 1 (owing to either a decision or an implication) at decision level \textit{dl}, we write $v_i@dl$. Similarly, $\overline{v_i}@dl$ reflects an assignment of False to this variable at decision level \textit{dl}.
% Where appropriate, we refer only to the truth assignment, omitting the decision level, in order to make the notation simpler.

% Consider, for example, a formula that contains the following set of conflict clauses, among others:
% \begin{equation}
%     \begin{aligned}
%         c_1 &= (\overline{v_1} \lor v_2) \\
%         c_2 &= (\overline{v_1} \lor v_3 \lor v_5) \\
%         c_3 &= (\overline{v_2} \lor v_4) \\
%         c_4 &= (\overline{v_3} \lor \overline{v_4}) \\
%         c_5 &= (v_1 \lor v_5 \lor \overline{v_2}) \\
%         c_6 &= (v_2 \lor v_3) \\
%         c_7 &= (v_2 \lor \overline{v_3}) \\
%         c_8 &= (v_6 \lor \overline{v_5})
%     \end{aligned}
% \end{equation}




\subsection{Conflict Analysis}\label{sec:analyze-conflicts}

Given an implication graph with a conflict (e.g.,~\autoref{fig:igraph}b), \texttt{AnalyzeConflict} learns a new \emph{clause} to avoid past decisions causing the conflict.
The algorithm traverses the implication graph backward, starting from the conflicting node $\kappa$, while constructing a new clause through a series of resolution steps.
\texttt{AnalyzeConflict} aims to obtain an \emph{asserting} clause, which is a clause that will force an immediate BCP implication after backtracking.


\begin{wrapfigure}{r}{0.50\textwidth}
\begin{minipage}{\linewidth}
\vspace{-0.2in}
\begin{algorithm}[H]
    \small
    \Input{implication graph \implicationgraph}
    \Output{\clause}
    \BlankLine
    $\clause \gets \CurrentConflictClause(\implicationgraph)$\;\label{line:conflict}
    \While{$\neg \StopCriterion(\clause)$}{\label{line:loopstart}
      $\literal \gets \LastAssignedLiteral(\implicationgraph, \clause)$\;\label{line:lit}
      $\variable \gets \LiteralToVariable(\literal)$\;\label{line:var}
      $\antecedent \gets \Antecedent(\implicationgraph,\literal)$\;\label{line:ante}
      $\clause \gets \BinRes(\clause, \antecedent, \variable)$\;\label{line:resolve}
    }\label{line:loopend}
    \Return{$\clause$}
    \caption{\textsc{AnalyzeConflict}}\label{alg:conflict}
  \end{algorithm}
  \end{minipage}
\end{wrapfigure}
\texttt{AnalyzeConflict}, shown in~\autoref{alg:conflict}, first extracts the conflicting clause $cl$ (line~\ref{line:conflict}), represented by the edges connecting to the conflicting node $\kappa$ in the implication graph.
Next, the algorithm refines this clause to achieve an asserting clause (lines~\ref{line:loopstart}--~\ref{line:loopend}).
It obtains the literal $lit$ that was assigned last in $cl$ (line~\ref{line:lit}), the variable $var$ associated with $lit$ (line~\ref{line:var}), and the antecedent clause $ante$ of that $var$ (line~\ref{line:ante}), which contains $\overline{lit}$ as the only satisfied literal in the clause. Now, \texttt{AnalyzeConflict} resolves $cl$ and $ante$ to eliminate literals involving $var$ (line~\ref{line:resolve}). The result of the resolution is a clause, which is then refined in the next iteration.

\paragraph{Resolution.} We use the standard \emph{binary resolution rule} to learn a new clause implied by two (\emph{resolving}) clauses $a_1 \lor ... \lor a_n \lor \beta$ and $b_1 \lor ... \lor b_m \lor \overline{\beta}$ containing complementary literals involving the (\emph{resolution}) variable $\beta$:
\begin{equation} \label{eq:binary-resolution}
    \frac{(a_1 \lor ... \lor a_n \lor \beta) \quad \quad (b_1 \lor ... \lor b_m \lor \overline{\beta})}{(a_1 \lor ... \lor a_n \lor b_1 \lor ... \lor b_m)} \quad  (\textsc{Binary-Resolution})
\end{equation}
The resulting (\emph{resolvant}) clause $a_1 \lor ... \lor a_n \lor b_1 \lor ... \lor b_m$ contains all the literals that do not have complements $\beta$ and $\neg{\beta}$.
%A well-known result obtained by Robinson \cite{robinson1965machine} shows that a deductive system based on the \textbf{binary resolution} rule as its single inference rule is \textbf{sound} and \textbf{complete}.
%In other words, a CNF formula is unsatisfiable if and only if there exists a finite series of binary resolution steps ending with the empty clause.

%The function \textsc{Binary-Resolution}($c_1, c_2, v$) used in line 10 of Algorithm~\ref{alg:conflict} returns the resolvent of clauses $c_1, c_2$, where the \textbf{resolution variable} is $v$ ($\beta$ in the Equation~\ref{eq:binary-resolution}).

%\textbf{Stopping Criteria} \hd{Learned conflict clause is a special kind of conflict clause, called an \textbf{asserting} clause: it forces an immediate implication after backtracking. Empirical studies show that a good strategy for stopping criteria is to  return \textbf{true} if and only if the learned conflict clause $cl$ contains the negation of the first UIP as its single literal at the current decision level. This negated literal becomes asserted immediately after backtracking. In short, the learned conflict clause $cl$ should be an \textbf{asserting} clause.}
%(to obtain an asserting clause

% using the clauses in~\autoref{fig:igraph}a and implication graph in~\autoref{fig:igraph}b developed in
\begin{example}

   ~\autoref{fig:igraph}(c) demonstrates \texttt{AnalyzeConflict} using the example in \S\ref{sec:bcp} with the BCP implication order $v_2,v_4,v_3$ and the conflicting clause $cl$ (connecting to node $\kappa$ in the graph in~\autoref{fig:igraph}(b)) $c_4=\overline{v_3} \lor \overline{v_4}$. From $c_4$, we determine the last assigned literal is $lit=\overline{v_3}$, which contains the variable $var=v_3$, and the antecedent clause containing $v_3$ is $c_2=\overline{v_1} \lor v_3 \lor v_5$ (from the implication graph in~\autoref{fig:igraph}(b), we determine that assignments $v_1@6$ and $\overline{v_5}@3$ cause the BCP implication $v_3@6$ due to clause $c_2$). Now we resolve the two clauses $cl$ and $c_2$ using the resolution variable $v_3$ to obtain the clause $\overline{v_4} \lor \overline{v_1} \lor v_5$.
Next, from the new clause, we obtain $lit=\overline{v_4}, var=v_4, ante=c_3$ and apply resolution to get the clause $\overline{v_1} \vee v_5 \lor \overline{v_2}$.
Similarly, from this clause, we obtain $lit=\overline{v_2}, var=v_2, ante=c_1$ and apply resolution to obtain the clause $v_1 \lor v_5$.
% \begin{figure}
%   \centering
%   \begin{tabular}{ccccc}
%     name & cl & lit & var & ante \\
%     \midrule
%     $c_4$ &$\overline{v_3} \lor \overline{v_4}$   & $\overline{v_3}$ &$v_3$   &     $c_2$\\
%          & $\overline{v_4} \lor \overline{v_1} \lor v_5$  & $\overline{v_4}$   &     $v_4$  &      $c_3$\\
%          &$\overline{v_1} \lor v_5 \lor \overline{v_2}$   & $\overline{v_2}$   &     $v_2$  &      $c_1$\\
%     $c_5$      & $\overline{v_1} \lor v_5$

%   \end{tabular}
%   \caption{Learning a new clause.}\label{fig:igraphc}
% \end{figure}

At this point, \texttt{AnalyzeConflict} determines that this is an asserting clause, which would force an immediate BCP implication after backtracking. As will be shown in \S\ref{sec:backtrack}, \tool{} will backtrack to level 3 and erases all assignments after this level (so the assignment $\overline{v_5}@3$ is not erased, but assignments after level 3 are erased).  Then, \texttt{BCP} will find that $c_5$ is a unit clause because $\overline{v_5}@3$ and infers $\overline{v_1}$.
Once obtaining the asserting clause, \texttt{AnalyzeConflict} stops the search, and \tool{} adds  $v_1\lor v_5$ as the new clause $c_5$ to the set of existing four clauses.

\end{example}

%is a main benefit of CDCL and
The process of learning clauses allows \tool{} to learn from its past mistakes.
While such clauses are logically implied by the formula in ~\autoref{eq:nnv2} and therefore do not change the result, they help prune the search space and allow DPLL and therefore \tool{} to scale. For example, after learning the clause $c_5$, together with assignment $v_5@3$, we immediately infer $v_1 \mapsto F$ through BCP instead of having to guess through \texttt{Decide}.

%The literal lit is the literal in cl assigned last, and var denotes its associated variable. The antecedent clause of var, denoted by ante, contains Â¬lit as the only satisfied literal, and other literals, all of which are currently unsatisfied. The clauses cl and ante thus contain lit and Â¬lit, respectively, and can therefore be resolved with the resolution variable var. The resolvent clause is again a conflicting clause, which is the basis for the next resolution step.


%% After detecting the conflict, the solver determines which decision level to backtrack to according to the \textbf{conflict-driven backtracking} strategy.
%% According to this strategy, the backtracking level is set to the second most recent decision level in the conflict clause, while erasing all decisions and implications made after that level.

%% There are two special cases: when learning a \textit{unary} clause, the solver backtracks to the ground level; when the conflict is at the ground level, the backtracking level is set to â€“1 and the solver exits and declares the formula to be \textbf{unsatisfiable}.

%In the case of $c_9$, the solver backtracks to decision level 3 (the decision level of $v_5$), and erases all assignments from decision level 4 onwards, including the assignments to $v_1@6, v_2@6, v_3@6$, and $v_4@6$.
%The newly added conflict clause $c_9$ becomes a unit clause since $\overline{v_5}@3$, and therefore the assignment $\overline{v_1}@3$ is implied.
%This new implication restarts the BCP process at level 3.


%% Formally, the process of the analyze conflict is described in Algorithm~\ref{alg:conflict}.
%% For a given unit clause $C$ with an unassigned literal $l$, we say that $l$ is implied by $C$ and that $C$ is the \textbf{antecedent clause} of $l$, denoted by \textsc{Antecedent}($l$).
%% For example, in the example in Sec \ref{sec:bcp}, at decision level 3 the decision was $\overline{v_6}@3$, which implied $\overline{v_5}@3$ owing to clause $c_8$, hence \textsc{Antecedent}($\overline{v_5}$) = $c_8$.


%% The other functions and variables are self-explanatory.


%% The implication graph on the~\autoref{fig:igraph}b demonstrates the BCP process at the current decision level 6 until, in this case, a conflict is detected.
%% The roots of this graph, namely $\overline{v_5}@3$ and $v_1@6$, constitute a sufficient condition for creating this conflict.
%% Therefore, we can safely add to our formula the \textbf{conflict clause}:
%% \begin{equation}
%%     c_9 = (v_5 \lor \overline{v_1})
%% \end{equation}


\subsection{Backtrack} \label{sec:backtrack}
From the clause returned by \texttt{AnalyzeConflict}, \texttt{Backtrack}  (\autoref{fig:alg}, line~\ref{line:backtrack}) computes a backtracking level and erases all decisions and implications made after that level.
If the clause is \emph{unary} (containing just a single literal), then we backtrack to level 0. % (and if we obtain further conflict with this clause, then the formula is unsatisfiable).

Currently, \tool{} uses the standard \emph{conflict-drive backtracking} strategy~\cite{barrett2013decision}, which sets the backtracking level to the \emph{second most recent} decision level in the clause.
Intuitively, by backtracking to the second most recent level, which means erasing assignments made \emph{after} that level, this strategy encourages trying new assignments for more recently decided variables.
%\hd{Other backtracking scheme in Chaff~\cite{moskewicz2001chaff}: always stop clause learning at the first UIP --- This form of clause learning, and associated backtracking procedure, is referred to as first UIP clause learning. Existing results indicate that the first UIP clause learning procedure may end up doing more backtracking than the original clause learning of GRASP~\cite{zhang2001efficient}. However, Chaff creates significantly fewer clauses and is significantly more effective at backtracking. As a result, the first UIP learning scheme is now commonly used by the majority of CDCL SAT solvers.}

%\tvn{Intuitively this is because} \hd{Intuitively, backtracking to 2nd most recent $dl$ in $cl$ to flip the assignment of the most recent decided literal (True to False or False to True). For example, \{$\neg x_5@3, x_1@6$\} causes the conflict, the most recent decided literal is $x_1$, then we need to flip $x_1$ from True to False. But now $x_1$ is associated with decision level 3 (dl 3 is decision level of $x_5$ --- the literal which has 2nd most recent decision level in the learned conflict clause.)}.



\begin{example}

    From the clause $c_5=\overline{v_1} \lor v_5$ learned in \texttt{AnalyzeConflict}, we backtrack to decision level 3, the second most recent decision level in the clause (because assignments $v_1@6$  and $\overline{v_5}@3$ were decided at levels 6 and 3, respectively). Next, we erase all assignments from decision level 4 onward (i.e., the assignments to $v_1,v_2,v_3,v_4$ as shown in the implication graph in~\autoref{fig:igraph}). This thus makes these more recently assigned variables (after decision level 3) available for new assignments (in fact, as shown by the example in~\autoref{sec:bcp}, \texttt{BCP} will immediately infer $v_1=T$ by noticing that $c_5$ is now a unit clause).
\end{example}

%\tvn{Discussion: waste of time for erasing everything from dl?} \hd{If we don't erase information from $dl$ when backtrack occurs, it will require a lot of memories to save the redundant information of implication graph from decision level $dl$ onwards.}
% \subsection{Clause Learning}
% \tvn{write pseudo code if it is complicated enough}
% \tvn{Describe }

% \tvn{Give small illustration using example in SEct 3}

% \subsection{Backtracking}
% \tvn{write pseudo code if it is complicated enough}
% \tvn{Describe }

% \tvn{Give small illustration using example in SEct 3}



%% \subsubsection{Backtrack} Given a conflict clause, \textbf{Backtrack}  (\autoref{fig:alg}, line~\ref{line:backtrack}) compute a decision level to backtrack to. Currently, we use the \emph{conflict-drive backtracking}~\cite{barrett2013decision}, which sets the backtracking level to the \emph{second most recent} decision level in the conflict clause \tvn{Intuitively this is because}.
%% Next, Backtrack erases decisions by Decide and implications by BCP and Deduce made after that level.
%% Note that if we learn a \emph{unary} clause, which contain just a single literal, then we backtrack to level 0 (and if we obtain further conflict with this clause (a conflict at level $dl=0$, line~\ref{line:unsat}), i.e., the formula is unsatisfiable).

\subsection{Restart}\label{sec:restart}


As with any stochastic algorithm, \tool{} can perform poorly if it gets into a subspace of the search that does not quickly lead to a solution, e.g., due to choosing a bad sequence of neurons to split~\cite{bunel2018unified,de2021improved}.
% In the development of modern SAT solver (e.g.PicoSAT~\cite{biere2008picosat}), researchers has realized most practical problems, even very large or complex, can be easily solved if they follow
This problem, which has been recognized in early SAT solving, motivates the introduction of restarting the search~\cite{gomes1998boosting} to avoid being stuck in such a \emph{local optima}.




%because the initial clause is too simple (e.g., $v_i \lor \overline{v_i}$) to make clause learning effective.

%\tvn{some more explanation on why this make clause learning ineffective}
%\hd{simple and trivial clauses lead to simple chronological backtracks by the binary resolution during conflict analysis step}
%Having said that without using restart, the non-chronological backtracks would never get used by \tool{} since these backtracks need more complex implication graph to be jumped into.

\tool{} uses a simple restart heuristic (\autoref{fig:alg}, line~\ref{line:restart}) that triggers a restart when either the number of processed assignments (nodes) exceeds a pre-defined number (e.g., 300 nodes) or the current runtime exceeds a pre-defined threshold (e.g., 50 seconds).
% \tvn{what are these number and threshold?}\hd{added}
After a restart, \tool{} avoids using the same decision order of previous runs (i.e., it would use a different sequence of neuron splittings). It also resets all internal information (e.g., decisions and implication graph) except the learned conflict clauses, which are kept and reused as these are \textit{facts} about the given constraint system.
This allows a restarted search to quickly prune parts of the  space of assignments.


%For \tool{} and DNN verification problem, we found that restart is especially important for solving difficult problem.
%Restart, which is only triggered for expensive searches, allows for a different decision ordering and assignments that might solve the problem quicker. Moreover,

We found the combination of clause learning and restarts effective for DNN verification. In particular, while restart resets information  it keeps learned clauses, which  are \emph{facts} implied by the problem, and therefore enables quicker BCP applications and non-chronological backtracking (e.g., as illustrated in~\autoref{fig:tree}).

%It is worth noting that while it is possible to add a restart to existing DNN verification approaches. This is unlikely to help, because these techniques do not learn conflict clauses and therefore restart will just randomize order but carry no information forward to prune the search space.

%... \mbd{discuss possibility of restart for other tools, but it will just randomize order but carry no information forward to prune search.}

% \tvn{these are standard arguments for restart.  For \tool{} and DNN verifcation problem,  restart is even more important because the inital clause is too simple to make clause learning effective.  You should say something here about that issue.  Just write all of them here and we can clean it up}


\section{Deduction (Theory Solving)}\label{sec:deduction}

\begin{algorithm}[t]
    \small

    \Input{ DNN $\network$, input property $\phi_{in}$, output property $\phi_{out}$, decision level $dl$ and current assignment $\assignment$}
    \Output{{\false} if infeasibility occurs, {\true} otherwise}

    \BlankLine

    $\lpmodel \leftarrow \LPSolver(\assignment, \network \land \phi_{in} \land \overline{\phi_{out}})$\;\label{line:lpsolver}
    \lIf{$\Solve(\lpmodel) \equiv \infeasible$}{\Return {\false}}\label{line:solve}
    \lIf(\tcp*[h]{orig prob (~\autoref{eq:nnv2}) is satisfiable}){$\isTotal(\assignment)$}{\Return {\true} }\label{line:full}
    %$\inputs = \GetInputs(\phi_{in})$
    % $\ninputs \leftarrow \GetNumInputs(\network)$
    % $\layernodes = \FindLayerNodes(\assignment)$\;

    % \If{$|\inputs| \le \maxinputs$}{
    %     $\inputbounds = \TightenBounds(\lpmodel, \inputs)$\;\label{line:tighteninpsb}
    % }
    % \Else{$\inputbounds = \GetInputBounds(\phi_{in})$\;\label{line:inputbounds}
    % }

    $\inputbounds \leftarrow \TightenInputBounds(\lpmodel, \phi_{in})$\;\label{line:absstart}
    $\outputbounds, \hiddenbounds \leftarrow \Abstract(\network, \assignment, \inputbounds$)\;\label{line:abstraction}

    \lIf{$\Check(\outputbounds, \overline{\phi_{out}}) \equiv \infeasible$}{\Return {\false}}\label{line:checkfeasibility}

    \For{$v \in \hiddenbounds$} {\label{line:infera}
      $x \leftarrow \ActivationStatus(v)$\;
      \lIf{$x \in \sigma \lor \neg{x} \in \sigma$}{\Continue}
      \lIf{$\Lower(v) > 0$}{$\assignment \leftarrow \assignment \cup x@dl$}
        \lElseIf{$\Upper(v) \le 0$}{$\assignment \leftarrow \assignment \cup \overline{x}@dl$}\label{line:inferb}
    }

    \Return {\true}\;\label{line:absend}

    \caption{\textsc{Deduction}}\label{alg:deduction}
\end{algorithm}

\texttt{Deduction} (\autoref{fig:alg}, line~\ref{line:deduction}) is the theory or T-solver, i.e., the T in DPLL(T). The main purpose of the T-solver is to check the feasibility of the constraints represented by the current propositional variable assignment; as shown in the formalization in \S\ref{sec:formalization} this amounts to just \emph{linear equation} solving for verifying piecewise linear DNNs. However, \tool{} is able to leverage specific information from the DNN problem, including input and output properties, for more aggressive feasibility checking.  Specifically, \texttt{Deduction} has three tasks: (i) checking feasibility using linear programming (LP) solving, (i) further checking feasibility with input tightening and abstraction, and (iii) inferring literals that are unassigned and are implied by the abstracted constraint.

%The algorithm returns conflict if the current assignment does not satisfy the constraints of the network and property.
%Similar to \textsc{BCP}, Deduce also perform assignment inferencing.


\autoref{alg:deduction} describes \texttt{Deduction}, which returns \texttt{False} if infeasibility occurs and  \texttt{True} otherwise.
%\textsc{Deduce} is a theory solver that takes the arguments including: the current assignment $\sigma$, neural network $\alpha$, precondition $\phi_{in}$ over inputs and postcondition $\phi_{out}$ over outputs.
First, it creates a linear constraint system from the input assignment $\sigma$ and $\alpha \land \phi_{in} \land \overline{\phi_{out}}$, i.e., the formula in ~\autoref{eq:nnv2} representing the original problem  (line~\ref{line:lpsolver}).
The key idea is that we can remove ReLU activation for hidden neurons whose activation status have been decided.
For constraints in $\alpha$ associated with variables that are not in the $\sigma$,  we ignore them and just consider the cutting planes introduced by the partial assignment.
%Fixup preceding sentence based on answer.}
%\hd{Yes, you're correct. We ignore constraints generated by unassigned variables and only consider the cutting planes introduced by the partial assignment}
For example, for the assignment $v_3\mapsto T, v_4 \mapsto F$, the non-linear ReLU constraints $x_3=ReLU(-0.5x_1+0.5x_2+1)$ and  $x_4=ReLU(x_1+x_2-1)$ for the DNN in~\autoref{fig:dnn} become linear constraints $x_3=-0.5x_1+0.5x_2$ and $x_4=0$, respectively.

Next, an LP solver checks the feasibility of the linear constraints (line~\ref{line:solve}).
If the solver returns infeasible,  \texttt{Deduction} returns \texttt{False} so that \tool{} can analyze the assignment and backtrack.
If the constraints are feasible, then there are two cases to handle. First, if the assignment is total (i.e., all variables are assigned), then that means that the original problem is satisfiable (line~\ref{line:full}) and \tool{} returns \texttt{sat}.

\paragraph{ReLU Abstraction.} Second, if the assignment is not total then \texttt{Deduction} applies abstraction to check satisfiability (lines~\ref{line:absstart}--\ref{line:checkfeasibility}).
Specifically, we over-approximate  ReLU computations to obtain the upper and lower bounds of the output values and check if the output properties are feasible with respect to these bounds. For example, the output $x_5 > 0$ is \emph{not} feasible if the upperbound is $x_5 \le 0$ and \emph{might be} feasible if the upperbound is $x_5 \le 0.5$ (``might be'' because this is an upper-bound). If abstraction results in infeasibility, then \texttt{Deduction} returns \texttt{False} for \tool{} to analyze the current assignment (line~\ref{line:checkfeasibility}).

\begin{figure}
    \begin{minipage}[b]{1\linewidth}
        \centering
        \begin{minipage}[c]{0.24\linewidth}
            \includegraphics[width=\linewidth]{figure/interval-3.pdf}
            \vspace*{-10mm}
            \caption*{(a) interval}
        \end{minipage}
        % \hspace{0.05\textwidth}%
        \begin{minipage}[c]{0.24\linewidth}
            \includegraphics[width=\linewidth]{figure/zonotope-3.pdf}
            \vspace*{-10mm}
            \caption*{(b) zonotope}
        \end{minipage}
        % \hspace{0.05\textwidth}%
        \begin{minipage}[c]{0.24\linewidth}
            \includegraphics[width=\linewidth]{figure/polytope-3.pdf}
            \vspace*{-10mm}
            \caption*{(c) DeepPoly}
        \end{minipage}
        \begin{minipage}[c]{0.24\linewidth}
            \includegraphics[width=\linewidth]{figure/lirpa-3.pdf}
            \vspace*{-10mm}
            \caption*{(d) LiRPA}
        \end{minipage}
        \vspace*{-3mm}
        \caption{Abstractions for ReLU: (a) interval, (b) zonotope, and (c-d) polytopes. Notice that ReLU is a non-convex region (red line) while all abstractions are convex regions. Note that (c) and (d) are both polytopes.}\label{fig:abs}
    \end{minipage}
\end{figure}

\tool{} uses abstraction to approximate the lower and upper bounds of hidden and output neurons.
\autoref{fig:abs} compares the (a) interval~\cite{wang2018formal}, (b) zonotope~\cite{singh2018fast}, and (c, d) polytope~\cite{xu2020fast,singh2019abstract,wang2021beta} abstraction domains to compute the lower $l_y(x)$ and upper $u_y(x)$ bounds of a ReLU computation $y=\texttt{ReLU(x)}$ (non-convex red line).
\tool{} can employ any existing abstract domains, though currently it adopts the \emph{LiRPA} polytope (\autoref{fig:abs}d)~\cite{xu2020fast,xu2020automatic,wang2021beta} because it has a good trade-off between precision and efficiency.

%\hd{remove this sentence?}

\paragraph{Inference} If abstraction results in feasible constraints, \texttt{Deduction} next attempts to infer implied literals (lines~\ref{line:infera}--~\ref{line:inferb}). To obtain the bounds of the output neurons, abstraction also needs to compute the bounds of hidden neurons, including those with undecided activation status (i.e., not yet in $\sigma$).
This allows us to assign the activation variable of a hidden neuron the value
\texttt{True} if the lowerbound of that neuron is greater than 0 (the neuron is active) and
\texttt{False} otherwise.
Since each literal is considered, this would be considered exhaustive theory propagation.  Whereas the literature~\cite{nieuwenhuis2006solving,kroening2016decision} suggests that this is an inefficient strategy, we find that it does not incur significant overhead (average overhead is about 4\% and median is 2\%).

%\mbd{forward pointer to data on this in evaluation section.}
%\hd{Maximum overhead is about 39\% of runtime, all cases which have overhead > 30\% belong to CIFAR networks from CIFAR2020 benchmark which are large (cifar10\_2\_255, convBigRELU\_PGD), average overhead is about 4\%, apply median filter and average will be 2\%}

\begin{example} For the illustrative example in~\autoref{ex:neuralsat}, in iteration 3, the current assignment $\sigma$ is  $\{v_4=1\}$, corresponding to a constraint $x_1 + x_2 - 1 > 0$. With the new constraint, we optimize the input bounds and compute the new bounds for hidden neurons $0.5 \le x_3 \le 2.5$, $0 < x_4 \le 2.0$ and output neuron  $x_5 \le 0.5$ (and use this to determine that the postcondition $x_5 > 0$ might be feasible). We also infer $v_3=1$ because of the positive lower bound $0.5 \le x_3$.
\end{example}

%reason
%with trade-offs between computational complexity and precision.

%\tvn{Describe how ABstractDomain works, e.g., are hidden\_bounds the bounds of values of hidden neurons? Also, how does CheckReachability work? why does it require $\phi_{in}$?}

%in which we know that the original problem is satisfiable and return (and \tool{} will return \texttt{sat}).
%The second case is when the assignment was not full, i.e., we

%% For every assignment $x\mapsto $
%% Base on the current assignment $\alpha$, first step is to build linear equations for each status variable over the input variables using back substitution.
%% The key idea here is that we could be able to remove the ReLU activation at layer $i$ if the pre-activation variables in the layer $i$ are fully assigned.
%% The ReLU function originally is non-linear (e.g., $y = max(0, x)$), but it becomes a linear function when we know about the value of its input (base on the value of assigned nodes, we could have the pre-activation values either greater or less than 0).

%% For example, the network in Figure~\ref{fig:dnn} is represented as the formula:
%% \begin{gather}
%%         x_3 = -0.5x_1 + 0.5x_2 + 1 \;\land\; x_3' = ReLU(x_3) \;\land\; \nonumber\\
%%         x_4 = x_1 + x_2 - 1 \;\land\; x_4' = ReLU(x_4)  \;\land\; \\
%%         x_5 = -x_3' + x_4' - 1 \;\nonumber
%% \end{gather}
%% If \tool{} decides $v_3 = True$ ($v_3$ is status variable of neuron $x_3'$) and $v_4$ is undecided, we cannot have the linear relationship between $x_5$ and the inputs $x_1, x_2$, because the first layer is not fully decided, then we cannot remove the ReLU layer.
%% Otherwise, \tool{} decides $v_3 = True$ and $v_4 = False$, then $x_3' = -0.5x_1 + 0.5x_2 + 1$ and $x_4' = 0$, also $x_5 = 0.5x_1 - 0.5x_2 - 2$.
%% The first layer now is fully assigned, then the ReLU layer no longer exists, that makes we could build linear relationship of $x_5$ over $x_1, x_2$.

%When all the neurons of the network are decided, the network becomes a linear one, then we could build a linear solver to check the feasibility of the model w.r.t the specification, with the constraints as linear equations of outputs over inputs.
%Branch-and-Bound based methods without the step of checking feasibility when all split neurons are also considered as \textbf{incomplete}.

%Next, these equations is added to a LP solver that follow the rule of ReLU activation: if a status variable is decided to be True, which means that neuron is in active region, its equation will be greater than 0, and constraint $eq(x) > 0$ is added to the solver; otherwise constraint $eq(x) \le 0$ is added to the solver (Line 2 in Algorithm~\ref{alg:deduction}).
%For example, $v_3 = True$ then $x_3 > 0$ and a constraint $-0.5x_1 + 0.5x_2 + 1 > 0$ is added into the LP solver.

%Then, solver runs optimization step without objective function to check the feasibility of model  (Line 3).
%If the model is infeasible, the current assignment will lead to UNSAT state, the Theory Deduce will raise ``conflict'' status so that the core DPLL could make a conflict analysis to handle it.

%Otherwise, the process continues with checking the reachability of the current assignment bases on the abstraction, described in Sec~\ref{sec:theory_abstraction}.
%Without this step, the Theory Deduce is unable to quickly decide an assignment is unreachable.
%Thus, this step uses an over-approximation technique to estimate the possible output ranges w.r.t the given input ranges and the current assignment.
%Two well-known abstraction techniques are adapted/adopted in our \tool{}, which are \textbf{DeepPoly} in ERAN verifier \cite{singh2019abstract} and \textbf{LiRPA} in $\alpha$-$\beta$-CROWN verifier\cite{wang2021beta} (Line 7).
%\hd{when does \tool{} use DeepPoly/LiRPA? Small number of inputs (<50), use LP to tighten input ranges then apply DeepPoly. Otherwise, jointly optimize hidden bounds and output bounds using LiRPA (same as ab-crown) --- Actually, in small number of inputs cases, it's reimplementation of DeepPoly with adaptation of learnable \textit{slopes} as in ab-crown. Depend on the input ranges, the abstraction will compute output ranges directly use original version or use optimized slopes version of DeepPoly to get better bounds.}
%The estimated output ranges could be used to check the reachability, as shown in Sec~\ref{sec:unsat}.
%If the output property is unreachable, the Theory Deduce will raise ``conflict'' status, otherwise, the output property might be reachable, we could not decide the reachability status of the current assignment.




\bibliographystyle{abbrv}
\bibliography{book.bib}


\end{document}
