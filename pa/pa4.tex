\section{PA4: Verifying ACAS XU benchmarks}\label{sec:pa4}

In this PA, you will use your existing implementations you have done in previous PAs to verify properties of a real benchmark using the standard format (ONNX for networks, and VNNLIB for properties).

\subsection{Part 1: Handling ONNX Networks}

In order to handle ONNX networks, the simplest way is to use the ONNX library to load the network and convert to Pytorch model.
You can install the conversion library ``onnx2pytorch'' using pip:
\begin{center}
    \begin{lstlisting}[language=bash]
    pip install onnx2pytorch
    \end{lstlisting}
\end{center}
Then you can use the library to load the network and convert to Pytorch model as follows:

\begin{lstlisting}[language=Python]
import onnx
import onnx2pytorch

# load the ONNX network
model = onnx.load("path/to/your/network.onnx")

# convert to Pytorch model
# experimental=True is optional to use batch processing
model = onnx2pytorch.convert(model, experimental=True) 

# since ACAS XU benchmarks contain simple feed-forward networks,
# we can simply enumerate each layer of a network
for layer_name, layer in enumerate(layers):
    if isinstance(layer, nn.Linear):
        # TODO handle linear layer
        pass
    elif isinstance(layer, nn.ReLU):
        # TODO handle ReLU layer
        pass
    elif isinstance(layer, sub):
        # handle subtraction layer
        continue # this layer is y = x - 0, which is identity, so skip it
    else:
        # TODO handle other layers
        pass

\end{lstlisting}


\subsection{Part 2: Handling VNNLIB Properties}

\subsubsection{Parsing VNNLIB Properties}

VNNLIB properties are designed to represent properties of neural networks in a formal language.
It specifies the precondition and postcondition of the network.
To extract the preconditions and postconditions from a VNNLIB property, you can follow the provided code \url{https://github.com/dynaroars/book_nnv/blob/main/code/pa4/test.py}:

\begin{lstlisting}[language=Python]
# input shape is (1, 5) for ACAS XU benchmarks
input_shape = (1, 5) 

# parse the VNNLIB property
properties = parse_vnnlib("path/to/your/property.vnnlib", input_shape)
\end{lstlisting}

\subsubsection{VNNLIB Disjunctive Properties}
Note that, one VNNLIB file can contain disjunctive properties. Let's take a look at an example VNNLIB property 7 of ACAS XU benchmarks:

\begin{lstlisting}[language=SMTLIB]
; ACAS Xu property 7

(declare-const X_0 Real)
(declare-const X_1 Real)
(declare-const X_2 Real)
(declare-const X_3 Real)
(declare-const X_4 Real)

(declare-const Y_0 Real)
(declare-const Y_1 Real)
(declare-const Y_2 Real)
(declare-const Y_3 Real)
(declare-const Y_4 Real)

; Unscaled Input 0: (0, 60760)
(assert (<= X_0 0.679857769))
(assert (>= X_0 -0.328422877))

; Unscaled Input 1: (-3.141592, 3.141592)
(assert (<= X_1 0.499999896))
(assert (>= X_1 -0.499999896))

; Unscaled Input 2: (-3.141592, 3.141592)
(assert (<= X_2 0.499999896))
(assert (>= X_2 -0.499999896))

; Unscaled Input 3: (100, 1200)
(assert (<= X_3 0.5))
(assert (>= X_3 -0.5))

; Unscaled Input 4: (0, 1200)
(assert (<= X_4 0.5))
(assert (>= X_4 -0.5))

; unsafe if strong left is minimial or strong right is minimal
(assert (or
    (and (<= Y_3 Y_0) (<= Y_3 Y_1) (<= Y_3 Y_2))
    (and (<= Y_4 Y_0) (<= Y_4 Y_1) (<= Y_4 Y_2))
))
\end{lstlisting}

This file specifies the properties in form of \(X \land (P_0 \vee P_1)\), where \(X\) is the precondition on input variables ($X_0$, $X_1$, $X_2$, $X_3$, $X_4$) and \(P_0\) and \(P_1\) are the postconditions in \emph{negation form} (do not negate them!) on output variables ($Y_0$, $Y_1$, $Y_2$, $Y_3$, $Y_4$).


Specifically,
\begin{align*}
X \equiv &~(-0.328422877 \leq X_0 \leq 0.679857769) \\
    \land &~(-0.499999896 \leq X_1 \leq 0.499999896) \\
    \land &~(-0.499999896 \leq X_2 \leq 0.499999896) \\
    \land &~(-0.5 \leq X_3 \leq 0.5) \\
    \land &~(-0.5 \leq X_4 \leq 0.5) \\
% P_0 \equiv & (Y_0 \leq Y_1) \land (Y_0 \leq Y_2) \land (Y_0 \leq Y_3) \land (Y_0 \leq Y_4) \\
% P_1 \equiv & (Y_3 \leq Y_4) \\
\end{align*}
\begin{align*}
P_0 \equiv &~(Y_3 \leq Y_0) \land (Y_3 \leq Y_1) \land (Y_3 \leq Y_2) \\
P_1 \equiv &~(Y_4 \leq Y_0) \land (Y_4 \leq Y_1) \land (Y_4 \leq Y_2)
\end{align*}

To deal with disjuntive postconditions (\(P_0 \vee P_1\)), the code above from \neuralsat{} simply converts \(X \land (P_0 \vee P_1)\) to a list of conjunctive postconditions:
\[
\underbrace{(X \land P_0)}_{\text{property 1}} \lor \underbrace{(X \land P_1)}_{\text{property 2}}
\]
Now each sub-property (e.g., property 1 and property 2) has the same form as PA3, to verify a sub-property, you can use the code from PA3.

\subsubsection{Output Constraints in VNNLIB}
VNNLIB always represents the output constraints in the form of:
\[cs \cdot Y \leq rhs\]
where \(Y\) is the output vector.

For example, \(Y_3 \leq Y_0\) is equivalent to \(-Y_0 + Y_3 \leq 0\), which is represented as:
\[
\underbrace{\begin{bmatrix}
-1 & 0 & 0 & 1 & 0
\end{bmatrix}}_{cs}
\underbrace{\begin{bmatrix}
Y_0 \\ Y_1 \\ Y_2 \\ Y_3 \\ Y_4
\end{bmatrix}}_{Y}
\leq
\underbrace{\begin{bmatrix}
0
\end{bmatrix}}_{rhs}
\]

If you are using VNNLIB extraction code from \neuralsat{}, each sub-property is an object with following attributes:
\begin{itemize}
    \item \texttt{lower\_bounds}: input lower bounds (e.g., lower bounds of all input variables)
    \item \texttt{upper\_bounds}: input upper bounds (e.g., upper bounds of all input variables)
    \item \texttt{cs}: coefficient matrix for output constraints
    \item \texttt{rhs}: constant vector for output constraints
\end{itemize}

\begin{lstlisting}[language=Python]

# number in pop(), e.g., pop(1), means numbers of sub-properties 
# we want to verify simultaneously, not the index of the sub-property
sub_property = properties.pop(1) # get one sub-property

print(sub_property.lower_bounds)
# tensor([[-0.3284, -0.5000, -0.5000, -0.5000, -0.5000]])

print(sub_property.upper_bounds)
# tensor([[0.6799, 0.5000, 0.5000, 0.5000, 0.5000]])

print(sub_property.cs)
# tensor([[[-1.,  0.,  0.,  1.,  0.],   # Y_3 <= Y_0
#         [ 0., -1.,  0.,  1.,  0.],    # Y_3 <= Y_1
#         [ 0.,  0., -1.,  1.,  0.]]])  # Y_3 <= Y_2

print(sub_property.rhs)
# tensor([[0., 0., 0.]])

\end{lstlisting}

\subsubsection{Verifying VNNLIB Properties}


Remember that we have a list of disjunctive sub-properties (e.g., property 1 and property 2 for property 7). 
To verify the original property is UNSAT, we need to verify all sub-properties are UNSAT. 
But to show the original property is SAT, disproving one sub-property is enough.
The high-level idea should look like this:
\begin{lstlisting}[language=Python]
while len(properties): # make sure to verify all sub-properties
    sub_property = properties.pop(1) # get one sub-property
    # disprove one sub-property, return counterexample immediately
    if verify(network, sub_property) == SAT:
        return SAT, cex

    # run out of time
    if verify(network, sub_property) == TIMEOUT:
        return TIMEOUT

    # prove one sub-property
    if verify(network, sub_property) == UNSAT:
        continue # move to next sub-property

# all sub-properties are verified, the original property is UNSAT
return UNSAT
\end{lstlisting}

\subsection{Part 3: Putting Everything Together}
Now you have all the components to buid the verifier. You need to follow the following naming conventions for your implementation:
\begin{enumerate}
    \item A single python file \code{verify.py} that accepts three command line arguments, and run the verification. This provides a unified interface for us to test your implementation.
        \begin{listlisting}[language=bash]
        python verify.py [path/to/network.onnx] [path/to/property.vnnlib] [timeout_in_seconds]

        E.g.
        python verify.py acasxu/Network1_1.onnx acasxu/Property7.vnnlib 116
        Would run the verifier on the given network and property with a timeout of 116 seconds.
        \end{listlisting}
        Your output should be either \code{UNSAT}, \code{SAT}, or \code{TIMEOUT}. If the output is \code{SAT}, you should also print the counterexample found.
    \item You actual implementation should be in \code{p4.py}.

    
\subsection{Part 4: Verifying ACAS XU benchmarks}
Download the ACAS XU benchmarks from \url{https://github.com/dynaroars/neuralbench/tree/main/instances/acasxu}.
In this folder, you will find the following files/folders:
\begin{itemize}
    \item Folder \texttt{onnx}: contains the ONNX networks
    \item Folder \texttt{vnnlib}: contains the VNNLIB properties
    \item File \texttt{instances.csv}: contains list of instances of the ACAS XU benchmarks, where each line is a tuple of (network path, property path, timeout in seconds).
\end{itemize}

Your task is to:
\begin{enumerate}
    \item enumerate first 90 instances in \texttt{instances.csv} and verify the properties, the rest are optional.
    \item report the result for each instance, either, UNSAT, SAT, or TIMEOUT.
    \item some timeouts are expected, we do not expect your verifier to verify all instances.
    \item check the results with the ground truth at \url{https://github.com/dynaroars/book_nnv/blob/main/code/pa4/acasxu_ground_truth.csv}.
\end{enumerate}

% Note that, you can also double check the ground truths to check whether the instances are SAT (counterexample exists).
% If that is the case, using abstraction alone will never return "verified", you will need a way to find a counterexample.




\subsection{What to Turn In}
You must submit a \textbf{zip file} containing the following files. Use the following names:

\begin{enumerate}
    \item The zip file must be named \code{pa4-[yourname/groupname].zip} (1 submission per group)
    \item If you imported anything from your previous PAs, please include those files as well (e.g., \code{p1.py}). We will not run your code if they are missing and you will lose points.
    \item One \code{verify.py} file as described above.
    \item A completed \code{README.md} file. You \emph{must} use the provided template and answer all questions in it.
    \item It is recommended include any logs or results your verifier generated in a seperate folder. You can name the folder as you like, e.g., \code{results/}.
        \begin{itemize}
            \item This is not mandatory, but it will show that you have done the experiments and help us to grade your PA.
        \end{itemize}
    \item If you used any additional scripts/files as needed to help your with Part 4, include those as well. Also include instructions on how to use those scripts/files in the \code{README.md} file.
    % Moved to README template
    % \item 2 screen shots showing how (1) you start your program (e.g., the commands used to run your program) and (2) the end of the run (e.g., of your program on the terminal screen)
    \item Nothing else, do not include any binary files or other directory like \code{\_\_pycache\_\_}, \code{.venv}.
\end{enumerate}



\subsection{Grading Rubric (out of 30 points)}
\begin{itemize}
\item 20 points — Verifier implementation
    \begin{itemize}
        \item 4 points — for parsing ONNX networks correctly
        \item 4 points — for parsing VNNLIB properties correctly
        \item 6 points — for implementing the verifier (\code{verify.py})
        \item 6 points — for running your verifier on ACAS XU benchmarks (first 90 instances)
    \end{itemize}
\item 10 points — for completed README with analysis
    % \begin{itemize}
    % \item 2 points for testing your implementation
    % \item 2 points for \texttt{bab\_vs\_z3}
    % \item 2 points for \texttt{bab\_vs\_abstraction}
    % \item 4 points for answers to discussion questions
    % \end{itemize}
\end{itemize}